{"cells":[{"cell_type":"markdown","source":["### Workflow and Thought Process (SML with USML)\n","\n","Step 1: Get the data into the right layout.\n","- Always think tabular first\n","- Rows are observations / samples\n","- Columns are variables / features\n","\n","```\n","# Load the data into pandas using the correct file type.\n","\n","df = pd.read_csv(...)  # csv\n","df = pd.read_excel(..., sheetname=...)  # excel\n","df = pd.read_parquet(...)  # parquet\n","\n","# and 16 other formats including spss and sql.\n","# ## See here: https://pandas.pydata.org/docs/user_guide/io.html\n","```\n","\n","```\n","# Perform data wrangling to get the correct layout.\n","# ## There is no shame in using GenAI (ChatGPT, Claude, Gemini)\n","\n","df = df.apply(lambda x: ..., axis=1)\n","```\n","\n","Step 2: Explore the data\n","- Interpret features and form inital hypotheses\n","- Observations are used to compute summary statistics for inspection\n","- \"Visualize\" the problem and solution\n","\n","```\n","# Create a profile report of the dataframe\n","# ## Inspect for anomalies and build a sense of the feature space and\n","# ## form an initial set of hypotheses\n","\n","df.profile_report(minimal=True)\n","```\n","\n","## Step 3: Identify themes and latent (hidden) features\n","1. Use-case Development - Hypothesize the possibility of latent (hidden) features by checking whether there are interdependencies between explanatory features.\n","\n","2. Engineer Features - Group features together under a hypothesized theme and think whether the interdependecy relations are simple or complex.\n","\n","3. Train an unsupervised model\n","> - For simple themes, use clustering (create 1 new feature out of n original features).\n",">\n","> - For complex themes, use dimension reduction (create n new features out of n original features).\n",">\n","> - For extremely complex themes with deep layers of interdependency, use a deep learning model instead.\n","\n","```\n","# Clustering\n","# Instantiate an experiment class\n","exp = ClusteringExperiment()\n","\n","# Setup experiment\n","exp.setup(\n","    data=...,\n","    normalize=True,\n",")\n","\n","# Train models\n","... = exp.create_model(...)\n","```\n","\n","```\n","# Dimension Reduction\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import normalize, MaxAbsScaler, Normalizer\n","from sklearn.decomposition import NMF\n","from sklearn.pipeline import make_pipeline\n","from scipy.sparse import csr_matrix\n","\n","# Perform pre-processing\n","# ## (if NLP) Call an instance of tfidf\n","tfidf = TfidfVectorizer()\n","\n","# ## (if not NLP) Call a normalizer\n","nml = Normalizer() # or\n","max = MaxAbsScaler()\n","\n","# Create a model instance\n","nmf = NMF(n_components=...) # or\n","pca = PCA()\n","\n","# Create a pipeline\n","# ## Pipeline will execute the fit and transform in sequence\n","pipeline = make_pipeline(tfidf, nmf)  # or\n","pipeline = make_pipeline(tfidf, mas, nmf, nml)  # if we want to compute cosine similarity\n","\n","# Execute the pipeline\n","# ## Train the pipeline\n","pipeline.fit(...)\n","\n","# ## Apply the trained pipeline to transform existing features into new features\n","new_features = pipeline.transform(...)\n","\n","# ## We can also do the fit-transform in one pass\n","# ## The model will still be trained\n","new_features = pipeline.fit_transform(...)\n","\n","# Assign new features to each observation\n","df_with_new_features = pd.DataFrame(new_features, index=...)\n","```\n","\n","4. Analyze the model result\n","\n","```\n","# For clustering\n","# Check sample distribution\n","exp.plot_model(..., plot='distribution')\n","\n","# Visual cluster connectivity\n","exp.plot_model(..., plot='tsne')\n","\n","# Check cluster separation\n","exp.plot_model(..., plot='distance')\n","```\n","\n","```\n","# For dimension reduction\n","# Extract the top n observations with the highest values for each new feature\n","# Inspect the observations and find a theme for this feature\n","df_with_new_features['...'].nlargest(20)\n","```\n","\n","5. (Depending on use-case) Use model to group or recommend.\n","\n","```\n","# For clustering\n","# Assign cluster membership to each observation\n","df_with_cluster = exp.assign_model(...)\n","\n","# Visualize the relationship between clusters and original features\n","\n","original_features = ['...', ..., '...']\n","\n","for feature in original_features:\n","    sns.boxplot(data=..., x='...', y=feature)\n","```\n","\n","```\n","# For dimension reduction\n","# Use cosine similarity or other methods as recommender\n","# Extract embeddings from sample\n","sample_embedding = [..., ..., ...]\n","\n","# Compute cosine similarity score against all observations\n","similarity_score = df_with_new_features.dot(sample_embedding)\n","\n","# Extract the closest n observations\n","similarity_score.nlargest(n)\n","```\n","\n","Step 4: Identify what you want to predict and what you want to predict with:\n","\n","**Predictive outcome**\n","- A value: Regression\n","- A label (i.e., a choice from a set of candidate choices): Classification\n","\n","**Features**\n","- Features to ignore (lookahead-bias, i.e., values that you will not observe on prediction day. Example, I want to predict price_psf and there are price_psm, transaction_price, and nett_price in the features. These must be ignored.)\n","- Features that should be numerical\n","- Features that should be categorical\n","- For classification, is there data imbalance in the outcome feature? Use fix_imbalance if True.\n","- For classification, ensure data_split_stratify is True so that the train and test datasets have the same proportion of outcome labels\n","- If there are important features that have different proportion in feature lables, pass the feature names as a list to data_split_stratify, which will ensure that the train and test datasets have similar proportions of the feature labels as well.\n","- Consider the need for preprocessing (normalize, transformation, polynomial features).\n","\n","```\n","# Instantiate an experiment class\n","exp = RegressionExperiment()  # or\n","exp = ClassificationExperiment()\n","\n","# Setup the experiment\n","exp.setup(\n","    data=df,\n","    target=...,\n","    fix_imbalance=True,\n","    data_split_stratify=True,\n","    ignore_features=[...],\n","    ...,\n","    session_id = 137,\n","    log_experiment=True,\n","    experiment_name='...',\n",")\n","\n","# See pycaret documentation: https://pycaret.gitbook.io/docs\n","```\n","\n","Step 5: Use the data and fit into models that are known to be:\n","- Easy to understand: Linear/Logistic Regression, Decision Trees\n","- Good predictive performance: Ensembles\n","- Adjusts for overfitting: Ensembles, Penalized Regressions\n","\n","```\n","# Fit the data across all classes of models\n","exp.compare_models()\n","\n","# Choose the best models\n","best_model = exp.create_model(...)\n","lgb = exp.create_model('lgb')\n","xgb = exp.create_model('xgb')\n","```\n","\n","Step 6: Analyze the performance of the models\n","- Feature importances: Does the important features make sense?\n","- Error distribution: What segment of the data tend to have larger errors?\n","- Learning curves: Will more samples help, or do we need more features?\n","\n","```\n","# Validate the model performance on the test set\n","exp.predict_model(best_model)\n","\n","# Inspect the model performance\n","exp.evaluate_model(best_model)\n","\n","# Get a shap diagram to inform hypotheses\n","exp.interpret_model(best_model)\n","```\n","\n","Step 7: Improve the solution\n","- More data and more relevant features\n","- Use stacking or blending ensembles\n","- Tune the model hyperparameters\n","- Insert more intermediate steps into the ML pipeline\n","- Better explanation\n","\n","```\n","# Stack or blend multiple models\n","stack_ensemble = exp.stack_models(...)\n","blend_ensemble = exp.blend_models(...)\n","\n","# Tune models (may or may not improve)\n","tuned_model = exp.tune_model(\n","    best_model,\n","    choose_better=True,\n","    search_library='optuna',\n","    n_iter=200,\n","    optimize='<metric>',\n","    early_stopping=True\n",")\n","```\n","\n","Step 8: Maintain a proper pipeline management\n","- MLOps to manage data and model versions, performance, and other related artifacts\n","\n","```\n","!mlflow ui\n","```\n","\n","Step 9: Prepare for deployment\n","- Train the model on all data\n","- Save the trained model into a file or\n","- Use MLFlow model versioning\n","\n","```\n","# Finalize the model by training it with all data\n","final_model = exp.finalize_model(tuned_model)\n","\n","# Save the final model\n","# ## Use datetime.now() to ensure that we can trace every model version\n","model_filename = f'final_model_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n","\n","# ## Save the model\n","exp.save_model(final_model, model_filename)\n","```\n","\n","Step 10: Create an interface for ease of use\n","- API service\n","- Dashboard\n","\n","```\n","from pycaret.... import load_model, predict_model\n","\n","# Load latest model\n","latest_model = load_model(model_filename)\n","\n","# Insert prediction code into interface code\n","# ## Convert input data into pandas dataframe\n","input_df = pd.DataFrame(...)\n","\n","# ## Get predicted value\n","predicted_value = latest_model.predict_model(input_df)\n","```\n","\n","Step 11: Terminate workflow\n","\n","```\n","# To terminate MLFlow and release ngrok\n","# ## Remove all Python processes containing \"mlflow\"\n","!pkill -f mlflow\n","\n","# ## Remove all ngrok tunnels\n","ngrok.kill()\n","```"],"metadata":{"id":"ktnePFG2Hciu"}},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"sKOV5k5gS2SV"}},{"cell_type":"markdown","source":["### Allow GPU for traditional machine learning\n","The following cells installs the lightgbm gpu version as well as cuml from rapids.ai.\n","\n","These are required if we want to run traditional machine learning models with GPU.\n","\n","Note that deep learning packages (e.g., pytorch, tensorflow) comes with native GPU access. There is no need to install anything else."],"metadata":{"id":"6QqkLQZWXk7x"}},{"cell_type":"code","source":["# LightGBM GPU can be activated with the following script\n","!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd"],"metadata":{"id":"SC9LoYUd0hQV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732545530706,"user_tz":-480,"elapsed":56,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"outputId":"3ae5862d-9251-46c8-9646-8b667945a3d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: /etc/OpenCL/vendors/nvidia.icd: Permission denied\r\n"]}]},{"cell_type":"code","source":["# For some ML models, we require rapids ai's cuml\n","!pip install --extra-index-url=https://pypi.nvidia.com cuml-cu12==24.10.*"],"metadata":{"id":"HPNxshiJ0vCj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732545533137,"user_tz":-480,"elapsed":2430,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"outputId":"4b9993e0-ffe0-4ccf-a720-2ddf27ede50a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\r\n","Requirement already satisfied: cuml-cu12==24.10.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (24.10.0)\n","Requirement already satisfied: cudf-cu12==24.10.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (24.10.1)\n","Requirement already satisfied: cupy-cuda12x>=12.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (13.3.0)\n","Requirement already satisfied: cuvs-cu12==24.10.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (24.10.0)\n","Requirement already satisfied: dask-cuda==24.10.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (24.10.0)\n","Requirement already satisfied: dask-cudf-cu12==24.10.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (24.10.1)\n","Requirement already satisfied: joblib>=0.11 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (1.3.2)\n","Requirement already satisfied: numba>=0.57 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (0.60.0)\n","Requirement already satisfied: numpy<3.0a0,>=1.23 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (1.24.4)\n","Requirement already satisfied: nvidia-cublas-cu12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (12.6.3.3)\n","Requirement already satisfied: nvidia-cufft-cu12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (12.5.4.2)\n","Requirement already satisfied: packaging in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (24.1)\n","Requirement already satisfied: pylibraft-cu12==24.10.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (24.10.0)\n","Requirement already satisfied: raft-dask-cu12==24.10.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (24.10.0)\n","Requirement already satisfied: rapids-dask-dependency==24.10.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (24.10.0)\n","Requirement already satisfied: rmm-cu12==24.10.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (24.10.0)\n","Requirement already satisfied: scipy>=1.8.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (1.11.4)\n","Requirement already satisfied: treelite==4.3.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cuml-cu12==24.10.*) (4.3.0)\n","Requirement already satisfied: cachetools in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cudf-cu12==24.10.*->cuml-cu12==24.10.*) (5.5.0)\n","Requirement already satisfied: cuda-python<13.0a0,>=12.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cudf-cu12==24.10.*->cuml-cu12==24.10.*) (12.6.2.post1)\n","Requirement already satisfied: fsspec>=0.6.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cudf-cu12==24.10.*->cuml-cu12==24.10.*) (2024.10.0)\n","Requirement already satisfied: libcudf-cu12==24.10.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cudf-cu12==24.10.*->cuml-cu12==24.10.*) (24.10.1)\n","Requirement already satisfied: nvtx>=0.2.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cudf-cu12==24.10.*->cuml-cu12==24.10.*) (0.2.10)\n","Requirement already satisfied: pandas<2.2.3dev0,>=2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cudf-cu12==24.10.*->cuml-cu12==24.10.*) (2.1.4)\n","Requirement already satisfied: pyarrow<18.0.0a0,>=14.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cudf-cu12==24.10.*->cuml-cu12==24.10.*) (17.0.0)\n","Requirement already satisfied: pylibcudf-cu12==24.10.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cudf-cu12==24.10.*->cuml-cu12==24.10.*) (24.10.1)\n","Requirement already satisfied: pynvjitlink-cu12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cudf-cu12==24.10.*->cuml-cu12==24.10.*) (0.4.0)\n","Requirement already satisfied: rich in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cudf-cu12==24.10.*->cuml-cu12==24.10.*) (13.9.4)\n","Requirement already satisfied: typing_extensions>=4.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cudf-cu12==24.10.*->cuml-cu12==24.10.*) (4.11.0)\n","Requirement already satisfied: click>=8.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask-cuda==24.10.*->cuml-cu12==24.10.*) (8.1.7)\n","Requirement already satisfied: pynvml<11.5,>=11.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask-cuda==24.10.*->cuml-cu12==24.10.*) (11.4.1)\n","Requirement already satisfied: zict>=2.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask-cuda==24.10.*->cuml-cu12==24.10.*) (3.0.0)\n","Requirement already satisfied: distributed-ucxx-cu12==0.40.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from raft-dask-cu12==24.10.*->cuml-cu12==24.10.*) (0.40.0)\n","Requirement already satisfied: ucx-py-cu12==0.40.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from raft-dask-cu12==24.10.*->cuml-cu12==24.10.*) (0.40.0)\n","Requirement already satisfied: dask==2024.9.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (2024.9.0)\n","Requirement already satisfied: distributed==2024.9.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (2024.9.0)\n","Requirement already satisfied: dask-expr==1.1.14 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (1.1.14)\n","Requirement already satisfied: cloudpickle>=3.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (3.1.0)\n","Requirement already satisfied: partd>=1.4.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (1.4.2)\n","Requirement already satisfied: pyyaml>=5.3.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (6.0.2)\n","Requirement already satisfied: toolz>=0.10.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (1.0.0)\n","Requirement already satisfied: importlib-metadata>=4.13.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (8.5.0)\n","Requirement already satisfied: jinja2>=2.10.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (3.1.4)\n","Requirement already satisfied: locket>=1.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (1.0.0)\n","Requirement already satisfied: msgpack>=1.0.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (1.1.0)\n","Requirement already satisfied: psutil>=5.8.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (5.9.0)\n","Requirement already satisfied: sortedcontainers>=2.0.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (2.4.0)\n","Requirement already satisfied: tblib>=1.6.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (3.0.0)\n","Requirement already satisfied: tornado>=6.2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (6.4.1)\n","Requirement already satisfied: urllib3>=1.26.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (1.26.20)\n","Requirement already satisfied: ucxx-cu12==0.40.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed-ucxx-cu12==0.40.*->raft-dask-cu12==24.10.*->cuml-cu12==24.10.*) (0.40.0)\n","Requirement already satisfied: libucx-cu12<1.18,>=1.15.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ucx-py-cu12==0.40.*->raft-dask-cu12==24.10.*->cuml-cu12==24.10.*) (1.17.0)\n","Requirement already satisfied: libucxx-cu12==0.40.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ucxx-cu12==0.40.*->distributed-ucxx-cu12==0.40.*->raft-dask-cu12==24.10.*->cuml-cu12==24.10.*) (0.40.0)\n","Requirement already satisfied: fastrlock>=0.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cupy-cuda12x>=12.0.0->cuml-cu12==24.10.*) (0.8.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from numba>=0.57->cuml-cu12==24.10.*) (0.43.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from nvidia-cufft-cu12->cuml-cu12==24.10.*) (12.6.77)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pandas<2.2.3dev0,>=2.0->cudf-cu12==24.10.*->cuml-cu12==24.10.*) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pandas<2.2.3dev0,>=2.0->cudf-cu12==24.10.*->cuml-cu12==24.10.*) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pandas<2.2.3dev0,>=2.0->cudf-cu12==24.10.*->cuml-cu12==24.10.*) (2024.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from rich->cudf-cu12==24.10.*->cuml-cu12==24.10.*) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from rich->cudf-cu12==24.10.*->cuml-cu12==24.10.*) (2.15.1)\n","Requirement already satisfied: zipp>=3.20 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (3.21.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from jinja2>=2.10.3->distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (2.1.3)\n","Requirement already satisfied: mdurl~=0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->cudf-cu12==24.10.*->cuml-cu12==24.10.*) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<2.2.3dev0,>=2.0->cudf-cu12==24.10.*->cuml-cu12==24.10.*) (1.16.0)\n"]}]},{"cell_type":"markdown","source":["### Other required installations"],"metadata":{"id":"2PFlLypb4L4r"}},{"cell_type":"code","source":["# Install the additional packages\n","# ## If we install the packages in a single row, it will perform dependency version checks\n","# ## else, the later packages will replace the dependencies of the earlier packages\n","!pip install ydata_profiling swifter\n","!pip install pycaret[full]\n","!pip install scikit-learn-intelex\n","!pip install fastapi[all] mlflow pyngrok"],"metadata":{"id":"vPDNcFBJ4Qzy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732545545436,"user_tz":-480,"elapsed":12297,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"outputId":"0afb9bc1-e142-4520-fe3d-47e28a7d69b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ydata_profiling in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (4.12.0)\r\n","Requirement already satisfied: swifter in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (1.4.0)\n","Requirement already satisfied: scipy<1.14,>=1.4.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (1.11.4)\n","Requirement already satisfied: pandas!=1.4.0,<3,>1.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (2.1.4)\n","Requirement already satisfied: matplotlib<3.10,>=3.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (3.7.5)\n","Requirement already satisfied: pydantic>=2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (2.9.2)\n","Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (6.0.2)\n","Requirement already satisfied: jinja2<3.2,>=2.11.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (3.1.4)\n","Requirement already satisfied: visions<0.7.7,>=0.7.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from visions[type_image_path]<0.7.7,>=0.7.5->ydata_profiling) (0.7.6)\n","Requirement already satisfied: numpy<2.2,>=1.16.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (1.24.4)\n","Requirement already satisfied: htmlmin==0.1.12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (0.1.12)\n","Requirement already satisfied: phik<0.13,>=0.11.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (0.12.4)\n","Requirement already satisfied: requests<3,>=2.24.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (2.32.3)\n","Requirement already satisfied: tqdm<5,>=4.48.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (4.67.0)\n","Requirement already satisfied: seaborn<0.14,>=0.10.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (0.13.2)\n","Requirement already satisfied: multimethod<2,>=1.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (1.12)\n","Requirement already satisfied: statsmodels<1,>=0.13.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (0.14.4)\n","Requirement already satisfied: typeguard<5,>=3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (4.4.1)\n","Requirement already satisfied: imagehash==4.3.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (4.3.1)\n","Requirement already satisfied: wordcloud>=1.9.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (1.9.4)\n","Requirement already satisfied: dacite>=1.8 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (1.8.1)\n","Requirement already satisfied: numba<1,>=0.56.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata_profiling) (0.60.0)\n","Requirement already satisfied: PyWavelets in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from imagehash==4.3.1->ydata_profiling) (1.7.0)\n","Requirement already satisfied: pillow in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from imagehash==4.3.1->ydata_profiling) (11.0.0)\n","Requirement already satisfied: psutil>=5.6.6 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from swifter) (5.9.0)\n","Requirement already satisfied: dask>=2.10.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask[dataframe]>=2.10.0->swifter) (2024.9.0)\n","Requirement already satisfied: click>=8.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.1.7)\n","Requirement already satisfied: cloudpickle>=3.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.1.0)\n","Requirement already satisfied: fsspec>=2021.09.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (2024.10.0)\n","Requirement already satisfied: packaging>=20.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (24.1)\n","Requirement already satisfied: partd>=1.4.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.4.2)\n","Requirement already satisfied: toolz>=0.10.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n","Requirement already satisfied: importlib-metadata>=4.13.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.5.0)\n","Requirement already satisfied: dask-expr<1.2,>=1.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask[dataframe]>=2.10.0->swifter) (1.1.14)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from jinja2<3.2,>=2.11.1->ydata_profiling) (2.1.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<3.10,>=3.5->ydata_profiling) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<3.10,>=3.5->ydata_profiling) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<3.10,>=3.5->ydata_profiling) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<3.10,>=3.5->ydata_profiling) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<3.10,>=3.5->ydata_profiling) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<3.10,>=3.5->ydata_profiling) (2.9.0.post0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from numba<1,>=0.56.0->ydata_profiling) (0.43.0)\n","Requirement already satisfied: pytz>=2020.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pandas!=1.4.0,<3,>1.1->ydata_profiling) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pandas!=1.4.0,<3,>1.1->ydata_profiling) (2024.2)\n","Requirement already satisfied: joblib>=0.14.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from phik<0.13,>=0.11.1->ydata_profiling) (1.3.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pydantic>=2->ydata_profiling) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pydantic>=2->ydata_profiling) (2.23.4)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pydantic>=2->ydata_profiling) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from requests<3,>=2.24.0->ydata_profiling) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from requests<3,>=2.24.0->ydata_profiling) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from requests<3,>=2.24.0->ydata_profiling) (1.26.20)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from requests<3,>=2.24.0->ydata_profiling) (2024.8.30)\n","Requirement already satisfied: patsy>=0.5.6 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from statsmodels<1,>=0.13.2->ydata_profiling) (1.0.1)\n","Requirement already satisfied: attrs>=19.3.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata_profiling) (24.2.0)\n","Requirement already satisfied: networkx>=2.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata_profiling) (3.4.2)\n","Requirement already satisfied: pyarrow>=14.0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask-expr<1.2,>=1.1->dask[dataframe]>=2.10.0->swifter) (17.0.0)\n","Requirement already satisfied: zipp>=3.20 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.21.0)\n","Requirement already satisfied: locket in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from partd>=1.4.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n","Requirement already satisfied: six>=1.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib<3.10,>=3.5->ydata_profiling) (1.16.0)\n","Requirement already satisfied: pycaret[full] in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (3.3.2)\n","Requirement already satisfied: ipython>=5.5.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (8.27.0)\n","Requirement already satisfied: ipywidgets>=7.6.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (8.1.5)\n","Requirement already satisfied: tqdm>=4.62.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (4.67.0)\n","Requirement already satisfied: numpy<1.27,>=1.21 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (1.24.4)\n","Requirement already satisfied: pandas<2.2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (2.1.4)\n","Requirement already satisfied: jinja2>=3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (3.1.4)\n","Requirement already satisfied: scipy<=1.11.4,>=1.6.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (1.11.4)\n","Requirement already satisfied: joblib<1.4,>=1.2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (1.3.2)\n","Requirement already satisfied: scikit-learn>1.4.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (1.4.2)\n","Requirement already satisfied: pyod>=1.1.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (2.0.2)\n","Requirement already satisfied: imbalanced-learn>=0.12.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.12.4)\n","Requirement already satisfied: category-encoders>=2.4.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (2.6.4)\n","Requirement already satisfied: lightgbm>=3.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (4.5.0.99)\n","Requirement already satisfied: numba>=0.55.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.60.0)\n","Requirement already satisfied: requests>=2.27.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (2.32.3)\n","Requirement already satisfied: psutil>=5.9.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (5.9.0)\n","Requirement already satisfied: markupsafe>=2.0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (2.1.3)\n","Requirement already satisfied: importlib-metadata>=4.12.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (8.5.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (5.10.4)\n","Requirement already satisfied: cloudpickle in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (3.1.0)\n","Requirement already satisfied: deprecation>=2.1.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (2.1.0)\n","Requirement already satisfied: xxhash in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (3.5.0)\n","Requirement already satisfied: matplotlib<3.8.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (3.7.5)\n","Requirement already satisfied: scikit-plot>=0.3.7 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.3.7)\n","Requirement already satisfied: yellowbrick>=1.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (1.5)\n","Requirement already satisfied: plotly>=5.14.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (5.24.1)\n","Requirement already satisfied: kaleido>=0.2.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.4.1)\n","Requirement already satisfied: schemdraw==0.15 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.15)\n","Requirement already satisfied: plotly-resampler>=0.8.3.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.10.0)\n","Requirement already satisfied: statsmodels>=0.12.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.14.4)\n","Requirement already satisfied: sktime==0.26.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.26.0)\n","Requirement already satisfied: tbats>=1.1.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (1.1.3)\n","Requirement already satisfied: pmdarima>=2.0.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (2.0.4)\n","Requirement already satisfied: wurlitzer in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (3.1.1)\n","Requirement already satisfied: shap~=0.44.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.44.1)\n","Requirement already satisfied: interpret>=0.2.7 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.6.5)\n","Requirement already satisfied: umap-learn>=0.5.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.5.7)\n","Requirement already satisfied: pyyaml in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (6.0.2)\n","Requirement already satisfied: ydata-profiling>=4.3.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (4.12.0)\n","Requirement already satisfied: explainerdashboard>=0.3.8 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.4.7)\n","Requirement already satisfied: fairlearn==0.7.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.7.0)\n","Requirement already satisfied: kmodes>=0.11.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.12.2)\n","Requirement already satisfied: mlxtend>=0.19.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.23.3)\n","Requirement already satisfied: statsforecast<1.6.0,>=0.5.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (1.5.0)\n","Requirement already satisfied: hyperopt>=0.2.7 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.2.7)\n","Requirement already satisfied: optuna>=3.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (4.1.0)\n","Requirement already satisfied: optuna-integration in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (4.1.0)\n","Requirement already satisfied: scikit-optimize>=0.9.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.10.2)\n","Requirement already satisfied: mlflow>=2.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (2.18.0)\n","Requirement already satisfied: gradio>=3.50.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (5.6.0)\n","Requirement already satisfied: boto3>=1.24.56 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (1.35.63)\n","Requirement already satisfied: fastapi in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.115.5)\n","Requirement already satisfied: uvicorn>=0.17.6 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.32.0)\n","Requirement already satisfied: m2cgen>=0.9.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.10.0)\n","Requirement already satisfied: evidently~=0.4.16 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.4.39)\n","Requirement already satisfied: dask>=2024.4.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (2024.9.0)\n","Requirement already satisfied: distributed>=2024.4.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (2024.9.0)\n","Requirement already satisfied: fugue~=0.8.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.8.7)\n","Requirement already satisfied: flask in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (2.3.3)\n","Requirement already satisfied: Werkzeug<3.0,>=2.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (2.3.8)\n","Requirement already satisfied: pytest<8.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (7.4.4)\n","Requirement already satisfied: moto<5.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (4.2.14)\n","Requirement already satisfied: dash[testing] in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (2.18.2)\n","Requirement already satisfied: scikit-learn-intelex>=2023.0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (2025.0.0)\n","Requirement already satisfied: catboost>=0.23.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (1.2.7)\n","Requirement already satisfied: tune-sklearn>=0.2.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (0.5.0)\n","Requirement already satisfied: ray>=1.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ray[tune]>=1.0.0; (python_version != \"3.11\" and platform_system != \"Windows\") and extra == \"full\"->pycaret[full]) (2.39.0)\n","Requirement already satisfied: xgboost>=1.1.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pycaret[full]) (2.1.2)\n","Requirement already satisfied: packaging in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from sktime==0.26.0->pycaret[full]) (24.1)\n","Requirement already satisfied: scikit-base<0.8.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from sktime==0.26.0->pycaret[full]) (0.7.8)\n","Requirement already satisfied: botocore<1.36.0,>=1.35.63 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from boto3>=1.24.56->pycaret[full]) (1.35.63)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from boto3>=1.24.56->pycaret[full]) (1.0.1)\n","Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from boto3>=1.24.56->pycaret[full]) (0.10.3)\n","Requirement already satisfied: graphviz in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from catboost>=0.23.2->pycaret[full]) (0.20.3)\n","Requirement already satisfied: six in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from catboost>=0.23.2->pycaret[full]) (1.16.0)\n","Requirement already satisfied: patsy>=0.5.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from category-encoders>=2.4.0->pycaret[full]) (1.0.1)\n","Requirement already satisfied: click>=8.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask>=2024.4.1->pycaret[full]) (8.1.7)\n","Requirement already satisfied: fsspec>=2021.09.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask>=2024.4.1->pycaret[full]) (2024.10.0)\n","Requirement already satisfied: partd>=1.4.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask>=2024.4.1->pycaret[full]) (1.4.2)\n","Requirement already satisfied: toolz>=0.10.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask>=2024.4.1->pycaret[full]) (1.0.0)\n","Requirement already satisfied: locket>=1.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed>=2024.4.1->pycaret[full]) (1.0.0)\n","Requirement already satisfied: msgpack>=1.0.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed>=2024.4.1->pycaret[full]) (1.1.0)\n","Requirement already satisfied: sortedcontainers>=2.0.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed>=2024.4.1->pycaret[full]) (2.4.0)\n","Requirement already satisfied: tblib>=1.6.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed>=2024.4.1->pycaret[full]) (3.0.0)\n","Requirement already satisfied: tornado>=6.2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed>=2024.4.1->pycaret[full]) (6.4.1)\n","Requirement already satisfied: urllib3>=1.26.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed>=2024.4.1->pycaret[full]) (1.26.20)\n","Requirement already satisfied: zict>=3.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from distributed>=2024.4.1->pycaret[full]) (3.0.0)\n","Requirement already satisfied: nltk>=3.6.7 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from evidently~=0.4.16->pycaret[full]) (3.9.1)\n","Requirement already satisfied: pydantic>=1.10.13 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from evidently~=0.4.16->pycaret[full]) (2.9.2)\n","Requirement already satisfied: litestar>=2.8.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from evidently~=0.4.16->pycaret[full]) (2.12.1)\n","Requirement already satisfied: typing-inspect>=0.9.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from evidently~=0.4.16->pycaret[full]) (0.9.0)\n","Requirement already satisfied: watchdog>=3.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from evidently~=0.4.16->pycaret[full]) (6.0.0)\n","Requirement already satisfied: typer>=0.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from evidently~=0.4.16->pycaret[full]) (0.13.0)\n","Requirement already satisfied: rich>=13 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from evidently~=0.4.16->pycaret[full]) (13.9.4)\n","Requirement already satisfied: iterative-telemetry>=0.0.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from evidently~=0.4.16->pycaret[full]) (0.0.9)\n","Requirement already satisfied: dynaconf>=3.2.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from evidently~=0.4.16->pycaret[full]) (3.2.6)\n","Requirement already satisfied: certifi>=2024.7.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from evidently~=0.4.16->pycaret[full]) (2024.8.30)\n","Requirement already satisfied: ujson>=5.4.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from evidently~=0.4.16->pycaret[full]) (5.10.0)\n","Requirement already satisfied: uuid6>=2024.7.10 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from evidently~=0.4.16->pycaret[full]) (2024.7.10)\n","Requirement already satisfied: cryptography>=43.0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from evidently~=0.4.16->pycaret[full]) (43.0.3)\n","Requirement already satisfied: dash-auth in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (2.3.0)\n","Requirement already satisfied: dash-bootstrap-components>=1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (1.6.0)\n","Requirement already satisfied: dtreeviz>=2.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (2.2.2)\n","Requirement already satisfied: flask-simplelogin in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (0.2.0)\n","Requirement already satisfied: Flask-WTF>=1.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (1.2.2)\n","Requirement already satisfied: jupyter-dash>=0.4.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (0.4.2)\n","Requirement already satisfied: oyaml in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (1.0)\n","Requirement already satisfied: waitress in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (3.0.2)\n","Requirement already satisfied: triad>=0.9.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fugue~=0.8.0->pycaret[full]) (0.9.8)\n","Requirement already satisfied: adagio>=0.2.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fugue~=0.8.0->pycaret[full]) (0.2.6)\n","Requirement already satisfied: qpd>=0.4.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fugue~=0.8.0->pycaret[full]) (0.4.4)\n","Requirement already satisfied: fugue-sql-antlr>=0.1.6 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fugue~=0.8.0->pycaret[full]) (0.2.2)\n","Requirement already satisfied: sqlglot in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fugue~=0.8.0->pycaret[full]) (25.31.4)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (23.2.1)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (4.6.2)\n","Requirement already satisfied: ffmpy in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (0.4.0)\n","Requirement already satisfied: gradio-client==1.4.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (1.4.3)\n","Requirement already satisfied: httpx>=0.24.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (0.27.0)\n","Requirement already satisfied: huggingface-hub>=0.25.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (0.26.2)\n","Requirement already satisfied: orjson~=3.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (3.10.11)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (11.0.0)\n","Requirement already satisfied: pydub in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (0.25.1)\n","Requirement already satisfied: python-multipart==0.0.12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (0.0.12)\n","Requirement already satisfied: ruff>=0.2.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (0.7.4)\n","Requirement already satisfied: safehttpx<1.0,>=0.1.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (0.1.1)\n","Requirement already satisfied: semantic-version~=2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (2.10.0)\n","Requirement already satisfied: starlette<1.0,>=0.40.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (0.41.2)\n","Requirement already satisfied: tomlkit==0.12.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (0.12.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio>=3.50.2->pycaret[full]) (4.11.0)\n","Requirement already satisfied: websockets<13.0,>=10.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gradio-client==1.4.3->gradio>=3.50.2->pycaret[full]) (12.0)\n","Requirement already satisfied: networkx>=2.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from hyperopt>=0.2.7->pycaret[full]) (3.4.2)\n","Requirement already satisfied: future in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from hyperopt>=0.2.7->pycaret[full]) (1.0.0)\n","Requirement already satisfied: py4j in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from hyperopt>=0.2.7->pycaret[full]) (0.10.9.7)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from imbalanced-learn>=0.12.0->pycaret[full]) (3.5.0)\n","Requirement already satisfied: zipp>=3.20 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from importlib-metadata>=4.12.0->pycaret[full]) (3.21.0)\n","Requirement already satisfied: interpret-core==0.6.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.5->interpret>=0.2.7->pycaret[full]) (0.6.5)\n","Requirement already satisfied: aplr>=10.6.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.5->interpret>=0.2.7->pycaret[full]) (10.7.4)\n","Requirement already satisfied: ipykernel>=4.10.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.5->interpret>=0.2.7->pycaret[full]) (6.29.5)\n","Requirement already satisfied: SALib>=1.3.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.5->interpret>=0.2.7->pycaret[full]) (1.5.1)\n","Requirement already satisfied: dill>=0.2.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.5->interpret>=0.2.7->pycaret[full]) (0.3.9)\n","Requirement already satisfied: dash-core-components>=1.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.5->interpret>=0.2.7->pycaret[full]) (2.0.0)\n","Requirement already satisfied: dash-html-components>=1.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.5->interpret>=0.2.7->pycaret[full]) (2.0.0)\n","Requirement already satisfied: dash-table>=4.1.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.5->interpret>=0.2.7->pycaret[full]) (5.0.0)\n","Requirement already satisfied: dash-cytoscape>=0.1.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.5->interpret>=0.2.7->pycaret[full]) (1.0.2)\n","Requirement already satisfied: gevent>=1.3.6 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.5->interpret>=0.2.7->pycaret[full]) (24.11.1)\n","Requirement already satisfied: decorator in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret[full]) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret[full]) (0.19.1)\n","Requirement already satisfied: matplotlib-inline in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret[full]) (0.1.6)\n","Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret[full]) (3.0.43)\n","Requirement already satisfied: pygments>=2.4.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret[full]) (2.15.1)\n","Requirement already satisfied: stack-data in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret[full]) (0.2.0)\n","Requirement already satisfied: traitlets>=5.13.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret[full]) (5.14.3)\n","Requirement already satisfied: exceptiongroup in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret[full]) (1.2.0)\n","Requirement already satisfied: pexpect>4.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret[full]) (4.8.0)\n","Requirement already satisfied: comm>=0.1.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ipywidgets>=7.6.5->pycaret[full]) (0.2.1)\n","Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ipywidgets>=7.6.5->pycaret[full]) (4.0.13)\n","Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ipywidgets>=7.6.5->pycaret[full]) (3.0.13)\n","Requirement already satisfied: choreographer>=0.99.6 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from kaleido>=0.2.1->pycaret[full]) (0.99.6)\n","Requirement already satisfied: async-timeout in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from kaleido>=0.2.1->pycaret[full]) (5.0.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret[full]) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret[full]) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret[full]) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret[full]) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret[full]) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret[full]) (2.9.0.post0)\n","Requirement already satisfied: mlflow-skinny==2.18.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow>=2.0.0->pycaret[full]) (2.18.0)\n","Requirement already satisfied: alembic!=1.10.0,<2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow>=2.0.0->pycaret[full]) (1.14.0)\n","Requirement already satisfied: docker<8,>=4.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow>=2.0.0->pycaret[full]) (7.1.0)\n","Requirement already satisfied: graphene<4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow>=2.0.0->pycaret[full]) (3.4.3)\n","Requirement already satisfied: markdown<4,>=3.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow>=2.0.0->pycaret[full]) (3.7)\n","Requirement already satisfied: pyarrow<19,>=4.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow>=2.0.0->pycaret[full]) (17.0.0)\n","Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow>=2.0.0->pycaret[full]) (2.0.36)\n","Requirement already satisfied: gunicorn<24 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow>=2.0.0->pycaret[full]) (23.0.0)\n","Requirement already satisfied: cachetools<6,>=5.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (5.5.0)\n","Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (0.37.0)\n","Requirement already satisfied: gitpython<4,>=3.1.9 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (3.1.43)\n","Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (1.28.1)\n","Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (1.28.1)\n","Requirement already satisfied: protobuf<6,>=3.12.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (5.28.3)\n","Requirement already satisfied: sqlparse<1,>=0.4.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (0.5.2)\n","Requirement already satisfied: itsdangerous>=2.1.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from flask->pycaret[full]) (2.2.0)\n","Requirement already satisfied: blinker>=1.6.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from flask->pycaret[full]) (1.9.0)\n","Requirement already satisfied: xmltodict in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from moto<5.0.0->pycaret[full]) (0.14.2)\n","Requirement already satisfied: responses>=0.13.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from moto<5.0.0->pycaret[full]) (0.25.3)\n","Requirement already satisfied: fastjsonschema>=2.15 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from nbformat>=4.2.0->pycaret[full]) (2.16.2)\n","Requirement already satisfied: jsonschema>=2.6 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from nbformat>=4.2.0->pycaret[full]) (4.23.0)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from nbformat>=4.2.0->pycaret[full]) (5.7.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from numba>=0.55.0->pycaret[full]) (0.43.0)\n","Requirement already satisfied: colorlog in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from optuna>=3.0.0->pycaret[full]) (6.9.0)\n","Requirement already satisfied: pytz>=2020.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pandas<2.2.0->pycaret[full]) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pandas<2.2.0->pycaret[full]) (2024.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from plotly>=5.14.0->pycaret[full]) (9.0.0)\n","Requirement already satisfied: tsdownsample>=0.1.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from plotly-resampler>=0.8.3.1->pycaret[full]) (0.1.3)\n","Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pmdarima>=2.0.4->pycaret[full]) (3.0.11)\n","Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pmdarima>=2.0.4->pycaret[full]) (75.1.0)\n","Requirement already satisfied: iniconfig in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pytest<8.0.0->pycaret[full]) (2.0.0)\n","Requirement already satisfied: pluggy<2.0,>=0.12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pytest<8.0.0->pycaret[full]) (1.5.0)\n","Requirement already satisfied: tomli>=1.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pytest<8.0.0->pycaret[full]) (2.0.1)\n","Requirement already satisfied: filelock in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ray>=1.0.0->ray[tune]>=1.0.0; (python_version != \"3.11\" and platform_system != \"Windows\") and extra == \"full\"->pycaret[full]) (3.16.1)\n","Requirement already satisfied: aiosignal in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ray>=1.0.0->ray[tune]>=1.0.0; (python_version != \"3.11\" and platform_system != \"Windows\") and extra == \"full\"->pycaret[full]) (1.3.1)\n","Requirement already satisfied: frozenlist in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ray>=1.0.0->ray[tune]>=1.0.0; (python_version != \"3.11\" and platform_system != \"Windows\") and extra == \"full\"->pycaret[full]) (1.5.0)\n","Requirement already satisfied: tensorboardX>=1.9 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ray[tune]>=1.0.0; (python_version != \"3.11\" and platform_system != \"Windows\") and extra == \"full\"->pycaret[full]) (2.6.2.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from requests>=2.27.1->pycaret[full]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from requests>=2.27.1->pycaret[full]) (3.7)\n","Requirement already satisfied: daal==2025.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from scikit-learn-intelex>=2023.0.1->pycaret[full]) (2025.0.0)\n","Requirement already satisfied: tbb==2022.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from daal==2025.0.0->scikit-learn-intelex>=2023.0.1->pycaret[full]) (2022.0.0)\n","Requirement already satisfied: tcmlib==1.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from tbb==2022.*->daal==2025.0.0->scikit-learn-intelex>=2023.0.1->pycaret[full]) (1.2.0)\n","Requirement already satisfied: pyaml>=16.9 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from scikit-optimize>=0.9.0->pycaret[full]) (24.9.0)\n","Requirement already satisfied: slicer==0.0.7 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from shap~=0.44.0->pycaret[full]) (0.0.7)\n","Requirement already satisfied: pynndescent>=0.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from umap-learn>=0.5.2->pycaret[full]) (0.5.13)\n","Requirement already satisfied: h11>=0.8 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from uvicorn>=0.17.6->pycaret[full]) (0.14.0)\n","Requirement already satisfied: nvidia-nccl-cu12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from xgboost>=1.1.0->pycaret[full]) (2.23.4)\n","Requirement already satisfied: visions<0.7.7,>=0.7.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling>=4.3.1->pycaret[full]) (0.7.6)\n","Requirement already satisfied: htmlmin==0.1.12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.1.12)\n","Requirement already satisfied: phik<0.13,>=0.11.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.12.4)\n","Requirement already satisfied: seaborn<0.14,>=0.10.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.13.2)\n","Requirement already satisfied: multimethod<2,>=1.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.12)\n","Requirement already satisfied: typeguard<5,>=3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (4.4.1)\n","Requirement already satisfied: imagehash==4.3.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (4.3.1)\n","Requirement already satisfied: wordcloud>=1.9.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.9.4)\n","Requirement already satisfied: dacite>=1.8 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.8.1)\n","Requirement already satisfied: PyWavelets in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from imagehash==4.3.1->ydata-profiling>=4.3.1->pycaret[full]) (1.7.0)\n","Requirement already satisfied: retrying in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (1.3.4)\n","Requirement already satisfied: nest-asyncio in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (1.6.0)\n","Requirement already satisfied: beautifulsoup4>=4.8.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (4.12.3)\n","Requirement already satisfied: lxml>=4.6.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (5.3.0)\n","Requirement already satisfied: percy>=2.0.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (2.0.2)\n","Requirement already satisfied: selenium<=4.2.0,>=3.141.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (4.2.0)\n","Requirement already satisfied: multiprocess>=0.70.12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (0.70.17)\n","Requirement already satisfied: dash-testing-stub>=0.0.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (0.0.2)\n","Requirement already satisfied: Mako in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow>=2.0.0->pycaret[full]) (1.3.6)\n","Requirement already satisfied: sniffio>=1.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio>=3.50.2->pycaret[full]) (1.3.0)\n","Requirement already satisfied: soupsieve>1.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from beautifulsoup4>=4.8.2->dash[testing]; extra == \"full\"->pycaret[full]) (2.5)\n","Requirement already satisfied: cffi>=1.12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cryptography>=43.0.1->evidently~=0.4.16->pycaret[full]) (1.17.1)\n","Requirement already satisfied: dask-expr<1.2,>=1.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dask[dataframe,distributed]>=2023.5.0; extra == \"dask\"->fugue[dask]; extra == \"full\"->pycaret[full]) (1.1.14)\n","Requirement already satisfied: colour in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from dtreeviz>=2.1->explainerdashboard>=0.3.8->pycaret[full]) (0.1.5)\n","Requirement already satisfied: wtforms in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from Flask-WTF>=1.1->explainerdashboard>=0.3.8->pycaret[full]) (3.2.1)\n","Requirement already satisfied: antlr4-python3-runtime<4.12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fugue-sql-antlr>=0.1.6->fugue~=0.8.0->pycaret[full]) (4.11.1)\n","Requirement already satisfied: graphql-core<3.3,>=3.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from graphene<4->mlflow>=2.0.0->pycaret[full]) (3.2.5)\n","Requirement already satisfied: graphql-relay<3.3,>=3.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from graphene<4->mlflow>=2.0.0->pycaret[full]) (3.2.0)\n","Requirement already satisfied: httpcore==1.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=3.50.2->pycaret[full]) (1.0.2)\n","Requirement already satisfied: appdirs in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from iterative-telemetry>=0.0.5->evidently~=0.4.16->pycaret[full]) (1.4.4)\n","Requirement already satisfied: distro in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from iterative-telemetry>=0.0.5->evidently~=0.4.16->pycaret[full]) (1.9.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from jedi>=0.16->ipython>=5.5.0->pycaret[full]) (0.8.3)\n","Requirement already satisfied: attrs>=22.2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (0.10.6)\n","Requirement already satisfied: platformdirs>=2.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret[full]) (3.10.0)\n","Requirement already satisfied: ansi2html in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from jupyter-dash>=0.4.1->explainerdashboard>=0.3.8->pycaret[full]) (1.9.2)\n","Requirement already satisfied: msgspec>=0.18.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (0.18.6)\n","Requirement already satisfied: multidict>=6.0.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (6.1.0)\n","Requirement already satisfied: polyfactory>=2.6.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (2.18.0)\n","Requirement already satisfied: rich-click in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (1.8.4)\n","Requirement already satisfied: regex>=2021.8.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from nltk>=3.6.7->evidently~=0.4.16->pycaret[full]) (2024.11.6)\n","Requirement already satisfied: ptyprocess>=0.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pexpect>4.3->ipython>=5.5.0->pycaret[full]) (0.7.0)\n","Requirement already satisfied: wcwidth in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.5.0->pycaret[full]) (0.2.5)\n","Requirement already satisfied: annotated-types>=0.6.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pydantic>=1.10.13->evidently~=0.4.16->pycaret[full]) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pydantic>=1.10.13->evidently~=0.4.16->pycaret[full]) (2.23.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from rich>=13->evidently~=0.4.16->pycaret[full]) (3.0.0)\n","Requirement already satisfied: trio~=0.17 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (0.27.0)\n","Requirement already satisfied: trio-websocket~=0.9 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (0.11.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.0.0->pycaret[full]) (3.1.1)\n","Requirement already satisfied: fs in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from triad>=0.9.3->fugue~=0.8.0->pycaret[full]) (2.4.16)\n","Requirement already satisfied: shellingham>=1.3.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from typer>=0.3->evidently~=0.4.16->pycaret[full]) (1.5.4)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from typing-inspect>=0.9.0->evidently~=0.4.16->pycaret[full]) (1.0.0)\n","Requirement already satisfied: httptools>=0.5.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from uvicorn[standard]>=0.22.0->evidently~=0.4.16->pycaret[full]) (0.6.4)\n","Requirement already satisfied: python-dotenv>=0.13 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from uvicorn[standard]>=0.22.0->evidently~=0.4.16->pycaret[full]) (1.0.1)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from uvicorn[standard]>=0.22.0->evidently~=0.4.16->pycaret[full]) (0.21.0)\n","Requirement already satisfied: watchfiles>=0.13 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from uvicorn[standard]>=0.22.0->evidently~=0.4.16->pycaret[full]) (0.24.0)\n","Requirement already satisfied: executing in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from stack-data->ipython>=5.5.0->pycaret[full]) (0.8.3)\n","Requirement already satisfied: asttokens in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from stack-data->ipython>=5.5.0->pycaret[full]) (2.0.5)\n","Requirement already satisfied: pure-eval in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from stack-data->ipython>=5.5.0->pycaret[full]) (0.2.2)\n","Requirement already satisfied: pycparser in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=43.0.1->evidently~=0.4.16->pycaret[full]) (2.21)\n","Requirement already satisfied: google-auth~=2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (2.36.0)\n","Requirement already satisfied: zope.event in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.5->interpret>=0.2.7->pycaret[full]) (5.0)\n","Requirement already satisfied: zope.interface in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.5->interpret>=0.2.7->pycaret[full]) (7.1.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (4.0.11)\n","Requirement already satisfied: debugpy>=1.6.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.5->interpret>=0.2.7->pycaret[full]) (1.6.7)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.5->interpret>=0.2.7->pycaret[full]) (8.6.0)\n","Requirement already satisfied: pyzmq>=24 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.5->interpret>=0.2.7->pycaret[full]) (25.1.2)\n","Requirement already satisfied: mdurl~=0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13->evidently~=0.4.16->pycaret[full]) (0.1.2)\n","Requirement already satisfied: deprecated>=1.2.6 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (1.2.15)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.49b1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (0.49b1)\n","Requirement already satisfied: faker in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from polyfactory>=2.6.3->litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (33.0.0)\n","Requirement already satisfied: outcome in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from trio~=0.17->selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (1.3.0.post0)\n","Requirement already satisfied: wsproto>=0.14 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from trio-websocket~=0.9->selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (1.2.0)\n","Requirement already satisfied: pyOpenSSL>=0.14 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from urllib3[secure,socks]~=1.26->selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (24.2.1)\n","Requirement already satisfied: urllib3-secure-extra in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from urllib3[secure,socks]~=1.26->selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (0.1.0)\n","Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from urllib3[secure,socks]~=1.26->selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (1.7.1)\n","Requirement already satisfied: wrapt<2,>=1.10 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (1.16.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (5.0.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (4.9)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow>=2.0.0->pycaret[full]) (0.6.1)\n","Requirement already satisfied: scikit-learn-intelex in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (2025.0.0)\n","Requirement already satisfied: daal==2025.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from scikit-learn-intelex) (2025.0.0)\n","Requirement already satisfied: numpy>=1.19 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from scikit-learn-intelex) (1.24.4)\n","Requirement already satisfied: scikit-learn>=0.22 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from scikit-learn-intelex) (1.4.2)\n","Requirement already satisfied: tbb==2022.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from daal==2025.0.0->scikit-learn-intelex) (2022.0.0)\n","Requirement already satisfied: tcmlib==1.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from tbb==2022.*->daal==2025.0.0->scikit-learn-intelex) (1.2.0)\n","Requirement already satisfied: scipy>=1.6.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.11.4)\n","Requirement already satisfied: joblib>=1.2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from scikit-learn>=0.22->scikit-learn-intelex) (3.5.0)\n","Requirement already satisfied: mlflow in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (2.18.0)\n","Requirement already satisfied: pyngrok in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (7.2.1)\n","Requirement already satisfied: fastapi[all] in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (0.115.5)\n","Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fastapi[all]) (0.41.2)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fastapi[all]) (2.9.2)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fastapi[all]) (4.11.0)\n","Requirement already satisfied: fastapi-cli>=0.0.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (0.0.5)\n","Requirement already satisfied: httpx>=0.23.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fastapi[all]) (0.27.0)\n","Requirement already satisfied: jinja2>=2.11.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fastapi[all]) (3.1.4)\n","Requirement already satisfied: python-multipart>=0.0.7 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fastapi[all]) (0.0.12)\n","Requirement already satisfied: itsdangerous>=1.1.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fastapi[all]) (2.2.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fastapi[all]) (6.0.2)\n","Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fastapi[all]) (5.10.0)\n","Requirement already satisfied: orjson>=3.2.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fastapi[all]) (3.10.11)\n","Requirement already satisfied: email-validator>=2.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fastapi[all]) (2.2.0)\n","Requirement already satisfied: uvicorn>=0.12.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all]) (0.32.0)\n","Requirement already satisfied: pydantic-settings>=2.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fastapi[all]) (2.6.1)\n","Requirement already satisfied: pydantic-extra-types>=2.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fastapi[all]) (2.10.0)\n","Requirement already satisfied: mlflow-skinny==2.18.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow) (2.18.0)\n","Requirement already satisfied: Flask<4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow) (2.3.3)\n","Requirement already satisfied: alembic!=1.10.0,<2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow) (1.14.0)\n","Requirement already satisfied: docker<8,>=4.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow) (7.1.0)\n","Requirement already satisfied: graphene<4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow) (3.4.3)\n","Requirement already satisfied: markdown<4,>=3.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow) (3.7)\n","Requirement already satisfied: matplotlib<4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow) (3.7.5)\n","Requirement already satisfied: numpy<3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow) (1.24.4)\n","Requirement already satisfied: pandas<3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow) (2.1.4)\n","Requirement already satisfied: pyarrow<19,>=4.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow) (17.0.0)\n","Requirement already satisfied: scikit-learn<2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow) (1.4.2)\n","Requirement already satisfied: scipy<2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow) (1.11.4)\n","Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow) (2.0.36)\n","Requirement already satisfied: gunicorn<24 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow) (23.0.0)\n","Requirement already satisfied: cachetools<6,>=5.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (5.5.0)\n","Requirement already satisfied: click<9,>=7.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (8.1.7)\n","Requirement already satisfied: cloudpickle<4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.0)\n","Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (0.37.0)\n","Requirement already satisfied: gitpython<4,>=3.1.9 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.43)\n","Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (8.5.0)\n","Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.1)\n","Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.1)\n","Requirement already satisfied: packaging<25 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (24.1)\n","Requirement already satisfied: protobuf<6,>=3.12.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (5.28.3)\n","Requirement already satisfied: requests<3,>=2.17.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (2.32.3)\n","Requirement already satisfied: sqlparse<1,>=0.4.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (0.5.2)\n","Requirement already satisfied: Mako in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.6)\n","Requirement already satisfied: urllib3>=1.26.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.20)\n","Requirement already satisfied: dnspython>=2.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from email-validator>=2.0.0->fastapi[all]) (2.7.0)\n","Requirement already satisfied: idna>=2.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from email-validator>=2.0.0->fastapi[all]) (3.7)\n","Requirement already satisfied: typer>=0.12.3 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (0.13.0)\n","Requirement already satisfied: Werkzeug>=2.3.7 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from Flask<4->mlflow) (2.3.8)\n","Requirement already satisfied: blinker>=1.6.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from Flask<4->mlflow) (1.9.0)\n","Requirement already satisfied: graphql-core<3.3,>=3.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.5)\n","Requirement already satisfied: graphql-relay<3.3,>=3.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.0)\n","Requirement already satisfied: python-dateutil<3,>=2.7.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n","Requirement already satisfied: anyio in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi[all]) (4.6.2)\n","Requirement already satisfied: certifi in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi[all]) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi[all]) (1.0.2)\n","Requirement already satisfied: sniffio in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi[all]) (1.3.0)\n","Requirement already satisfied: h11<0.15,>=0.13 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[all]) (0.14.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from jinja2>=2.11.2->fastapi[all]) (2.1.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<4->mlflow) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.2.0)\n","Requirement already satisfied: pytz>=2020.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pandas<3->mlflow) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pandas<3->mlflow) (2024.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (2.23.4)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pydantic-settings>=2.0.0->fastapi[all]) (1.0.1)\n","Requirement already satisfied: joblib>=1.2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (3.5.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n","Requirement already satisfied: httptools>=0.5.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all]) (0.6.4)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all]) (0.21.0)\n","Requirement already satisfied: watchfiles>=0.13 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all]) (0.24.0)\n","Requirement already satisfied: websockets>=10.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all]) (12.0)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from anyio->httpx>=0.23.0->fastapi[all]) (1.2.0)\n","Requirement already satisfied: google-auth~=2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (2.36.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (4.0.11)\n","Requirement already satisfied: zipp>=3.20 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow) (3.21.0)\n","Requirement already satisfied: deprecated>=1.2.6 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.2.15)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.49b1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (0.49b1)\n","Requirement already satisfied: six>=1.5 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.3.2)\n","Requirement already satisfied: shellingham>=1.3.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (13.9.4)\n","Requirement already satisfied: wrapt<2,>=1.10 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.16.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (5.0.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (4.9)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (2.15.1)\n","Requirement already satisfied: mdurl~=0.1 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (0.1.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/dannel/miniconda3/envs/colab/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.6.1)\n"]}]},{"cell_type":"markdown","source":["### Imports and data connectivity"],"metadata":{"id":"GIrEqfHM2kzn"}},{"cell_type":"code","source":["# All import statements should be upfront so that it is easy to\n","# track what are required\n","\n","# ## Import the following packages\n","import datetime\n","import swifter\n","import mlflow\n","import mlflow.data\n","from mlflow.data.pandas_dataset import PandasDataset\n","import pandas as pd\n","import numpy as np\n","import plotly.express as px\n","import seaborn as sns\n","from tqdm.notebook import tqdm, tnrange\n","from pathlib import Path\n","from pydantic import BaseModel\n","from ydata_profiling import ProfileReport\n","from pycaret.regression import RegressionExperiment\n","from pycaret.classification import ClassificationExperiment\n","from pycaret.clustering import ClusteringExperiment"],"metadata":{"id":"F4fsJ4cn29ea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Connect to data folder\n","try:\n","    from google.colab import userdata\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    data_dir = Path('/content/drive/MyDrive/pcml_data')\n","    mlrun_dir = Path('/content/drive/MyDrive/logs/mlruns')\n","    models_dir = Path('/content/drive/MyDrive/Colab Notebooks/models')\n","\n","except (NotImplementedError, ModuleNotFoundError):\n","    data_dir = Path('data')\n","    mlrun_dir = Path('logs/mlruns')\n","    models_dir = Path('models')\n","\n","else:\n","    print(f'Using Colab...')\n","\n","finally:\n","    if not mlrun_dir.exists():\n","        mlrun_dir.mkdir(parents=True)\n","    mlflow.set_tracking_uri(mlrun_dir)"],"metadata":{"id":"snG43ZJTTkkO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Additional imports"],"metadata":{"id":"wLUGZmH2zIWT"}},{"cell_type":"code","source":["# For this exercise, we require these additional packages\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","from string import punctuation\n","from scipy.sparse import csr_matrix\n","from sklearn.preprocessing import Normalizer, MaxAbsScaler, MinMaxScaler\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import LatentDirichletAllocation, PCA, NMF\n","from sklearn.pipeline import make_pipeline\n","from matplotlib import pyplot as plt\n","from pycaret.classification import ClassificationExperiment\n","\n","# Punkt contains the dictionaries for stemming\n","nltk.download('punkt_tab')\n","\n","# stopwords contains the dictionaries for stop words\n","nltk.download('stopwords')\n","\n","# Wordnet contains the dictionaries for lemmatizing\n","nltk.download('wordnet')\n","\n","# Setup data path\n","data_path = Path('data')"],"metadata":{"id":"PRb_KWamqINQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732545560766,"user_tz":-480,"elapsed":996,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"outputId":"ad067d1d-7e32-4eaf-c533-fedf01950a4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /home/dannel/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package stopwords to /home/dannel/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /home/dannel/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"markdown","metadata":{"id":"xjoSRcSd79kw"},"source":["#### Case Study - Netflix & Chill\n","\n","In this exercise, you are given 9957 netflix titles with various features.\n","\n","Your tasks:\n","1. Convert the features into a layout that ML models can use.\n","2. Convert the description into a set of features that ML models can use.\n","3. Perform a SML on the rating\n","4. Create a recommender system that recommends 10 movies to an user after receiving an input for 3 movies that they like."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"di7Ou9ys79kw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732545560874,"user_tz":-480,"elapsed":107,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"outputId":"b6ad70bc-f933-4438-feff-a80afb2a1b21"},"outputs":[{"output_type":"stream","name":"stdout","text":["                    title         year certificate duration  \\\n","0               Cobra Kai     (2018 )       TV-14   30 min   \n","1               The Crown     (2016 )       TV-MA   58 min   \n","2        Better Call Saul  (20152022)       TV-MA   46 min   \n","3           Devil in Ohio       (2022)       TV-MA  356 min   \n","4  Cyberpunk: Edgerunners     (2022 )       TV-MA   24 min   \n","\n","                          genre  rating  \\\n","0         Action, Comedy, Drama     8.5   \n","1     Biography, Drama, History     8.7   \n","2                  Crime, Drama     8.9   \n","3        Drama, Horror, Mystery     5.9   \n","4  Animation, Action, Adventure     8.6   \n","\n","                                         description  \\\n","0  Decades after their 1984 All Valley Karate Tou...   \n","1  Follows the political rivalries and romance of...   \n","2  The trials and tribulations of criminal lawyer...   \n","3  When a psychiatrist shelters a mysterious cult...   \n","4  A Street Kid trying to survive in a technology...   \n","\n","                                               stars    votes  \n","0  ['Ralph Macchio, ', 'William Zabka, ', 'Courtn...  177,031  \n","1  ['Claire Foy, ', 'Olivia Colman, ', 'Imelda St...  199,885  \n","2  ['Bob Odenkirk, ', 'Rhea Seehorn, ', 'Jonathan...  501,384  \n","3  ['Emily Deschanel, ', 'Sam Jaeger, ', 'Gerardo...    9,773  \n","4  ['Zach Aguilar, ', 'Kenichiro Ohashi, ', 'Emi ...   15,413  \n"]}],"source":["# Load the netflix dataset\n","netflix = pd.read_csv(data_dir / '6USML/netflix_movies.csv')\n","print(netflix.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gjpCgBxC79kw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732545560879,"user_tz":-480,"elapsed":4,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"outputId":"886fa466-c0f5-4e10-9a27-3dd7daa3fb0e"},"outputs":[{"output_type":"stream","name":"stdout","text":["0    2018\n","1    2016\n","2    2015\n","3    2022\n","4    2022\n","Name: year, dtype: object\n"]}],"source":["# Convert the year feature into just the starting year\n","netflix['year'] = netflix.year.str.extract(r'(\\d{4})')\n","print(netflix['year'].head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIpfrGPo79kw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732545560886,"user_tz":-480,"elapsed":6,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"outputId":"c19692b4-1989-4660-bcf5-4571da43d73b"},"outputs":[{"output_type":"stream","name":"stdout","text":["19     NaN\n","67     NaN\n","77     NaN\n","168    NaN\n","199    NaN\n","Name: duration, dtype: object\n","0     30 min\n","1     58 min\n","2     46 min\n","3    356 min\n","4     24 min\n","Name: duration, dtype: object\n"]}],"source":["# Filter the rows for missing values in duration\n","netflix_duration_na = netflix[netflix.duration.isna()]\n","print(netflix_duration_na['duration'].head())\n","netflix_duration_not_na = netflix[netflix.duration.notna()]\n","print(netflix_duration_not_na['duration'].head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2xYC7O8s79kw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732545560937,"user_tz":-480,"elapsed":32,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"outputId":"f040304b-ba42-48bb-b6e7-1bbdce05d785"},"outputs":[{"output_type":"stream","name":"stdout","text":["74 min\n","                    title  year certificate  duration  \\\n","0               Cobra Kai  2018       TV-14        30   \n","1               The Crown  2016       TV-MA        58   \n","2        Better Call Saul  2015       TV-MA        46   \n","3           Devil in Ohio  2022       TV-MA       356   \n","4  Cyberpunk: Edgerunners  2022       TV-MA        24   \n","\n","                          genre  rating  \\\n","0         Action, Comedy, Drama     8.5   \n","1     Biography, Drama, History     8.7   \n","2                  Crime, Drama     8.9   \n","3        Drama, Horror, Mystery     5.9   \n","4  Animation, Action, Adventure     8.6   \n","\n","                                         description  \\\n","0  Decades after their 1984 All Valley Karate Tou...   \n","1  Follows the political rivalries and romance of...   \n","2  The trials and tribulations of criminal lawyer...   \n","3  When a psychiatrist shelters a mysterious cult...   \n","4  A Street Kid trying to survive in a technology...   \n","\n","                                               stars    votes  \n","0  ['Ralph Macchio, ', 'William Zabka, ', 'Courtn...  177,031  \n","1  ['Claire Foy, ', 'Olivia Colman, ', 'Imelda St...  199,885  \n","2  ['Bob Odenkirk, ', 'Rhea Seehorn, ', 'Jonathan...  501,384  \n","3  ['Emily Deschanel, ', 'Sam Jaeger, ', 'Gerardo...    9,773  \n","4  ['Zach Aguilar, ', 'Kenichiro Ohashi, ', 'Emi ...   15,413  \n"]}],"source":["import math\n","# Should we drop the column or fill in the missing values?\n","# ## We can fill in the missing values with the mean value\n","\n","duration_without_mins = netflix_duration_not_na['duration'].copy().str.replace(' min', '').astype(int)\n","duration_mean = str(math.ceil(duration_without_mins.mean()))  + ' min'\n","print(duration_mean)\n","netflix.duration.fillna(duration_mean, inplace=True)\n","# ## We can drop the column\n","# netflix_no_duration = netflix.drop(columns=['duration'])\n","# print(netflix_no_duration.head())\n","\n","# remove \" min\" from duration column\n","netflix['duration'] = netflix['duration'].str.replace(' min', '', regex=False).astype(int)\n","print(netflix.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LkgeTifU79kw"},"outputs":[],"source":["# # Split the genre into multiple columns\n","# split_genres_df = netflix_no_duration['genre'].str.split(', ', expand=True)\n","\n","# Extract the genre into a separate dataframe using the method explode\n","exploded_df = netflix.assign(genre_type=netflix['genre'].str.split(', ')).explode('genre_type')\n","\n","# Think of a way to indicate 1 for every genre that each title belongs to\n","genre_one_hot_df = pd.get_dummies(exploded_df['genre_type'])\n","genre_indicators_df = pd.concat([exploded_df[['title']], genre_one_hot_df], axis=1)\n","\n","# map for title and its hash\n","mapping = pd.DataFrame({\n","    'title': netflix['title'],\n","    'hash': [hash(title) for title in netflix['title']]\n","})\n","\n","# to use as index instead of title\n","genre_indicators_df['title'] = genre_indicators_df['title'].apply(hash)\n","# # Combine rows by title, taking the maximum value for each column\n","combined_df = genre_indicators_df.groupby('title', sort=False).max().astype(int)\n","\n","# # Reset index (optional, to make Title a regular column again)\n","combined_df.reset_index(inplace=True)\n","\n","hash_to_title = dict(zip(mapping['hash'], mapping['title']))\n","combined_df['title'] = combined_df['title'].map(hash_to_title)\n","\n","# Don't concat it to the netflix df yet"]},{"cell_type":"code","source":["# exploded_df['genre_type']\n","# netflix\n","\n","# Concat combined_df with netflix df on the column title and drop the genre column\n","# netflix_with_genre = pd.merge(netflix, combined_df, on='title', how='left')\n","\n","# # drop the genre column\n","# netflix_with_genre = netflix_with_genre.drop(columns=['genre'])\n","\n","# # remove the text ' min' from the column duration\n","# netflix_with_genre['duration'] = netflix_with_genre['duration'].str.replace(' min', '', regex=False).astype(int)\n","\n","# # convert the column rating to float\n","# netflix_with_genre['rating'] = netflix_with_genre['rating'].astype(float)\n","\n","# # convert the column votes from the string format x,xxx to float\n","# netflix_with_genre['votes'] = netflix_with_genre['votes'].str.replace(',', '').astype(float)\n","\n","# # convert the column year to int\n","# netflix_with_genre['year'] = netflix_with_genre['year'].astype(float)\n","\n","\n","# # save netflix_with_genre to csv\n","# netflix_with_genre.to_csv('netflix_with_genre.csv', index=False)"],"metadata":{"id":"kw9JjtMPJoXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cLWujfHI79kw","executionInfo":{"status":"ok","timestamp":1732545561274,"user_tz":-480,"elapsed":237,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a4bec36e-857d-4ad7-a1b7-9d2951f866d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of unique names: 23993\n"]}],"source":["# Do the same for the stars\n","# Check the number of columns that it will generate\n","\n","# clean\n","df_stars = netflix.copy();\n","\n","df_stars['stars'] = df_stars['stars'].str.replace(r\"\\|\\s*\", \",\", regex=True)\n","df_stars['stars'] = df_stars['stars'].str.replace(\"','\", \"\", regex=False).str.replace(\"', '\", \", \", regex=False).str.strip()\n","\n","# Clean the 'stars' column\n","df_stars['stars'] = df_stars['stars'].str.replace(r\",\\s*,\", \",\", regex=True)  # Remove ', ,'\n","df_stars['stars'] = df_stars['stars'].str.replace(r\"\\[\\s*'\\s*|\\s*'\\s*\\]\", \"\", regex=True)  # Remove surrounding brackets and quotes\n","df_stars['stars'] = df_stars['stars'].str.replace(r\"', '    Stars:\", \"\", regex=True)  # Normalize 'Stars:' formatting\n","df_stars['stars'] = df_stars['stars'].str.replace(r\", '    Stars:\", \"\", regex=True)  # Normalize 'Stars:' formatting\n","df_stars['stars'] = df_stars['stars'].str.replace(r\" \\\", '\", \"\", regex=True)\n","df_stars['stars'] = df_stars['stars'].str.replace(r\" '    Star:',\", \"\", regex=True)\n","df_stars['stars'] = df_stars['stars'].str.replace(r\"', '    Star:\", \"\", regex=True)\n","df_stars['stars'] = df_stars['stars'].str.replace(r\"[\\[\\]]\", \"\", regex=True)  # Remove square brackets\n","df_stars['stars'] = df_stars['stars'].str.replace('\"', \"\", regex=False)  # Remove double quotes\n","\n","df_stars['stars'] = df_stars['stars'].str.strip()  # Remove leading/trailing spaces\n","\n","# Extract the stars into a separate dataframe using the method explode\n","exploded_stars_df = df_stars.assign(star_name=df_stars['stars'].str.split(', ')).explode('star_name')\n","\n","# Count the number of unique names\n","unique_name_count = exploded_stars_df['star_name'].nunique()\n","\n","# Output the result\n","print(f\"Number of unique names: {unique_name_count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2sYwMN3a79kw"},"outputs":[],"source":["# Given that there are 27k+ stars, we should consider decomposition techniques\n","# and represent each firm with a few latent features\n","\n","# Should we have 1 NMF for stars + genre or individual NMFs for stars and genre?\n","# Think about how latent features are generated, and the possibility of interactions between stars and genres"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BOgE30pv79kw","executionInfo":{"status":"ok","timestamp":1732545562098,"user_tz":-480,"elapsed":821,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5935a01c-bbfc-4535-c2eb-3942f30e8217"},"outputs":[{"output_type":"stream","name":"stdout","text":["nmf_feature_0: peter, navarro, manuel, lvaro, music, family, sport, history, biography, drama\n","nmf_feature_1: mike, paul, james, van, david, chris, john, michael, family, comedy\n","nmf_feature_2: anthony, scott, ben, chris, james, david, fi, sci, adventure, action\n","nmf_feature_3: peter, john, david, michael, music, sport, history, biography, short, documentary\n","nmf_feature_4: kana, kino, jun, greg, yki, fantasy, adventure, short, family, animation\n","nmf_feature_5: brian, ben, clarkson, hammond, jeremy, james, richard, game, reality, tv\n","nmf_feature_6: kang, yki, jung, park, ji, min, jin, kim, lee, romance\n","nmf_feature_7: jakob, eklund, antonia, jason, ella, john, action, tom, robert, thriller\n","nmf_feature_8: daniel, adam, alejandro, amit, anu, michael, robert, action, mystery, crime\n","nmf_feature_9: adam, mehmet, david, kim, lee, sci, fi, fantasy, mystery, horror\n"]}],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import NMF\n","from sklearn.pipeline import Pipeline\n","import pandas as pd\n","\n","# Perform NMF on your choice of stars and genre\n","netflix_nmf = df_stars.copy() # star list is cleaned already\n","\n","# Combine 'stars' and 'genre' columns for textual analysis\n","netflix_nmf['combined_text'] = netflix_nmf['stars'] + ' ' + netflix_nmf['genre']\n","\n","# Clean and prepare the text\n","netflix_nmf['combined_text'] = netflix_nmf['combined_text'].fillna('').str.lower()\n","\n","# What is the scaler that you should use?\n","# scaler needed to convert data to be non-negative\n","# apply td-idf which already produces non negative\n","# td-idf transforms raw text  it transforms raw text into a numerical matrix that\n","# effectively represents the importance of terms within a document while reducing noise\n","# from overly common terms.\n","\n","# Vectorize the combined text using TF-IDF\n","vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n","tfidf_matrix = vectorizer.fit_transform(netflix_nmf['combined_text'])\n","\n","# How many components should we use?\n","# trial and error to see if topics make sense. dont want to oversimply or overcomplicate\n","# Topic 6: kang, yki, jung, park, ji, min, jin, kim, lee, romance eg. this is good\n","# but dont want to link all korean sounding names to romance\n","\n","n_components = 10  # Number of latent features/topics\n","nmf_model = NMF(n_components=n_components, random_state=42)\n","nmf_features = nmf_model.fit_transform(tfidf_matrix)\n","\n","# Display top words for each topic\n","feature_names = vectorizer.get_feature_names_out()\n","for topic_idx, topic in enumerate(nmf_model.components_):\n","    top_features = [feature_names[i] for i in topic.argsort()[-10:]]\n","    print(f\"nmf_feature_{topic_idx}: {', '.join(top_features)}\")\n","\n","# Create the pipeline and apply it to the dataframe\n","\n","# Add NMF features to the dataframe\n","for i in range(n_components):\n","    netflix_nmf[f'nmf_feature_{i+1}'] = nmf_features[:, i]\n","\n","# Create a pipeline with TF-IDF vectorizer and NMF (no idea what to do with this)\n","combined_text_pipeline = Pipeline([\n","    ('tfidf', TfidfVectorizer(max_features=1000, stop_words='english')),\n","    ('nmf', NMF(n_components=5, random_state=42))\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2crPBpK979kw"},"outputs":[],"source":["# Combine the NMF features with the original dataframe\n","# Drop genre and stars columns\n","netflix_genre_star_nmf_feature = netflix_nmf.drop(columns=['genre', 'stars','combined_text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"15msNUis79kw"},"outputs":[],"source":["# Observe that there's other features such as year and votes (and duration if you didn't drop it)\n","# Should we have combined all these and NMF them together?\n","# Consider the implications:\n","#   1. interactions between these features (interpretability)\n","#   2. how would you scale these features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qi-zdVFe79kw"},"outputs":[],"source":["# Lastly, we need to NMF the description\n","# Extract the descriptions and clean it\n","df_des = netflix_nmf.copy()\n","df_des['description'] = df_des['description'].str.lower()\n","df_des['description'] = df_des['description'].str.replace(r\"\\|\\s*\", \",\", regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0P6LqTh-79kx","executionInfo":{"status":"ok","timestamp":1732545562889,"user_tz":-480,"elapsed":733,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"344025a4-f3b6-4664-c34b-9954dd715871"},"outputs":[{"output_type":"stream","name":"stdout","text":["nmf_desc_feature_0: victor, did, mystery, game, adaptation, kept, unknown, wraps, plot, add\n","nmf_desc_feature_1: years, girl, mother, father, murder, past, mysterious, woman, man, young\n","nmf_desc_feature_2: save, journey, ii, people, look, documentary, war, series, summary, world\n","nmf_desc_feature_3: work, time, follows, personal, changing, documentary, death, career, real, life\n","nmf_desc_feature_4: town, goes, james, summary, jeremy, takes, team, city, york, new\n","nmf_desc_feature_5: teenage, girl, students, student, group, summary, best, friends, high, school\n","nmf_desc_feature_6: finds, christmas, house, tries, mother, daughter, lives, father, home, family\n","nmf_desc_feature_7: netflix, stage, live, comic, takes, series, comedian, comedy, special, stand\n","nmf_desc_feature_8: home, friend, son, mother, years, girl, boy, summary, year, old\n","nmf_desc_feature_9: film, true, lives, based, series, tells, summary, follows, love, story\n"]}],"source":["# Perform NMF on the descriptions\n","# What additional preprocessing do you need?\n","\n","# Vectorize the combined text using TF-IDF\n","vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n","tfidf_matrix = vectorizer.fit_transform(df_des['description'])\n","\n","# What is the scaler that you should use?\n","\n","# How many components should we use?\n","\n","n_components = 10  # Number of latent features/topics\n","nmf_model = NMF(n_components=n_components, random_state=42)\n","nmf_features = nmf_model.fit_transform(tfidf_matrix)\n","\n","# Display top words for each topic\n","feature_names = vectorizer.get_feature_names_out()\n","for topic_idx, topic in enumerate(nmf_model.components_):\n","    top_features = [feature_names[i] for i in topic.argsort()[-10:]]\n","    print(f\"nmf_desc_feature_{topic_idx}: {', '.join(top_features)}\")\n","\n","# Create the pipeline and apply it to the dataframe\n","\n","# Add NMF features to the dataframe\n","for i in range(n_components):\n","    df_des[f'nmf_desc_feature_{i+1}'] = nmf_features[:, i]\n","\n","# Create a pipeline with TF-IDF vectorizer and NMF (no idea what to do with this)\n","desc_pipeline = Pipeline([\n","    ('tfidf', TfidfVectorizer(max_features=1000, stop_words='english')),\n","    ('nmf', NMF(n_components=5, random_state=42))\n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zPPeH9sz79kx"},"outputs":[],"source":["# Combine the NMF features with the original dataframe\n","# Drop the description column\n","netflix_nmf_feature_desc = df_des.drop(columns=['description'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XrYP-4X679kx","executionInfo":{"status":"ok","timestamp":1732545562953,"user_tz":-480,"elapsed":4,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7d63c864-d6b4-45f1-a1db-80344afbeca0"},"outputs":[{"output_type":"stream","name":"stdout","text":["float64\n"]}],"source":["# Check what dtype is votes?\n","# Do we need to convert it to a numerical value?\n","\n","votes_df = netflix_nmf_feature_desc.copy()\n","\n","# Convert the 'votes' column to numeric by removing commas and changing type to float\n","votes_df['votes'] = votes_df['votes'].str.replace(',', '', regex=True).astype(float)\n","\n","# Verify the conversion\n","print(votes_df['votes'].dtype)  # Should print float64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kBA8MY1T79kx","executionInfo":{"status":"ok","timestamp":1732545562956,"user_tz":-480,"elapsed":2,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ec1c167d-656b-4d36-c2a1-9d0923a1a742"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of missing values in 'votes' column: 1173\n"]}],"source":["# Check votes_df['votes'] for missing values\n","# Check for missing values in the 'votes' column\n","missing_votes = votes_df['votes'].isnull().sum()\n","print(f\"Number of missing values in 'votes' column: {missing_votes}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TlUTZwhz79kx"},"outputs":[],"source":["# We are going to predict ratings\n","# Can we just drop the rows with missing values?\n","# yes because we need that information for training\n","\n","# Create a copy of the dataframe and name it rating_df\n","# Proceed with your choice of processing the data\n","rating_df = votes_df.dropna()\n","\n","# Clean column names by replacing spaces with underscores\n","rating_df.columns = rating_df.columns.str.replace(' ', '_')\n","\n","# If there are categorical variables, standardize their values\n","if 'certificate' in rating_df.columns:\n","    rating_df['certificate'] = rating_df['certificate'].str.replace(' ', '_')\n","\n","# Convert year column to date time\n","rating_df['year'] = pd.to_datetime(rating_df['year'], format='%Y')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K2pTTCjj79kx","executionInfo":{"status":"ok","timestamp":1732545568803,"user_tz":-480,"elapsed":5843,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"826dd126-54b1-4d1b-e96e-f33c888d5b91"},"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n","[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n","[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n","[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n","[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n","[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n","[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n","[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]}],"source":["# Perform regression or classification on the netflix dataset?\n","# use regression as we want to predict\n","from pycaret.regression import *\n","\n","exp = RegressionExperiment()\n","\n","regression_data = rating_df.copy()\n","\n","features = [\n","    'year',\n","    'duration',\n","    'certificate',\n","    'votes'\n","]  # Select relevant features\n","target = 'rating'\n","\n","# Set up PyCaret regression environment\n","regression_setup = exp.setup(\n","    data=regression_data,\n","    target=target,\n","    train_size=0.8,\n","    normalize=True,  # Normalize numerical features automatically\n","    feature_selection=True,  # Enable feature selection\n","    ignore_features=['title'],  # Exclude irrelevant features\n","    numeric_features=[\n","        'votes',\n","        *[f'nmf_feature_{i}' for i in range(1, 11)],  # Numeric NMF features\n","        *[f'nmf_desc_feature_{i}' for i in range(1, 11)]  # Numeric NMF description features\n","    ],\n","    categorical_features=[\n","        'certificate',\n","        'genre',\n","        'stars',\n","        'combined_text',  # Combined text feature as categorical (or processed separately)\n","    ],\n","    date_features=['year'],  # Treat 'year' as a date feature\n","    use_gpu=True,  # Use GPU for acceleration if available\n","    session_id=123,  # Set a random seed for reproducibility\n","    experiment_name='rating_prediction',  # Name the experiment for tracking\n","    verbose=False  # Suppress detailed output during setup\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pWmV9Ax579kx","executionInfo":{"status":"ok","timestamp":1732545913263,"user_tz":-480,"elapsed":344459,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"colab":{"base_uri":"https://localhost:8080/","height":498,"referenced_widgets":["7e7e0e0152ed48789138b43c6a3d8c68","1df4c613d4c84fac96d4a2d5cf21168f","66acfff9ab4c488a941b5ba981d97f5d","8fae36c19d654874828aab4ce9c9ed26","a39cea6d5207416c9a3f1b629cbde24a","60dae55270e64185a77526c1d0e22825","2cc5277716b7462597a8ea1768d449eb","5b00a55336f34e378c26a01f04181fed","ccd64b825b994e70ac08471b8cc65240","0cb45b6a38504708b15f21ff9d37131c","51fb89dd58c74beb99ca3d163ba396f7"]},"outputId":"8beafad0-fddf-4a38-848a-ee8c714eef05"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7f738c1d67a0>"],"text/html":["<style type=\"text/css\">\n","#T_42852 th {\n","  text-align: left;\n","}\n","#T_42852_row0_col0, #T_42852_row1_col0, #T_42852_row1_col1, #T_42852_row1_col2, #T_42852_row1_col3, #T_42852_row1_col4, #T_42852_row1_col5, #T_42852_row1_col6, #T_42852_row2_col0, #T_42852_row2_col1, #T_42852_row2_col2, #T_42852_row2_col3, #T_42852_row2_col4, #T_42852_row2_col5, #T_42852_row2_col6, #T_42852_row3_col0, #T_42852_row3_col1, #T_42852_row3_col2, #T_42852_row3_col3, #T_42852_row3_col4, #T_42852_row3_col5, #T_42852_row3_col6, #T_42852_row4_col0, #T_42852_row4_col1, #T_42852_row4_col2, #T_42852_row4_col3, #T_42852_row4_col4, #T_42852_row4_col5, #T_42852_row4_col6, #T_42852_row5_col0, #T_42852_row5_col1, #T_42852_row5_col2, #T_42852_row5_col3, #T_42852_row5_col4, #T_42852_row5_col5, #T_42852_row5_col6, #T_42852_row6_col0, #T_42852_row6_col1, #T_42852_row6_col2, #T_42852_row6_col3, #T_42852_row6_col4, #T_42852_row6_col5, #T_42852_row6_col6, #T_42852_row7_col0, #T_42852_row7_col1, #T_42852_row7_col2, #T_42852_row7_col3, #T_42852_row7_col4, #T_42852_row7_col5, #T_42852_row7_col6, #T_42852_row8_col0, #T_42852_row8_col1, #T_42852_row8_col2, #T_42852_row8_col3, #T_42852_row8_col4, #T_42852_row8_col5, #T_42852_row8_col6, #T_42852_row9_col0, #T_42852_row9_col1, #T_42852_row9_col2, #T_42852_row9_col3, #T_42852_row9_col4, #T_42852_row9_col5, #T_42852_row9_col6, #T_42852_row10_col0, #T_42852_row10_col1, #T_42852_row10_col2, #T_42852_row10_col3, #T_42852_row10_col4, #T_42852_row10_col5, #T_42852_row10_col6, #T_42852_row11_col0, #T_42852_row11_col1, #T_42852_row11_col2, #T_42852_row11_col3, #T_42852_row11_col4, #T_42852_row11_col5, #T_42852_row11_col6, #T_42852_row12_col0, #T_42852_row12_col1, #T_42852_row12_col2, #T_42852_row12_col3, #T_42852_row12_col4, #T_42852_row12_col5, #T_42852_row12_col6, #T_42852_row13_col0, #T_42852_row13_col1, #T_42852_row13_col2, #T_42852_row13_col3, #T_42852_row13_col4, #T_42852_row13_col5, #T_42852_row13_col6, #T_42852_row14_col0, #T_42852_row14_col1, #T_42852_row14_col2, #T_42852_row14_col3, #T_42852_row14_col4, #T_42852_row14_col5, #T_42852_row14_col6, #T_42852_row15_col0, #T_42852_row15_col1, #T_42852_row15_col2, #T_42852_row15_col3, #T_42852_row15_col4, #T_42852_row15_col5, #T_42852_row15_col6, #T_42852_row16_col0, #T_42852_row16_col1, #T_42852_row16_col2, #T_42852_row16_col3, #T_42852_row16_col4, #T_42852_row16_col5, #T_42852_row16_col6, #T_42852_row17_col0, #T_42852_row17_col1, #T_42852_row17_col2, #T_42852_row17_col3, #T_42852_row17_col4, #T_42852_row17_col5, #T_42852_row17_col6, #T_42852_row18_col0, #T_42852_row18_col1, #T_42852_row18_col2, #T_42852_row18_col3, #T_42852_row18_col4, #T_42852_row18_col5, #T_42852_row18_col6 {\n","  text-align: left;\n","}\n","#T_42852_row0_col1, #T_42852_row0_col2, #T_42852_row0_col3, #T_42852_row0_col4, #T_42852_row0_col5, #T_42852_row0_col6 {\n","  text-align: left;\n","  background-color: yellow;\n","}\n","#T_42852_row0_col7, #T_42852_row1_col7, #T_42852_row2_col7, #T_42852_row3_col7, #T_42852_row4_col7, #T_42852_row5_col7, #T_42852_row6_col7, #T_42852_row7_col7, #T_42852_row8_col7, #T_42852_row9_col7, #T_42852_row10_col7, #T_42852_row11_col7, #T_42852_row12_col7, #T_42852_row13_col7, #T_42852_row14_col7, #T_42852_row15_col7, #T_42852_row16_col7, #T_42852_row18_col7 {\n","  text-align: left;\n","  background-color: lightgrey;\n","}\n","#T_42852_row17_col7 {\n","  text-align: left;\n","  background-color: yellow;\n","  background-color: lightgrey;\n","}\n","</style>\n","<table id=\"T_42852\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_42852_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n","      <th id=\"T_42852_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n","      <th id=\"T_42852_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n","      <th id=\"T_42852_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n","      <th id=\"T_42852_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n","      <th id=\"T_42852_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n","      <th id=\"T_42852_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n","      <th id=\"T_42852_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_42852_level0_row0\" class=\"row_heading level0 row0\" >knn</th>\n","      <td id=\"T_42852_row0_col0\" class=\"data row0 col0\" >K Neighbors Regressor</td>\n","      <td id=\"T_42852_row0_col1\" class=\"data row0 col1\" >0.8572</td>\n","      <td id=\"T_42852_row0_col2\" class=\"data row0 col2\" >1.2917</td>\n","      <td id=\"T_42852_row0_col3\" class=\"data row0 col3\" >1.1362</td>\n","      <td id=\"T_42852_row0_col4\" class=\"data row0 col4\" >0.1259</td>\n","      <td id=\"T_42852_row0_col5\" class=\"data row0 col5\" >0.1637</td>\n","      <td id=\"T_42852_row0_col6\" class=\"data row0 col6\" >0.1485</td>\n","      <td id=\"T_42852_row0_col7\" class=\"data row0 col7\" >0.4330</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n","      <td id=\"T_42852_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n","      <td id=\"T_42852_row1_col1\" class=\"data row1 col1\" >0.8631</td>\n","      <td id=\"T_42852_row1_col2\" class=\"data row1 col2\" >1.3113</td>\n","      <td id=\"T_42852_row1_col3\" class=\"data row1 col3\" >1.1447</td>\n","      <td id=\"T_42852_row1_col4\" class=\"data row1 col4\" >0.1126</td>\n","      <td id=\"T_42852_row1_col5\" class=\"data row1 col5\" >0.1648</td>\n","      <td id=\"T_42852_row1_col6\" class=\"data row1 col6\" >0.1495</td>\n","      <td id=\"T_42852_row1_col7\" class=\"data row1 col7\" >1.0830</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row2\" class=\"row_heading level0 row2\" >gbr</th>\n","      <td id=\"T_42852_row2_col0\" class=\"data row2 col0\" >Gradient Boosting Regressor</td>\n","      <td id=\"T_42852_row2_col1\" class=\"data row2 col1\" >0.8652</td>\n","      <td id=\"T_42852_row2_col2\" class=\"data row2 col2\" >1.3148</td>\n","      <td id=\"T_42852_row2_col3\" class=\"data row2 col3\" >1.1462</td>\n","      <td id=\"T_42852_row2_col4\" class=\"data row2 col4\" >0.1103</td>\n","      <td id=\"T_42852_row2_col5\" class=\"data row2 col5\" >0.1648</td>\n","      <td id=\"T_42852_row2_col6\" class=\"data row2 col6\" >0.1496</td>\n","      <td id=\"T_42852_row2_col7\" class=\"data row2 col7\" >1.1020</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row3\" class=\"row_heading level0 row3\" >xgboost</th>\n","      <td id=\"T_42852_row3_col0\" class=\"data row3 col0\" >Extreme Gradient Boosting</td>\n","      <td id=\"T_42852_row3_col1\" class=\"data row3 col1\" >0.8651</td>\n","      <td id=\"T_42852_row3_col2\" class=\"data row3 col2\" >1.3154</td>\n","      <td id=\"T_42852_row3_col3\" class=\"data row3 col3\" >1.1465</td>\n","      <td id=\"T_42852_row3_col4\" class=\"data row3 col4\" >0.1099</td>\n","      <td id=\"T_42852_row3_col5\" class=\"data row3 col5\" >0.1650</td>\n","      <td id=\"T_42852_row3_col6\" class=\"data row3 col6\" >0.1497</td>\n","      <td id=\"T_42852_row3_col7\" class=\"data row3 col7\" >1.1580</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row4\" class=\"row_heading level0 row4\" >ridge</th>\n","      <td id=\"T_42852_row4_col0\" class=\"data row4 col0\" >Ridge Regression</td>\n","      <td id=\"T_42852_row4_col1\" class=\"data row4 col1\" >0.8745</td>\n","      <td id=\"T_42852_row4_col2\" class=\"data row4 col2\" >1.3192</td>\n","      <td id=\"T_42852_row4_col3\" class=\"data row4 col3\" >1.1482</td>\n","      <td id=\"T_42852_row4_col4\" class=\"data row4 col4\" >0.1073</td>\n","      <td id=\"T_42852_row4_col5\" class=\"data row4 col5\" >0.1645</td>\n","      <td id=\"T_42852_row4_col6\" class=\"data row4 col6\" >0.1502</td>\n","      <td id=\"T_42852_row4_col7\" class=\"data row4 col7\" >0.4270</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row5\" class=\"row_heading level0 row5\" >lr</th>\n","      <td id=\"T_42852_row5_col0\" class=\"data row5 col0\" >Linear Regression</td>\n","      <td id=\"T_42852_row5_col1\" class=\"data row5 col1\" >0.8746</td>\n","      <td id=\"T_42852_row5_col2\" class=\"data row5 col2\" >1.3194</td>\n","      <td id=\"T_42852_row5_col3\" class=\"data row5 col3\" >1.1482</td>\n","      <td id=\"T_42852_row5_col4\" class=\"data row5 col4\" >0.1072</td>\n","      <td id=\"T_42852_row5_col5\" class=\"data row5 col5\" >0.1646</td>\n","      <td id=\"T_42852_row5_col6\" class=\"data row5 col6\" >0.1502</td>\n","      <td id=\"T_42852_row5_col7\" class=\"data row5 col7\" >0.4210</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row6\" class=\"row_heading level0 row6\" >lar</th>\n","      <td id=\"T_42852_row6_col0\" class=\"data row6 col0\" >Least Angle Regression</td>\n","      <td id=\"T_42852_row6_col1\" class=\"data row6 col1\" >0.8746</td>\n","      <td id=\"T_42852_row6_col2\" class=\"data row6 col2\" >1.3194</td>\n","      <td id=\"T_42852_row6_col3\" class=\"data row6 col3\" >1.1482</td>\n","      <td id=\"T_42852_row6_col4\" class=\"data row6 col4\" >0.1072</td>\n","      <td id=\"T_42852_row6_col5\" class=\"data row6 col5\" >0.1646</td>\n","      <td id=\"T_42852_row6_col6\" class=\"data row6 col6\" >0.1502</td>\n","      <td id=\"T_42852_row6_col7\" class=\"data row6 col7\" >0.3810</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row7\" class=\"row_heading level0 row7\" >br</th>\n","      <td id=\"T_42852_row7_col0\" class=\"data row7 col0\" >Bayesian Ridge</td>\n","      <td id=\"T_42852_row7_col1\" class=\"data row7 col1\" >0.8746</td>\n","      <td id=\"T_42852_row7_col2\" class=\"data row7 col2\" >1.3194</td>\n","      <td id=\"T_42852_row7_col3\" class=\"data row7 col3\" >1.1482</td>\n","      <td id=\"T_42852_row7_col4\" class=\"data row7 col4\" >0.1072</td>\n","      <td id=\"T_42852_row7_col5\" class=\"data row7 col5\" >0.1645</td>\n","      <td id=\"T_42852_row7_col6\" class=\"data row7 col6\" >0.1502</td>\n","      <td id=\"T_42852_row7_col7\" class=\"data row7 col7\" >0.4470</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row8\" class=\"row_heading level0 row8\" >et</th>\n","      <td id=\"T_42852_row8_col0\" class=\"data row8 col0\" >Extra Trees Regressor</td>\n","      <td id=\"T_42852_row8_col1\" class=\"data row8 col1\" >0.8656</td>\n","      <td id=\"T_42852_row8_col2\" class=\"data row8 col2\" >1.3233</td>\n","      <td id=\"T_42852_row8_col3\" class=\"data row8 col3\" >1.1499</td>\n","      <td id=\"T_42852_row8_col4\" class=\"data row8 col4\" >0.1045</td>\n","      <td id=\"T_42852_row8_col5\" class=\"data row8 col5\" >0.1655</td>\n","      <td id=\"T_42852_row8_col6\" class=\"data row8 col6\" >0.1500</td>\n","      <td id=\"T_42852_row8_col7\" class=\"data row8 col7\" >0.6900</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row9\" class=\"row_heading level0 row9\" >omp</th>\n","      <td id=\"T_42852_row9_col0\" class=\"data row9 col0\" >Orthogonal Matching Pursuit</td>\n","      <td id=\"T_42852_row9_col1\" class=\"data row9 col1\" >0.8759</td>\n","      <td id=\"T_42852_row9_col2\" class=\"data row9 col2\" >1.3237</td>\n","      <td id=\"T_42852_row9_col3\" class=\"data row9 col3\" >1.1501</td>\n","      <td id=\"T_42852_row9_col4\" class=\"data row9 col4\" >0.1043</td>\n","      <td id=\"T_42852_row9_col5\" class=\"data row9 col5\" >0.1648</td>\n","      <td id=\"T_42852_row9_col6\" class=\"data row9 col6\" >0.1504</td>\n","      <td id=\"T_42852_row9_col7\" class=\"data row9 col7\" >0.3860</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row10\" class=\"row_heading level0 row10\" >catboost</th>\n","      <td id=\"T_42852_row10_col0\" class=\"data row10 col0\" >CatBoost Regressor</td>\n","      <td id=\"T_42852_row10_col1\" class=\"data row10 col1\" >0.8658</td>\n","      <td id=\"T_42852_row10_col2\" class=\"data row10 col2\" >1.3279</td>\n","      <td id=\"T_42852_row10_col3\" class=\"data row10 col3\" >1.1520</td>\n","      <td id=\"T_42852_row10_col4\" class=\"data row10 col4\" >0.1012</td>\n","      <td id=\"T_42852_row10_col5\" class=\"data row10 col5\" >0.1661</td>\n","      <td id=\"T_42852_row10_col6\" class=\"data row10 col6\" >0.1510</td>\n","      <td id=\"T_42852_row10_col7\" class=\"data row10 col7\" >23.3080</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row11\" class=\"row_heading level0 row11\" >huber</th>\n","      <td id=\"T_42852_row11_col0\" class=\"data row11 col0\" >Huber Regressor</td>\n","      <td id=\"T_42852_row11_col1\" class=\"data row11 col1\" >0.8798</td>\n","      <td id=\"T_42852_row11_col2\" class=\"data row11 col2\" >1.3399</td>\n","      <td id=\"T_42852_row11_col3\" class=\"data row11 col3\" >1.1572</td>\n","      <td id=\"T_42852_row11_col4\" class=\"data row11 col4\" >0.0932</td>\n","      <td id=\"T_42852_row11_col5\" class=\"data row11 col5\" >0.1658</td>\n","      <td id=\"T_42852_row11_col6\" class=\"data row11 col6\" >0.1518</td>\n","      <td id=\"T_42852_row11_col7\" class=\"data row11 col7\" >0.7240</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row12\" class=\"row_heading level0 row12\" >dt</th>\n","      <td id=\"T_42852_row12_col0\" class=\"data row12 col0\" >Decision Tree Regressor</td>\n","      <td id=\"T_42852_row12_col1\" class=\"data row12 col1\" >0.8727</td>\n","      <td id=\"T_42852_row12_col2\" class=\"data row12 col2\" >1.3455</td>\n","      <td id=\"T_42852_row12_col3\" class=\"data row12 col3\" >1.1592</td>\n","      <td id=\"T_42852_row12_col4\" class=\"data row12 col4\" >0.0899</td>\n","      <td id=\"T_42852_row12_col5\" class=\"data row12 col5\" >0.1667</td>\n","      <td id=\"T_42852_row12_col6\" class=\"data row12 col6\" >0.1510</td>\n","      <td id=\"T_42852_row12_col7\" class=\"data row12 col7\" >0.4130</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row13\" class=\"row_heading level0 row13\" >en</th>\n","      <td id=\"T_42852_row13_col0\" class=\"data row13 col0\" >Elastic Net</td>\n","      <td id=\"T_42852_row13_col1\" class=\"data row13 col1\" >0.8973</td>\n","      <td id=\"T_42852_row13_col2\" class=\"data row13 col2\" >1.3460</td>\n","      <td id=\"T_42852_row13_col3\" class=\"data row13 col3\" >1.1598</td>\n","      <td id=\"T_42852_row13_col4\" class=\"data row13 col4\" >0.0892</td>\n","      <td id=\"T_42852_row13_col5\" class=\"data row13 col5\" >0.1659</td>\n","      <td id=\"T_42852_row13_col6\" class=\"data row13 col6\" >0.1533</td>\n","      <td id=\"T_42852_row13_col7\" class=\"data row13 col7\" >0.4000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row14\" class=\"row_heading level0 row14\" >ada</th>\n","      <td id=\"T_42852_row14_col0\" class=\"data row14 col0\" >AdaBoost Regressor</td>\n","      <td id=\"T_42852_row14_col1\" class=\"data row14 col1\" >0.9007</td>\n","      <td id=\"T_42852_row14_col2\" class=\"data row14 col2\" >1.3660</td>\n","      <td id=\"T_42852_row14_col3\" class=\"data row14 col3\" >1.1669</td>\n","      <td id=\"T_42852_row14_col4\" class=\"data row14 col4\" >0.0775</td>\n","      <td id=\"T_42852_row14_col5\" class=\"data row14 col5\" >0.1655</td>\n","      <td id=\"T_42852_row14_col6\" class=\"data row14 col6\" >0.1503</td>\n","      <td id=\"T_42852_row14_col7\" class=\"data row14 col7\" >0.6290</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row15\" class=\"row_heading level0 row15\" >lasso</th>\n","      <td id=\"T_42852_row15_col0\" class=\"data row15 col0\" >Lasso Regression</td>\n","      <td id=\"T_42852_row15_col1\" class=\"data row15 col1\" >0.9382</td>\n","      <td id=\"T_42852_row15_col2\" class=\"data row15 col2\" >1.4209</td>\n","      <td id=\"T_42852_row15_col3\" class=\"data row15 col3\" >1.1917</td>\n","      <td id=\"T_42852_row15_col4\" class=\"data row15 col4\" >0.0386</td>\n","      <td id=\"T_42852_row15_col5\" class=\"data row15 col5\" >0.1691</td>\n","      <td id=\"T_42852_row15_col6\" class=\"data row15 col6\" >0.1586</td>\n","      <td id=\"T_42852_row15_col7\" class=\"data row15 col7\" >0.4630</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row16\" class=\"row_heading level0 row16\" >llar</th>\n","      <td id=\"T_42852_row16_col0\" class=\"data row16 col0\" >Lasso Least Angle Regression</td>\n","      <td id=\"T_42852_row16_col1\" class=\"data row16 col1\" >0.9382</td>\n","      <td id=\"T_42852_row16_col2\" class=\"data row16 col2\" >1.4209</td>\n","      <td id=\"T_42852_row16_col3\" class=\"data row16 col3\" >1.1917</td>\n","      <td id=\"T_42852_row16_col4\" class=\"data row16 col4\" >0.0386</td>\n","      <td id=\"T_42852_row16_col5\" class=\"data row16 col5\" >0.1691</td>\n","      <td id=\"T_42852_row16_col6\" class=\"data row16 col6\" >0.1586</td>\n","      <td id=\"T_42852_row16_col7\" class=\"data row16 col7\" >0.3760</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row17\" class=\"row_heading level0 row17\" >par</th>\n","      <td id=\"T_42852_row17_col0\" class=\"data row17 col0\" >Passive Aggressive Regressor</td>\n","      <td id=\"T_42852_row17_col1\" class=\"data row17 col1\" >0.9108</td>\n","      <td id=\"T_42852_row17_col2\" class=\"data row17 col2\" >1.4397</td>\n","      <td id=\"T_42852_row17_col3\" class=\"data row17 col3\" >1.1982</td>\n","      <td id=\"T_42852_row17_col4\" class=\"data row17 col4\" >0.0241</td>\n","      <td id=\"T_42852_row17_col5\" class=\"data row17 col5\" >0.1716</td>\n","      <td id=\"T_42852_row17_col6\" class=\"data row17 col6\" >0.1565</td>\n","      <td id=\"T_42852_row17_col7\" class=\"data row17 col7\" >0.3730</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_42852_level0_row18\" class=\"row_heading level0 row18\" >dummy</th>\n","      <td id=\"T_42852_row18_col0\" class=\"data row18 col0\" >Dummy Regressor</td>\n","      <td id=\"T_42852_row18_col1\" class=\"data row18 col1\" >0.9631</td>\n","      <td id=\"T_42852_row18_col2\" class=\"data row18 col2\" >1.4809</td>\n","      <td id=\"T_42852_row18_col3\" class=\"data row18 col3\" >1.2166</td>\n","      <td id=\"T_42852_row18_col4\" class=\"data row18 col4\" >-0.0020</td>\n","      <td id=\"T_42852_row18_col5\" class=\"data row18 col5\" >0.1718</td>\n","      <td id=\"T_42852_row18_col6\" class=\"data row18 col6\" >0.1618</td>\n","      <td id=\"T_42852_row18_col7\" class=\"data row18 col7\" >0.4270</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[I] [22:40:16.739108] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:12.541589] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:12.542357] Unused keyword parameter: n_jobs during cuML estimator initialization\n"]}],"source":["# Perform model selection\n","\n","# Compare models and select the best one\n","best_model = regression_setup.compare_models(exclude=\"rf\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SUbJ7kzN79kx","executionInfo":{"status":"ok","timestamp":1732545913732,"user_tz":-480,"elapsed":467,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"colab":{"base_uri":"https://localhost:8080/","height":305},"outputId":"aed81dbf-7a70-4d0f-ad65-93c796a2dc92"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7f73a3668640>"],"text/html":["<style type=\"text/css\">\n","</style>\n","<table id=\"T_23eba\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_23eba_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n","      <th id=\"T_23eba_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n","      <th id=\"T_23eba_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n","      <th id=\"T_23eba_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n","      <th id=\"T_23eba_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n","      <th id=\"T_23eba_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n","      <th id=\"T_23eba_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_23eba_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_23eba_row0_col0\" class=\"data row0 col0\" >K Neighbors Regressor</td>\n","      <td id=\"T_23eba_row0_col1\" class=\"data row0 col1\" >0.8114</td>\n","      <td id=\"T_23eba_row0_col2\" class=\"data row0 col2\" >1.1701</td>\n","      <td id=\"T_23eba_row0_col3\" class=\"data row0 col3\" >1.0817</td>\n","      <td id=\"T_23eba_row0_col4\" class=\"data row0 col4\" >0.1385</td>\n","      <td id=\"T_23eba_row0_col5\" class=\"data row0 col5\" >0.1546</td>\n","      <td id=\"T_23eba_row0_col6\" class=\"data row0 col6\" >0.1381</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["      rating  prediction_label\n","5174     6.9          6.880000\n","9121     7.4          6.780000\n","6694     6.3          6.800000\n","230      8.4          6.840000\n","1447     7.0          6.800000\n","...      ...               ...\n","4410     6.2          6.800000\n","747      6.7          6.740000\n","4684     7.6          6.800000\n","7570     7.1          6.820001\n","234      7.1          6.800000\n","\n","[1277 rows x 2 columns]\n"]}],"source":["# Validate best model on test data\n","from pycaret.regression import predict_model\n","\n","# Validate the best model on test data\n","validation_results = regression_setup.predict_model(best_model)\n","print(validation_results[['rating', 'prediction_label']])\n"]},{"cell_type":"code","source":["# # Tune model\n","tuned_model = regression_setup.tune_model(best_model)\n","\n","# Validate the tuned model on test data\n","validation_results = regression_setup.predict_model(tuned_model, verbose=True)\n","print(validation_results[['rating', 'prediction_label']])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d9855e178e434bc9b18cebb4b58ee794","b2408cc1378e4363b7da40d22232fc40","415c5b11550e4823ac2e39da558a4452","719f02e8440a4a51820419fb4726e0a2","eee093b3f4d34dfeac243f4451c2f988","742a8f7fcb6045e79e4c7ab324a10b3a","5d099bbccb3143ab8805f169e7b9f09f","2d5b688f15434bba805eb17d404b21e2","82e1e99c48e94e2989c4fd01204fa85c","b4d220e9d2274dfbb357a05332a49bd5","1841357aedc442d7ba96a4b429cffdab"]},"id":"lDUmuDfANgTU","executionInfo":{"status":"ok","timestamp":1732545970680,"user_tz":-480,"elapsed":56942,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"outputId":"c479facc-9a4f-4984-b9fc-93bf227915e9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7f738c206080>"],"text/html":["<style type=\"text/css\">\n","#T_fa370_row10_col0, #T_fa370_row10_col1, #T_fa370_row10_col2, #T_fa370_row10_col3, #T_fa370_row10_col4, #T_fa370_row10_col5 {\n","  background: yellow;\n","}\n","</style>\n","<table id=\"T_fa370\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_fa370_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n","      <th id=\"T_fa370_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n","      <th id=\"T_fa370_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n","      <th id=\"T_fa370_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n","      <th id=\"T_fa370_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n","      <th id=\"T_fa370_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n","    </tr>\n","    <tr>\n","      <th class=\"index_name level0\" >Fold</th>\n","      <th class=\"blank col0\" >&nbsp;</th>\n","      <th class=\"blank col1\" >&nbsp;</th>\n","      <th class=\"blank col2\" >&nbsp;</th>\n","      <th class=\"blank col3\" >&nbsp;</th>\n","      <th class=\"blank col4\" >&nbsp;</th>\n","      <th class=\"blank col5\" >&nbsp;</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_fa370_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_fa370_row0_col0\" class=\"data row0 col0\" >0.8646</td>\n","      <td id=\"T_fa370_row0_col1\" class=\"data row0 col1\" >1.2499</td>\n","      <td id=\"T_fa370_row0_col2\" class=\"data row0 col2\" >1.1180</td>\n","      <td id=\"T_fa370_row0_col3\" class=\"data row0 col3\" >0.1424</td>\n","      <td id=\"T_fa370_row0_col4\" class=\"data row0 col4\" >0.1553</td>\n","      <td id=\"T_fa370_row0_col5\" class=\"data row0 col5\" >0.1419</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_fa370_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n","      <td id=\"T_fa370_row1_col0\" class=\"data row1 col0\" >0.9061</td>\n","      <td id=\"T_fa370_row1_col1\" class=\"data row1 col1\" >1.4154</td>\n","      <td id=\"T_fa370_row1_col2\" class=\"data row1 col2\" >1.1897</td>\n","      <td id=\"T_fa370_row1_col3\" class=\"data row1 col3\" >0.1108</td>\n","      <td id=\"T_fa370_row1_col4\" class=\"data row1 col4\" >0.1710</td>\n","      <td id=\"T_fa370_row1_col5\" class=\"data row1 col5\" >0.1559</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_fa370_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n","      <td id=\"T_fa370_row2_col0\" class=\"data row2 col0\" >0.8620</td>\n","      <td id=\"T_fa370_row2_col1\" class=\"data row2 col1\" >1.3038</td>\n","      <td id=\"T_fa370_row2_col2\" class=\"data row2 col2\" >1.1419</td>\n","      <td id=\"T_fa370_row2_col3\" class=\"data row2 col3\" >0.0875</td>\n","      <td id=\"T_fa370_row2_col4\" class=\"data row2 col4\" >0.1638</td>\n","      <td id=\"T_fa370_row2_col5\" class=\"data row2 col5\" >0.1504</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_fa370_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n","      <td id=\"T_fa370_row3_col0\" class=\"data row3 col0\" >0.8740</td>\n","      <td id=\"T_fa370_row3_col1\" class=\"data row3 col1\" >1.3636</td>\n","      <td id=\"T_fa370_row3_col2\" class=\"data row3 col2\" >1.1677</td>\n","      <td id=\"T_fa370_row3_col3\" class=\"data row3 col3\" >0.1147</td>\n","      <td id=\"T_fa370_row3_col4\" class=\"data row3 col4\" >0.1722</td>\n","      <td id=\"T_fa370_row3_col5\" class=\"data row3 col5\" >0.1558</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_fa370_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n","      <td id=\"T_fa370_row4_col0\" class=\"data row4 col0\" >0.8575</td>\n","      <td id=\"T_fa370_row4_col1\" class=\"data row4 col1\" >1.3243</td>\n","      <td id=\"T_fa370_row4_col2\" class=\"data row4 col2\" >1.1508</td>\n","      <td id=\"T_fa370_row4_col3\" class=\"data row4 col3\" >0.1284</td>\n","      <td id=\"T_fa370_row4_col4\" class=\"data row4 col4\" >0.1687</td>\n","      <td id=\"T_fa370_row4_col5\" class=\"data row4 col5\" >0.1524</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_fa370_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n","      <td id=\"T_fa370_row5_col0\" class=\"data row5 col0\" >0.8159</td>\n","      <td id=\"T_fa370_row5_col1\" class=\"data row5 col1\" >1.2135</td>\n","      <td id=\"T_fa370_row5_col2\" class=\"data row5 col2\" >1.1016</td>\n","      <td id=\"T_fa370_row5_col3\" class=\"data row5 col3\" >0.1657</td>\n","      <td id=\"T_fa370_row5_col4\" class=\"data row5 col4\" >0.1591</td>\n","      <td id=\"T_fa370_row5_col5\" class=\"data row5 col5\" >0.1417</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_fa370_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n","      <td id=\"T_fa370_row6_col0\" class=\"data row6 col0\" >0.8676</td>\n","      <td id=\"T_fa370_row6_col1\" class=\"data row6 col1\" >1.2997</td>\n","      <td id=\"T_fa370_row6_col2\" class=\"data row6 col2\" >1.1401</td>\n","      <td id=\"T_fa370_row6_col3\" class=\"data row6 col3\" >0.1219</td>\n","      <td id=\"T_fa370_row6_col4\" class=\"data row6 col4\" >0.1621</td>\n","      <td id=\"T_fa370_row6_col5\" class=\"data row6 col5\" >0.1479</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_fa370_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n","      <td id=\"T_fa370_row7_col0\" class=\"data row7 col0\" >0.8543</td>\n","      <td id=\"T_fa370_row7_col1\" class=\"data row7 col1\" >1.3355</td>\n","      <td id=\"T_fa370_row7_col2\" class=\"data row7 col2\" >1.1557</td>\n","      <td id=\"T_fa370_row7_col3\" class=\"data row7 col3\" >0.1249</td>\n","      <td id=\"T_fa370_row7_col4\" class=\"data row7 col4\" >0.1708</td>\n","      <td id=\"T_fa370_row7_col5\" class=\"data row7 col5\" >0.1540</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_fa370_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n","      <td id=\"T_fa370_row8_col0\" class=\"data row8 col0\" >0.8281</td>\n","      <td id=\"T_fa370_row8_col1\" class=\"data row8 col1\" >1.1721</td>\n","      <td id=\"T_fa370_row8_col2\" class=\"data row8 col2\" >1.0826</td>\n","      <td id=\"T_fa370_row8_col3\" class=\"data row8 col3\" >0.1101</td>\n","      <td id=\"T_fa370_row8_col4\" class=\"data row8 col4\" >0.1556</td>\n","      <td id=\"T_fa370_row8_col5\" class=\"data row8 col5\" >0.1418</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_fa370_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n","      <td id=\"T_fa370_row9_col0\" class=\"data row9 col0\" >0.8505</td>\n","      <td id=\"T_fa370_row9_col1\" class=\"data row9 col1\" >1.2714</td>\n","      <td id=\"T_fa370_row9_col2\" class=\"data row9 col2\" >1.1275</td>\n","      <td id=\"T_fa370_row9_col3\" class=\"data row9 col3\" >0.1315</td>\n","      <td id=\"T_fa370_row9_col4\" class=\"data row9 col4\" >0.1606</td>\n","      <td id=\"T_fa370_row9_col5\" class=\"data row9 col5\" >0.1445</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_fa370_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n","      <td id=\"T_fa370_row10_col0\" class=\"data row10 col0\" >0.8581</td>\n","      <td id=\"T_fa370_row10_col1\" class=\"data row10 col1\" >1.2949</td>\n","      <td id=\"T_fa370_row10_col2\" class=\"data row10 col2\" >1.1376</td>\n","      <td id=\"T_fa370_row10_col3\" class=\"data row10 col3\" >0.1238</td>\n","      <td id=\"T_fa370_row10_col4\" class=\"data row10 col4\" >0.1639</td>\n","      <td id=\"T_fa370_row10_col5\" class=\"data row10 col5\" >0.1486</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_fa370_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n","      <td id=\"T_fa370_row11_col0\" class=\"data row11 col0\" >0.0234</td>\n","      <td id=\"T_fa370_row11_col1\" class=\"data row11 col1\" >0.0679</td>\n","      <td id=\"T_fa370_row11_col2\" class=\"data row11 col2\" >0.0299</td>\n","      <td id=\"T_fa370_row11_col3\" class=\"data row11 col3\" >0.0199</td>\n","      <td id=\"T_fa370_row11_col4\" class=\"data row11 col4\" >0.0061</td>\n","      <td id=\"T_fa370_row11_col5\" class=\"data row11 col5\" >0.0056</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[I] [22:45:13.774881] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:14.086851] Unused keyword parameter: n_jobs during cuML estimator initialization\n","Fitting 10 folds for each of 10 candidates, totalling 100 fits\n","[I] [22:45:14.092216] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003029 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6206\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.818855\n","[I] [22:45:14.478308] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:14.542170] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001071 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6274\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.821816\n","[I] [22:45:14.879650] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:14.936957] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000860 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6281\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.838189\n","[I] [22:45:15.277621] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:15.328759] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001098 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6231\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.827215\n","[I] [22:45:15.759823] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:15.810026] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000877 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6267\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.831193\n","[I] [22:45:16.134044] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:16.187234] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001911 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6271\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.826491\n","[I] [22:45:16.600443] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:16.654693] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004510 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6282\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.828407\n","[I] [22:45:17.083532] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:17.133453] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000991 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6220\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.834654\n","[I] [22:45:17.517334] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:17.583253] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000845 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6214\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.828864\n","[I] [22:45:17.899026] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:17.948465] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006337 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6223\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.824293\n","[I] [22:45:18.448293] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:18.510350] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000797 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6206\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.818855\n","[I] [22:45:18.836354] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:18.885975] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000799 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6274\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.821816\n","[I] [22:45:19.196346] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:19.255654] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000832 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6281\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.838189\n","[I] [22:45:19.562700] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:19.611362] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000953 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6231\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.827215\n","[I] [22:45:19.993213] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:20.049170] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000775 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6267\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.831193\n","[I] [22:45:20.366803] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:20.425806] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003076 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6271\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.826491\n","[I] [22:45:20.802647] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:20.851847] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000935 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6282\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.828407\n","[I] [22:45:21.190492] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:21.245282] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000910 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6220\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.834654\n","[I] [22:45:21.550874] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:21.599492] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000873 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6214\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.828864\n","[I] [22:45:21.934556] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:21.987438] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002656 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6223\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.824293\n","[I] [22:45:22.356446] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:22.405308] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001109 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6206\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.818855\n","[I] [22:45:22.731817] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:22.786235] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002082 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6274\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.821816\n","[I] [22:45:23.168251] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:23.229511] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000860 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6281\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.838189\n","[I] [22:45:23.536633] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:23.596966] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000646 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6231\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.827215\n","[I] [22:45:23.935139] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:23.998595] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000965 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6267\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.831193\n","[I] [22:45:24.315276] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:24.371290] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005322 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6271\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.826491\n","[I] [22:45:24.733059] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:24.789703] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004503 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6282\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.828407\n","[I] [22:45:25.126238] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:25.181058] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005452 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6220\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.834654\n","[I] [22:45:25.505228] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:25.559238] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007481 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6214\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.828864\n","[I] [22:45:25.957865] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:26.015944] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000930 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6223\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.824293\n","[I] [22:45:26.338365] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:26.403250] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000823 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6206\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.818855\n","[I] [22:45:26.714778] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:26.934411] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000891 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6274\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.821816\n","[I] [22:45:27.268538] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:27.327058] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001928 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6281\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.838189\n","[I] [22:45:27.666169] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:27.724452] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001768 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6231\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.827215\n","[I] [22:45:28.062262] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:28.124583] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000937 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6267\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.831193\n","[I] [22:45:28.476164] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:28.571808] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039235 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6271\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.826491\n","[I] [22:45:29.316840] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:29.389409] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000993 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6282\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.828407\n","[I] [22:45:29.810637] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:29.863357] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001071 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6220\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.834654\n","[I] [22:45:30.342862] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:30.398158] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001189 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6214\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.828864\n","[I] [22:45:30.732792] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:30.784941] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001273 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6223\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.824293\n","[I] [22:45:31.096978] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:31.148072] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001191 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6206\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.818855\n","[I] [22:45:31.453144] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:31.504208] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001004 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6274\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.821816\n","[I] [22:45:31.897019] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:31.945732] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001142 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6281\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.838189\n","[I] [22:45:32.268128] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:32.323205] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001051 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6231\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.827215\n","[I] [22:45:32.640902] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:32.687766] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004706 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6267\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.831193\n","[I] [22:45:33.050843] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:33.106580] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000897 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6271\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.826491\n","[I] [22:45:33.435274] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:33.488249] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000887 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6282\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.828407\n","[I] [22:45:33.821068] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:33.879878] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001058 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6220\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.834654\n","[I] [22:45:34.238867] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:34.297127] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003304 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6214\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.828864\n","[I] [22:45:34.666129] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:34.721752] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000842 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6223\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.824293\n","[I] [22:45:35.038760] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:35.093908] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002549 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6206\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.818855\n","[I] [22:45:35.430090] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:35.512139] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001346 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6274\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.821816\n","[I] [22:45:35.854436] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:35.932681] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6281\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.838189\n","[I] [22:45:36.269251] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:36.344229] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026274 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6231\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.827215\n","[I] [22:45:36.784684] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:36.865607] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000910 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6267\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.831193\n","[I] [22:45:37.185819] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:37.278532] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001047 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6271\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.826491\n","[I] [22:45:37.614296] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:37.696387] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001204 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6282\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.828407\n","[I] [22:45:38.071812] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:38.147841] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006316 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6220\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.834654\n","[I] [22:45:38.541214] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:38.613737] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000858 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6214\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.828864\n","[I] [22:45:38.910294] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:38.990379] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000912 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6223\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.824293\n","[I] [22:45:39.314030] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:39.394099] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004031 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6206\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.818855\n","[I] [22:45:39.798914] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:39.857872] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000909 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6274\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.821816\n","[I] [22:45:40.225430] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:40.289971] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6281\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.838189\n","[I] [22:45:40.739858] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:40.801443] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005046 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6231\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.827215\n","[I] [22:45:41.198319] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:41.265739] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001165 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6267\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.831193\n","[I] [22:45:41.601941] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:41.667028] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000949 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6271\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.826491\n","[I] [22:45:42.053560] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:42.144470] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000700 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6282\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.828407\n","[I] [22:45:42.468926] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:42.523192] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004315 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6220\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.834654\n","[I] [22:45:42.891592] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:42.940021] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003984 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6214\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.828864\n","[I] [22:45:43.350642] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:43.410381] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000843 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6223\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.824293\n","[I] [22:45:43.741219] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:43.799058] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004109 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6206\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.818855\n","[I] [22:45:44.176249] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:44.247291] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000867 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6274\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.821816\n","[I] [22:45:44.582550] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:44.640995] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001063 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6281\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.838189\n","[I] [22:45:44.977902] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:45.028323] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000861 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6231\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.827215\n","[I] [22:45:45.363867] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:45.466843] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000780 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6267\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.831193\n","[I] [22:45:45.798385] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:45.847588] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000866 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6271\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.826491\n","[I] [22:45:46.146607] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:46.193091] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000885 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6282\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.828407\n","[I] [22:45:46.526912] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:46.574252] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002008 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6220\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.834654\n","[I] [22:45:46.934520] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:47.014376] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000843 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6214\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.828864\n","[I] [22:45:47.367936] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:47.415788] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000911 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6223\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.824293\n","[I] [22:45:47.816243] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:47.878035] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001045 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6206\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.818855\n","[I] [22:45:48.323835] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:48.381709] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000934 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6274\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.821816\n","[I] [22:45:48.727872] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:48.784506] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004291 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6281\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.838189\n","[I] [22:45:49.187149] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:49.243334] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001468 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6231\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.827215\n","[I] [22:45:49.693150] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:49.749936] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002798 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6267\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.831193\n","[I] [22:45:50.095786] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:50.154021] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007756 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6271\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.826491\n","[I] [22:45:50.567425] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:50.620945] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000952 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6282\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.828407\n","[I] [22:45:51.006628] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:51.071962] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000855 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6220\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.834654\n","[I] [22:45:51.460490] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:51.524763] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000900 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6214\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.828864\n","[I] [22:45:51.963025] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:52.035905] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000853 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6223\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.824293\n","[I] [22:45:52.420928] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:52.489262] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000921 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6206\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.818855\n","[I] [22:45:52.857627] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:52.916770] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000900 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6274\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.821816\n","[I] [22:45:53.347239] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:53.426570] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000909 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6281\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.838189\n","[I] [22:45:53.786572] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:53.843969] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000841 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6231\n","[LightGBM] [Info] Number of data points in the train set: 4593, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.827215\n","[I] [22:45:54.139743] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:54.205887] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013699 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6267\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.831193\n","[I] [22:45:54.823052] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:54.889881] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000615 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6271\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.826491\n","[I] [22:45:55.270462] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:55.336777] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000953 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6282\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.828407\n","[I] [22:45:55.665271] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:55.736242] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002926 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6220\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.834654\n","[I] [22:45:56.311768] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:56.387011] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005017 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 6214\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 39\n","[LightGBM] [Info] Start training from score 6.828864\n","[I] [22:45:56.944208] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:56.998776] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006879 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 6223\n","[LightGBM] [Info] Number of data points in the train set: 4594, number of used features: 40\n","[LightGBM] [Info] Start training from score 6.824293\n","[I] [22:45:57.567976] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:57.664356] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:45:57.665504] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:46:04.531955] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:46:04.532726] Unused keyword parameter: n_jobs during cuML estimator initialization\n","Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"]},{"output_type":"display_data","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7f738c1509a0>"],"text/html":["<style type=\"text/css\">\n","</style>\n","<table id=\"T_fcf19\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_fcf19_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n","      <th id=\"T_fcf19_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n","      <th id=\"T_fcf19_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n","      <th id=\"T_fcf19_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n","      <th id=\"T_fcf19_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n","      <th id=\"T_fcf19_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n","      <th id=\"T_fcf19_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_fcf19_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_fcf19_row0_col0\" class=\"data row0 col0\" >K Neighbors Regressor</td>\n","      <td id=\"T_fcf19_row0_col1\" class=\"data row0 col1\" >0.8114</td>\n","      <td id=\"T_fcf19_row0_col2\" class=\"data row0 col2\" >1.1701</td>\n","      <td id=\"T_fcf19_row0_col3\" class=\"data row0 col3\" >1.0817</td>\n","      <td id=\"T_fcf19_row0_col4\" class=\"data row0 col4\" >0.1385</td>\n","      <td id=\"T_fcf19_row0_col5\" class=\"data row0 col5\" >0.1546</td>\n","      <td id=\"T_fcf19_row0_col6\" class=\"data row0 col6\" >0.1381</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["      rating  prediction_label\n","5174     6.9          6.880000\n","9121     7.4          6.780000\n","6694     6.3          6.800000\n","230      8.4          6.840000\n","1447     7.0          6.800000\n","...      ...               ...\n","4410     6.2          6.800000\n","747      6.7          6.740000\n","4684     7.6          6.800000\n","7570     7.1          6.820001\n","234      7.1          6.800000\n","\n","[1277 rows x 2 columns]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8kloXna79kx","executionInfo":{"status":"ok","timestamp":1732545972573,"user_tz":-480,"elapsed":1885,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"24fb5682-7e55-41e2-fbd1-5b971331cefe"},"outputs":[{"output_type":"stream","name":"stdout","text":["[I] [22:46:10.700688] Unused keyword parameter: n_jobs during cuML estimator initialization\n","[I] [22:46:10.701302] Unused keyword parameter: n_jobs during cuML estimator initialization\n"]},{"output_type":"display_data","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7f7385b52860>"],"text/html":["<style type=\"text/css\">\n","</style>\n","<table id=\"T_146e2\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_146e2_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n","      <th id=\"T_146e2_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n","      <th id=\"T_146e2_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n","      <th id=\"T_146e2_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n","      <th id=\"T_146e2_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n","      <th id=\"T_146e2_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n","      <th id=\"T_146e2_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_146e2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_146e2_row0_col0\" class=\"data row0 col0\" >K Neighbors Regressor</td>\n","      <td id=\"T_146e2_row0_col1\" class=\"data row0 col1\" >0.0636</td>\n","      <td id=\"T_146e2_row0_col2\" class=\"data row0 col2\" >0.0232</td>\n","      <td id=\"T_146e2_row0_col3\" class=\"data row0 col3\" >0.1523</td>\n","      <td id=\"T_146e2_row0_col4\" class=\"data row0 col4\" >0.9841</td>\n","      <td id=\"T_146e2_row0_col5\" class=\"data row0 col5\" >0.0198</td>\n","      <td id=\"T_146e2_row0_col6\" class=\"data row0 col6\" >0.0091</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["      rating  prediction_label\n","0        8.5          8.460000\n","1        8.7          8.780001\n","2        8.9          8.879999\n","3        5.9          5.880000\n","4        8.6          8.460001\n","...      ...               ...\n","9952     6.3          6.380000\n","9953     8.1          8.280001\n","9954     8.7          8.780001\n","9955     8.4          8.480000\n","9956     5.9          5.880000\n","\n","[6381 rows x 2 columns]\n","Transformation Pipeline and Model Successfully Saved\n"]}],"source":["# # Finalize model\n","\n","final_model = regression_setup.finalize_model(tuned_model)\n","\n","# # Make predictions on the test set\n","predictions = regression_setup.predict_model(final_model, regression_data)\n","print(predictions[['rating', 'prediction_label']])\n","\n","# # Save the model\n","saved_model = regression_setup.save_model(final_model, 'netflix_regression_model')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BessRL3a79kx","executionInfo":{"status":"ok","timestamp":1732545972643,"user_tz":-480,"elapsed":53,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0b0f2a19-8a12-4882-f8cd-b1a4aee81f5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["                    title  rating rating_class\n","0               Cobra Kai     8.5    Excellent\n","1               The Crown     8.7    Excellent\n","2        Better Call Saul     8.9    Excellent\n","3           Devil in Ohio     5.9      Average\n","4  Cyberpunk: Edgerunners     8.6    Excellent\n","                    title  rating  rating_class_10\n","0               Cobra Kai     8.5                8\n","1               The Crown     8.7                9\n","2        Better Call Saul     8.9                9\n","3           Devil in Ohio     5.9                6\n","4  Cyberpunk: Edgerunners     8.6                9\n"]}],"source":["# Will a classification model work better?\n","# Convert the ratings into classes\n","\n","# Approach 1: Use 5 ratings\n","\n","# Define bins and labels for the 5 classes\n","bins = [0, 2, 4, 6, 8, 10]\n","labels = ['Very Poor', 'Poor', 'Average', 'Good', 'Excellent']\n","\n","# Convert the 'rating' column into a new categorical column 'rating_class'\n","rating_df['rating_class'] = pd.cut(rating_df['rating'], bins=bins, labels=labels, include_lowest=True)\n","\n","# Display a sample of the updated dataset to verify the transformation\n","print(rating_df[['title', 'rating', 'rating_class']].head())\n","\n","\n","# Approach 2: Convert the ratings into 10 classes (round to the nearest integer)\n","\n","# Fill missing values in the 'rating' column with the median of the column\n","# rating_df['rating'] = rating_df['rating'].fillna(rating_df['rating'].median())\n","\n","# Convert the 'rating' column into 10 classes by rounding to the nearest integer\n","rating_df['rating_class_10'] = rating_df['rating'].round().astype(int)\n","\n","# Display a sample of the updated dataset to verify the transformation\n","print(rating_df[['title', 'rating', 'rating_class_10']].head())\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M5dTAIVd79ky","executionInfo":{"status":"ok","timestamp":1732545972651,"user_tz":-480,"elapsed":7,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ae469dd3-566a-4e84-e7d1-ad190fde77fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["rating_class\n","Very Poor       3\n","Poor          162\n","Average      1332\n","Good         3962\n","Excellent     922\n","Name: count, dtype: int64\n","rating_class_10\n","2       15\n","3       58\n","4      216\n","5      538\n","6     1498\n","7     1934\n","8     1804\n","9      305\n","10      13\n","Name: count, dtype: int64\n"]}],"source":["# Check for class imbalance\n","\n","class_distribution_5 = rating_df['rating_class'].value_counts().sort_index()\n","print(class_distribution_5)\n","\n","class_distribution_10 = rating_df['rating_class_10'].value_counts().sort_index()\n","print(class_distribution_10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crel89My79ky","executionInfo":{"status":"ok","timestamp":1732546853070,"user_tz":-480,"elapsed":880418,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5ed5e06d28694c77a12a0992a27cc11a","251d58a82c50422e822ebe4ebd548a6d","4c65f9dd28a34a44800f76010ba753db","5a354e1c25214c4589b3b9369d85cb5a","95d22b6c0e6a4c35ab5a0b46aa784791","b724571c41e142b3859c7f7c319d01c9","3be252c93c53464e84544d7e333ea120","2a8b3dc309db41c1a1501f739aebf109","e05d2ee9e7c04812a59edd29f049d62e","95136f5b5a5f48c28fee742cc6f4915e","4c6c169dc5a442d2a638e94487c12cd7"]},"outputId":"d481e045-d969-4189-a5b0-f47c226d0650"},"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n","[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n","[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n","[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n","[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7f7385ae36d0>"],"text/html":["<style type=\"text/css\">\n","#T_adb36 th {\n","  text-align: left;\n","}\n","#T_adb36_row0_col0, #T_adb36_row0_col2, #T_adb36_row0_col4, #T_adb36_row0_col5, #T_adb36_row0_col6, #T_adb36_row0_col7, #T_adb36_row1_col0, #T_adb36_row1_col1, #T_adb36_row1_col2, #T_adb36_row1_col3, #T_adb36_row1_col4, #T_adb36_row1_col5, #T_adb36_row1_col6, #T_adb36_row1_col7, #T_adb36_row2_col0, #T_adb36_row2_col1, #T_adb36_row2_col2, #T_adb36_row2_col3, #T_adb36_row2_col4, #T_adb36_row2_col7, #T_adb36_row3_col0, #T_adb36_row3_col1, #T_adb36_row3_col3, #T_adb36_row3_col4, #T_adb36_row3_col5, #T_adb36_row3_col6, #T_adb36_row3_col7, #T_adb36_row4_col0, #T_adb36_row4_col1, #T_adb36_row4_col2, #T_adb36_row4_col3, #T_adb36_row4_col4, #T_adb36_row4_col5, #T_adb36_row4_col6, #T_adb36_row4_col7, #T_adb36_row5_col0, #T_adb36_row5_col1, #T_adb36_row5_col2, #T_adb36_row5_col3, #T_adb36_row5_col4, #T_adb36_row5_col5, #T_adb36_row5_col6, #T_adb36_row6_col0, #T_adb36_row6_col1, #T_adb36_row6_col2, #T_adb36_row6_col3, #T_adb36_row6_col4, #T_adb36_row6_col5, #T_adb36_row6_col6, #T_adb36_row6_col7, #T_adb36_row7_col0, #T_adb36_row7_col1, #T_adb36_row7_col2, #T_adb36_row7_col3, #T_adb36_row7_col4, #T_adb36_row7_col5, #T_adb36_row7_col6, #T_adb36_row7_col7, #T_adb36_row8_col0, #T_adb36_row8_col1, #T_adb36_row8_col2, #T_adb36_row8_col3, #T_adb36_row8_col4, #T_adb36_row8_col5, #T_adb36_row8_col6, #T_adb36_row8_col7, #T_adb36_row9_col0, #T_adb36_row9_col1, #T_adb36_row9_col2, #T_adb36_row9_col3, #T_adb36_row9_col4, #T_adb36_row9_col5, #T_adb36_row9_col6, #T_adb36_row9_col7, #T_adb36_row10_col0, #T_adb36_row10_col1, #T_adb36_row10_col2, #T_adb36_row10_col3, #T_adb36_row10_col4, #T_adb36_row10_col5, #T_adb36_row10_col6, #T_adb36_row10_col7, #T_adb36_row11_col0, #T_adb36_row11_col1, #T_adb36_row11_col2, #T_adb36_row11_col3, #T_adb36_row11_col5, #T_adb36_row11_col6, #T_adb36_row11_col7, #T_adb36_row12_col0, #T_adb36_row12_col1, #T_adb36_row12_col2, #T_adb36_row12_col3, #T_adb36_row12_col4, #T_adb36_row12_col5, #T_adb36_row12_col6, #T_adb36_row12_col7, #T_adb36_row13_col0, #T_adb36_row13_col1, #T_adb36_row13_col2, #T_adb36_row13_col3, #T_adb36_row13_col4, #T_adb36_row13_col5, #T_adb36_row13_col6, #T_adb36_row13_col7, #T_adb36_row14_col0, #T_adb36_row14_col1, #T_adb36_row14_col2, #T_adb36_row14_col3, #T_adb36_row14_col4, #T_adb36_row14_col5, #T_adb36_row14_col6, #T_adb36_row14_col7 {\n","  text-align: left;\n","}\n","#T_adb36_row0_col1, #T_adb36_row0_col3, #T_adb36_row2_col5, #T_adb36_row2_col6, #T_adb36_row3_col2, #T_adb36_row5_col7, #T_adb36_row11_col4 {\n","  text-align: left;\n","  background-color: yellow;\n","}\n","#T_adb36_row0_col8, #T_adb36_row1_col8, #T_adb36_row2_col8, #T_adb36_row3_col8, #T_adb36_row4_col8, #T_adb36_row6_col8, #T_adb36_row7_col8, #T_adb36_row8_col8, #T_adb36_row9_col8, #T_adb36_row10_col8, #T_adb36_row11_col8, #T_adb36_row12_col8, #T_adb36_row13_col8, #T_adb36_row14_col8 {\n","  text-align: left;\n","  background-color: lightgrey;\n","}\n","#T_adb36_row5_col8 {\n","  text-align: left;\n","  background-color: yellow;\n","  background-color: lightgrey;\n","}\n","</style>\n","<table id=\"T_adb36\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_adb36_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n","      <th id=\"T_adb36_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n","      <th id=\"T_adb36_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n","      <th id=\"T_adb36_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n","      <th id=\"T_adb36_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n","      <th id=\"T_adb36_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n","      <th id=\"T_adb36_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n","      <th id=\"T_adb36_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n","      <th id=\"T_adb36_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_adb36_level0_row0\" class=\"row_heading level0 row0\" >dummy</th>\n","      <td id=\"T_adb36_row0_col0\" class=\"data row0 col0\" >Dummy Classifier</td>\n","      <td id=\"T_adb36_row0_col1\" class=\"data row0 col1\" >0.6209</td>\n","      <td id=\"T_adb36_row0_col2\" class=\"data row0 col2\" >0.1000</td>\n","      <td id=\"T_adb36_row0_col3\" class=\"data row0 col3\" >0.6209</td>\n","      <td id=\"T_adb36_row0_col4\" class=\"data row0 col4\" >0.3855</td>\n","      <td id=\"T_adb36_row0_col5\" class=\"data row0 col5\" >0.4757</td>\n","      <td id=\"T_adb36_row0_col6\" class=\"data row0 col6\" >0.0000</td>\n","      <td id=\"T_adb36_row0_col7\" class=\"data row0 col7\" >0.0000</td>\n","      <td id=\"T_adb36_row0_col8\" class=\"data row0 col8\" >0.1970</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_adb36_level0_row1\" class=\"row_heading level0 row1\" >lr</th>\n","      <td id=\"T_adb36_row1_col0\" class=\"data row1 col0\" >Logistic Regression</td>\n","      <td id=\"T_adb36_row1_col1\" class=\"data row1 col1\" >0.6191</td>\n","      <td id=\"T_adb36_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n","      <td id=\"T_adb36_row1_col3\" class=\"data row1 col3\" >0.6191</td>\n","      <td id=\"T_adb36_row1_col4\" class=\"data row1 col4\" >0.4914</td>\n","      <td id=\"T_adb36_row1_col5\" class=\"data row1 col5\" >0.4866</td>\n","      <td id=\"T_adb36_row1_col6\" class=\"data row1 col6\" >0.0148</td>\n","      <td id=\"T_adb36_row1_col7\" class=\"data row1 col7\" >0.0437</td>\n","      <td id=\"T_adb36_row1_col8\" class=\"data row1 col8\" >3.3050</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_adb36_level0_row2\" class=\"row_heading level0 row2\" >knn</th>\n","      <td id=\"T_adb36_row2_col0\" class=\"data row2 col0\" >K Neighbors Classifier</td>\n","      <td id=\"T_adb36_row2_col1\" class=\"data row2 col1\" >0.5672</td>\n","      <td id=\"T_adb36_row2_col2\" class=\"data row2 col2\" >0.1182</td>\n","      <td id=\"T_adb36_row2_col3\" class=\"data row2 col3\" >0.5672</td>\n","      <td id=\"T_adb36_row2_col4\" class=\"data row2 col4\" >0.5332</td>\n","      <td id=\"T_adb36_row2_col5\" class=\"data row2 col5\" >0.5459</td>\n","      <td id=\"T_adb36_row2_col6\" class=\"data row2 col6\" >0.1492</td>\n","      <td id=\"T_adb36_row2_col7\" class=\"data row2 col7\" >0.1518</td>\n","      <td id=\"T_adb36_row2_col8\" class=\"data row2 col8\" >0.2210</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_adb36_level0_row3\" class=\"row_heading level0 row3\" >et</th>\n","      <td id=\"T_adb36_row3_col0\" class=\"data row3 col0\" >Extra Trees Classifier</td>\n","      <td id=\"T_adb36_row3_col1\" class=\"data row3 col1\" >0.5262</td>\n","      <td id=\"T_adb36_row3_col2\" class=\"data row3 col2\" >0.1305</td>\n","      <td id=\"T_adb36_row3_col3\" class=\"data row3 col3\" >0.5262</td>\n","      <td id=\"T_adb36_row3_col4\" class=\"data row3 col4\" >0.5879</td>\n","      <td id=\"T_adb36_row3_col5\" class=\"data row3 col5\" >0.4785</td>\n","      <td id=\"T_adb36_row3_col6\" class=\"data row3 col6\" >0.1166</td>\n","      <td id=\"T_adb36_row3_col7\" class=\"data row3 col7\" >0.1275</td>\n","      <td id=\"T_adb36_row3_col8\" class=\"data row3 col8\" >0.6950</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_adb36_level0_row4\" class=\"row_heading level0 row4\" >ada</th>\n","      <td id=\"T_adb36_row4_col0\" class=\"data row4 col0\" >Ada Boost Classifier</td>\n","      <td id=\"T_adb36_row4_col1\" class=\"data row4 col1\" >0.4786</td>\n","      <td id=\"T_adb36_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n","      <td id=\"T_adb36_row4_col3\" class=\"data row4 col3\" >0.4786</td>\n","      <td id=\"T_adb36_row4_col4\" class=\"data row4 col4\" >0.5690</td>\n","      <td id=\"T_adb36_row4_col5\" class=\"data row4 col5\" >0.3953</td>\n","      <td id=\"T_adb36_row4_col6\" class=\"data row4 col6\" >0.0731</td>\n","      <td id=\"T_adb36_row4_col7\" class=\"data row4 col7\" >0.1281</td>\n","      <td id=\"T_adb36_row4_col8\" class=\"data row4 col8\" >0.9550</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_adb36_level0_row5\" class=\"row_heading level0 row5\" >nb</th>\n","      <td id=\"T_adb36_row5_col0\" class=\"data row5 col0\" >Naive Bayes</td>\n","      <td id=\"T_adb36_row5_col1\" class=\"data row5 col1\" >0.4774</td>\n","      <td id=\"T_adb36_row5_col2\" class=\"data row5 col2\" >0.1214</td>\n","      <td id=\"T_adb36_row5_col3\" class=\"data row5 col3\" >0.4774</td>\n","      <td id=\"T_adb36_row5_col4\" class=\"data row5 col4\" >0.5396</td>\n","      <td id=\"T_adb36_row5_col5\" class=\"data row5 col5\" >0.4714</td>\n","      <td id=\"T_adb36_row5_col6\" class=\"data row5 col6\" >0.1398</td>\n","      <td id=\"T_adb36_row5_col7\" class=\"data row5 col7\" >0.1558</td>\n","      <td id=\"T_adb36_row5_col8\" class=\"data row5 col8\" >0.1960</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_adb36_level0_row6\" class=\"row_heading level0 row6\" >dt</th>\n","      <td id=\"T_adb36_row6_col0\" class=\"data row6 col0\" >Decision Tree Classifier</td>\n","      <td id=\"T_adb36_row6_col1\" class=\"data row6 col1\" >0.4592</td>\n","      <td id=\"T_adb36_row6_col2\" class=\"data row6 col2\" >0.1082</td>\n","      <td id=\"T_adb36_row6_col3\" class=\"data row6 col3\" >0.4592</td>\n","      <td id=\"T_adb36_row6_col4\" class=\"data row6 col4\" >0.5511</td>\n","      <td id=\"T_adb36_row6_col5\" class=\"data row6 col5\" >0.4616</td>\n","      <td id=\"T_adb36_row6_col6\" class=\"data row6 col6\" >0.0936</td>\n","      <td id=\"T_adb36_row6_col7\" class=\"data row6 col7\" >0.1034</td>\n","      <td id=\"T_adb36_row6_col8\" class=\"data row6 col8\" >0.2400</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_adb36_level0_row7\" class=\"row_heading level0 row7\" >gbc</th>\n","      <td id=\"T_adb36_row7_col0\" class=\"data row7 col0\" >Gradient Boosting Classifier</td>\n","      <td id=\"T_adb36_row7_col1\" class=\"data row7 col1\" >0.4386</td>\n","      <td id=\"T_adb36_row7_col2\" class=\"data row7 col2\" >0.0000</td>\n","      <td id=\"T_adb36_row7_col3\" class=\"data row7 col3\" >0.4386</td>\n","      <td id=\"T_adb36_row7_col4\" class=\"data row7 col4\" >0.5828</td>\n","      <td id=\"T_adb36_row7_col5\" class=\"data row7 col5\" >0.4210</td>\n","      <td id=\"T_adb36_row7_col6\" class=\"data row7 col6\" >0.0763</td>\n","      <td id=\"T_adb36_row7_col7\" class=\"data row7 col7\" >0.0877</td>\n","      <td id=\"T_adb36_row7_col8\" class=\"data row7 col8\" >14.6870</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_adb36_level0_row8\" class=\"row_heading level0 row8\" >catboost</th>\n","      <td id=\"T_adb36_row8_col0\" class=\"data row8 col0\" >CatBoost Classifier</td>\n","      <td id=\"T_adb36_row8_col1\" class=\"data row8 col1\" >0.4200</td>\n","      <td id=\"T_adb36_row8_col2\" class=\"data row8 col2\" >0.1253</td>\n","      <td id=\"T_adb36_row8_col3\" class=\"data row8 col3\" >0.4200</td>\n","      <td id=\"T_adb36_row8_col4\" class=\"data row8 col4\" >0.5727</td>\n","      <td id=\"T_adb36_row8_col5\" class=\"data row8 col5\" >0.4083</td>\n","      <td id=\"T_adb36_row8_col6\" class=\"data row8 col6\" >0.0713</td>\n","      <td id=\"T_adb36_row8_col7\" class=\"data row8 col7\" >0.0828</td>\n","      <td id=\"T_adb36_row8_col8\" class=\"data row8 col8\" >17.6810</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_adb36_level0_row9\" class=\"row_heading level0 row9\" >lightgbm</th>\n","      <td id=\"T_adb36_row9_col0\" class=\"data row9 col0\" >Light Gradient Boosting Machine</td>\n","      <td id=\"T_adb36_row9_col1\" class=\"data row9 col1\" >0.3840</td>\n","      <td id=\"T_adb36_row9_col2\" class=\"data row9 col2\" >0.1238</td>\n","      <td id=\"T_adb36_row9_col3\" class=\"data row9 col3\" >0.3840</td>\n","      <td id=\"T_adb36_row9_col4\" class=\"data row9 col4\" >0.5952</td>\n","      <td id=\"T_adb36_row9_col5\" class=\"data row9 col5\" >0.3839</td>\n","      <td id=\"T_adb36_row9_col6\" class=\"data row9 col6\" >0.0691</td>\n","      <td id=\"T_adb36_row9_col7\" class=\"data row9 col7\" >0.0875</td>\n","      <td id=\"T_adb36_row9_col8\" class=\"data row9 col8\" >2.2790</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_adb36_level0_row10\" class=\"row_heading level0 row10\" >xgboost</th>\n","      <td id=\"T_adb36_row10_col0\" class=\"data row10 col0\" >Extreme Gradient Boosting</td>\n","      <td id=\"T_adb36_row10_col1\" class=\"data row10 col1\" >0.3294</td>\n","      <td id=\"T_adb36_row10_col2\" class=\"data row10 col2\" >0.1192</td>\n","      <td id=\"T_adb36_row10_col3\" class=\"data row10 col3\" >0.3294</td>\n","      <td id=\"T_adb36_row10_col4\" class=\"data row10 col4\" >0.6013</td>\n","      <td id=\"T_adb36_row10_col5\" class=\"data row10 col5\" >0.3357</td>\n","      <td id=\"T_adb36_row10_col6\" class=\"data row10 col6\" >0.0569</td>\n","      <td id=\"T_adb36_row10_col7\" class=\"data row10 col7\" >0.0833</td>\n","      <td id=\"T_adb36_row10_col8\" class=\"data row10 col8\" >2.7570</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_adb36_level0_row11\" class=\"row_heading level0 row11\" >lda</th>\n","      <td id=\"T_adb36_row11_col0\" class=\"data row11 col0\" >Linear Discriminant Analysis</td>\n","      <td id=\"T_adb36_row11_col1\" class=\"data row11 col1\" >0.2235</td>\n","      <td id=\"T_adb36_row11_col2\" class=\"data row11 col2\" >0.0000</td>\n","      <td id=\"T_adb36_row11_col3\" class=\"data row11 col3\" >0.2235</td>\n","      <td id=\"T_adb36_row11_col4\" class=\"data row11 col4\" >0.6541</td>\n","      <td id=\"T_adb36_row11_col5\" class=\"data row11 col5\" >0.1935</td>\n","      <td id=\"T_adb36_row11_col6\" class=\"data row11 col6\" >0.0307</td>\n","      <td id=\"T_adb36_row11_col7\" class=\"data row11 col7\" >0.0723</td>\n","      <td id=\"T_adb36_row11_col8\" class=\"data row11 col8\" >0.3570</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_adb36_level0_row12\" class=\"row_heading level0 row12\" >svm</th>\n","      <td id=\"T_adb36_row12_col0\" class=\"data row12 col0\" >SVM - Linear Kernel</td>\n","      <td id=\"T_adb36_row12_col1\" class=\"data row12 col1\" >0.1827</td>\n","      <td id=\"T_adb36_row12_col2\" class=\"data row12 col2\" >0.0000</td>\n","      <td id=\"T_adb36_row12_col3\" class=\"data row12 col3\" >0.1827</td>\n","      <td id=\"T_adb36_row12_col4\" class=\"data row12 col4\" >0.0675</td>\n","      <td id=\"T_adb36_row12_col5\" class=\"data row12 col5\" >0.0866</td>\n","      <td id=\"T_adb36_row12_col6\" class=\"data row12 col6\" >0.0072</td>\n","      <td id=\"T_adb36_row12_col7\" class=\"data row12 col7\" >0.0164</td>\n","      <td id=\"T_adb36_row12_col8\" class=\"data row12 col8\" >42.9980</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_adb36_level0_row13\" class=\"row_heading level0 row13\" >ridge</th>\n","      <td id=\"T_adb36_row13_col0\" class=\"data row13 col0\" >Ridge Classifier</td>\n","      <td id=\"T_adb36_row13_col1\" class=\"data row13 col1\" >0.1637</td>\n","      <td id=\"T_adb36_row13_col2\" class=\"data row13 col2\" >0.0000</td>\n","      <td id=\"T_adb36_row13_col3\" class=\"data row13 col3\" >0.1637</td>\n","      <td id=\"T_adb36_row13_col4\" class=\"data row13 col4\" >0.5910</td>\n","      <td id=\"T_adb36_row13_col5\" class=\"data row13 col5\" >0.1003</td>\n","      <td id=\"T_adb36_row13_col6\" class=\"data row13 col6\" >0.0004</td>\n","      <td id=\"T_adb36_row13_col7\" class=\"data row13 col7\" >0.0017</td>\n","      <td id=\"T_adb36_row13_col8\" class=\"data row13 col8\" >0.2310</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_adb36_level0_row14\" class=\"row_heading level0 row14\" >qda</th>\n","      <td id=\"T_adb36_row14_col0\" class=\"data row14 col0\" >Quadratic Discriminant Analysis</td>\n","      <td id=\"T_adb36_row14_col1\" class=\"data row14 col1\" >0.1409</td>\n","      <td id=\"T_adb36_row14_col2\" class=\"data row14 col2\" >0.0000</td>\n","      <td id=\"T_adb36_row14_col3\" class=\"data row14 col3\" >0.1409</td>\n","      <td id=\"T_adb36_row14_col4\" class=\"data row14 col4\" >0.3500</td>\n","      <td id=\"T_adb36_row14_col5\" class=\"data row14 col5\" >0.0748</td>\n","      <td id=\"T_adb36_row14_col6\" class=\"data row14 col6\" >0.0085</td>\n","      <td id=\"T_adb36_row14_col7\" class=\"data row14 col7\" >0.0236</td>\n","      <td id=\"T_adb36_row14_col8\" class=\"data row14 col8\" >0.3820</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[I] [22:46:47.915294] Unused keyword parameter: n_jobs during cuML estimator initialization\n"]}],"source":["# Perform approach 1 classification on the netflix dataset\n","from pycaret.classification import *\n","\n","# Select target and features\n","target_variable = 'rating_class'\n","five_cat_data = rating_df.copy()\n","\n","exp = ClassificationExperiment()\n","\n","# Step 2: Set up the classification environment\n","clf_setup = exp.setup(\n","    data=five_cat_data,\n","    target=target_variable,  # Target column\n","    session_id=42,  # For reproducibility\n","    ignore_features=['title', 'rating_class_10', 'rating'],  # Exclude irrelevant columns\n","    numeric_features=[\n","        'votes',\n","        *[f'nmf_feature_{i}' for i in range(1, 11)],  # Numeric NMF features\n","        *[f'nmf_desc_feature_{i}' for i in range(1, 11)]  # NMF description features\n","    ],\n","    categorical_features=['certificate', 'genre', 'stars', 'combined_text'],  # Treat these as categorical\n","    date_features=['year'],  # Treat 'year' as a date feature\n","    use_gpu=True,  # Use GPU for acceleration if available\n","    verbose=False,  # Suppress detailed output during setup\n","    experiment_name='rating_classification'  # Name the experiment for tracking\n",")\n","\n","# Step 3: Compare models to find the best one\n","class_best_model = clf_setup.compare_models(exclude=\"rf\")\n"]},{"cell_type":"code","source":["# # Tune model\n","class_tuned_model = clf_setup.tune_model(class_best_model)\n","\n","# Validate the tuned model on test data\n","validation_results = clf_setup.predict_model(class_tuned_model)\n","print(validation_results[['rating_class', 'prediction_label']])\n","\n","# # Finalize the model\n","class_final_model = clf_setup.finalize_model(class_tuned_model)\n","\n","# # Make predictions on the test set\n","predictions = clf_setup.predict_model(class_final_model, five_cat_data)\n","print(predictions[['rating_class', 'prediction_label']])\n","\n","rating_class_classifier = clf_setup.save_model(final_model, 'rating_class_classifier')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":966,"referenced_widgets":["3e28c5b9268d41bc835b580536063a93","4c8fad4946274558a888ecba95806393","a8c5682b3599426ca88903995a920e35","17f62aeed7524c328891d918d6e74f67","95b8ccdaab154d8abd8d9ebb0f58b24b","07ec919d277f42cba2d983d4ad60de27","852caa28e6524f05bd8b977ed299a80b","40e57fed84684f48a40be5ab09dc169c","ded86a4fa16b4107bbf4de8861e706a0","4a3107f4cc3146e483c144534311c85c","b1020dd2915d46e7ae67261a7730b0b1"]},"id":"6TBRTrzWTiv1","executionInfo":{"status":"ok","timestamp":1732546903507,"user_tz":-480,"elapsed":9942,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"outputId":"847cbdb3-b81f-411c-92b2-35eb1c1baea3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7f74c2c55e70>"],"text/html":["<style type=\"text/css\">\n","#T_db0ce_row10_col0, #T_db0ce_row10_col1, #T_db0ce_row10_col2, #T_db0ce_row10_col3, #T_db0ce_row10_col4, #T_db0ce_row10_col5, #T_db0ce_row10_col6 {\n","  background: yellow;\n","}\n","</style>\n","<table id=\"T_db0ce\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_db0ce_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n","      <th id=\"T_db0ce_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n","      <th id=\"T_db0ce_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n","      <th id=\"T_db0ce_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n","      <th id=\"T_db0ce_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n","      <th id=\"T_db0ce_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n","      <th id=\"T_db0ce_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n","    </tr>\n","    <tr>\n","      <th class=\"index_name level0\" >Fold</th>\n","      <th class=\"blank col0\" >&nbsp;</th>\n","      <th class=\"blank col1\" >&nbsp;</th>\n","      <th class=\"blank col2\" >&nbsp;</th>\n","      <th class=\"blank col3\" >&nbsp;</th>\n","      <th class=\"blank col4\" >&nbsp;</th>\n","      <th class=\"blank col5\" >&nbsp;</th>\n","      <th class=\"blank col6\" >&nbsp;</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_db0ce_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_db0ce_row0_col0\" class=\"data row0 col0\" >0.6197</td>\n","      <td id=\"T_db0ce_row0_col1\" class=\"data row0 col1\" >0.0000</td>\n","      <td id=\"T_db0ce_row0_col2\" class=\"data row0 col2\" >0.6197</td>\n","      <td id=\"T_db0ce_row0_col3\" class=\"data row0 col3\" >0.3840</td>\n","      <td id=\"T_db0ce_row0_col4\" class=\"data row0 col4\" >0.4742</td>\n","      <td id=\"T_db0ce_row0_col5\" class=\"data row0 col5\" >0.0000</td>\n","      <td id=\"T_db0ce_row0_col6\" class=\"data row0 col6\" >0.0000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_db0ce_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n","      <td id=\"T_db0ce_row1_col0\" class=\"data row1 col0\" >0.6197</td>\n","      <td id=\"T_db0ce_row1_col1\" class=\"data row1 col1\" >0.0000</td>\n","      <td id=\"T_db0ce_row1_col2\" class=\"data row1 col2\" >0.6197</td>\n","      <td id=\"T_db0ce_row1_col3\" class=\"data row1 col3\" >0.3840</td>\n","      <td id=\"T_db0ce_row1_col4\" class=\"data row1 col4\" >0.4742</td>\n","      <td id=\"T_db0ce_row1_col5\" class=\"data row1 col5\" >0.0000</td>\n","      <td id=\"T_db0ce_row1_col6\" class=\"data row1 col6\" >0.0000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_db0ce_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n","      <td id=\"T_db0ce_row2_col0\" class=\"data row2 col0\" >0.6197</td>\n","      <td id=\"T_db0ce_row2_col1\" class=\"data row2 col1\" >0.0000</td>\n","      <td id=\"T_db0ce_row2_col2\" class=\"data row2 col2\" >0.6197</td>\n","      <td id=\"T_db0ce_row2_col3\" class=\"data row2 col3\" >0.3840</td>\n","      <td id=\"T_db0ce_row2_col4\" class=\"data row2 col4\" >0.4742</td>\n","      <td id=\"T_db0ce_row2_col5\" class=\"data row2 col5\" >0.0000</td>\n","      <td id=\"T_db0ce_row2_col6\" class=\"data row2 col6\" >0.0000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_db0ce_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n","      <td id=\"T_db0ce_row3_col0\" class=\"data row3 col0\" >0.6197</td>\n","      <td id=\"T_db0ce_row3_col1\" class=\"data row3 col1\" >0.0000</td>\n","      <td id=\"T_db0ce_row3_col2\" class=\"data row3 col2\" >0.6197</td>\n","      <td id=\"T_db0ce_row3_col3\" class=\"data row3 col3\" >0.3840</td>\n","      <td id=\"T_db0ce_row3_col4\" class=\"data row3 col4\" >0.4742</td>\n","      <td id=\"T_db0ce_row3_col5\" class=\"data row3 col5\" >0.0000</td>\n","      <td id=\"T_db0ce_row3_col6\" class=\"data row3 col6\" >0.0000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_db0ce_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n","      <td id=\"T_db0ce_row4_col0\" class=\"data row4 col0\" >0.6197</td>\n","      <td id=\"T_db0ce_row4_col1\" class=\"data row4 col1\" >0.5000</td>\n","      <td id=\"T_db0ce_row4_col2\" class=\"data row4 col2\" >0.6197</td>\n","      <td id=\"T_db0ce_row4_col3\" class=\"data row4 col3\" >0.3840</td>\n","      <td id=\"T_db0ce_row4_col4\" class=\"data row4 col4\" >0.4742</td>\n","      <td id=\"T_db0ce_row4_col5\" class=\"data row4 col5\" >0.0000</td>\n","      <td id=\"T_db0ce_row4_col6\" class=\"data row4 col6\" >0.0000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_db0ce_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n","      <td id=\"T_db0ce_row5_col0\" class=\"data row5 col0\" >0.6197</td>\n","      <td id=\"T_db0ce_row5_col1\" class=\"data row5 col1\" >0.5000</td>\n","      <td id=\"T_db0ce_row5_col2\" class=\"data row5 col2\" >0.6197</td>\n","      <td id=\"T_db0ce_row5_col3\" class=\"data row5 col3\" >0.3840</td>\n","      <td id=\"T_db0ce_row5_col4\" class=\"data row5 col4\" >0.4742</td>\n","      <td id=\"T_db0ce_row5_col5\" class=\"data row5 col5\" >0.0000</td>\n","      <td id=\"T_db0ce_row5_col6\" class=\"data row5 col6\" >0.0000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_db0ce_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n","      <td id=\"T_db0ce_row6_col0\" class=\"data row6 col0\" >0.6233</td>\n","      <td id=\"T_db0ce_row6_col1\" class=\"data row6 col1\" >0.0000</td>\n","      <td id=\"T_db0ce_row6_col2\" class=\"data row6 col2\" >0.6233</td>\n","      <td id=\"T_db0ce_row6_col3\" class=\"data row6 col3\" >0.3885</td>\n","      <td id=\"T_db0ce_row6_col4\" class=\"data row6 col4\" >0.4787</td>\n","      <td id=\"T_db0ce_row6_col5\" class=\"data row6 col5\" >0.0000</td>\n","      <td id=\"T_db0ce_row6_col6\" class=\"data row6 col6\" >0.0000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_db0ce_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n","      <td id=\"T_db0ce_row7_col0\" class=\"data row7 col0\" >0.6233</td>\n","      <td id=\"T_db0ce_row7_col1\" class=\"data row7 col1\" >0.0000</td>\n","      <td id=\"T_db0ce_row7_col2\" class=\"data row7 col2\" >0.6233</td>\n","      <td id=\"T_db0ce_row7_col3\" class=\"data row7 col3\" >0.3885</td>\n","      <td id=\"T_db0ce_row7_col4\" class=\"data row7 col4\" >0.4787</td>\n","      <td id=\"T_db0ce_row7_col5\" class=\"data row7 col5\" >0.0000</td>\n","      <td id=\"T_db0ce_row7_col6\" class=\"data row7 col6\" >0.0000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_db0ce_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n","      <td id=\"T_db0ce_row8_col0\" class=\"data row8 col0\" >0.6233</td>\n","      <td id=\"T_db0ce_row8_col1\" class=\"data row8 col1\" >0.0000</td>\n","      <td id=\"T_db0ce_row8_col2\" class=\"data row8 col2\" >0.6233</td>\n","      <td id=\"T_db0ce_row8_col3\" class=\"data row8 col3\" >0.3885</td>\n","      <td id=\"T_db0ce_row8_col4\" class=\"data row8 col4\" >0.4787</td>\n","      <td id=\"T_db0ce_row8_col5\" class=\"data row8 col5\" >0.0000</td>\n","      <td id=\"T_db0ce_row8_col6\" class=\"data row8 col6\" >0.0000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_db0ce_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n","      <td id=\"T_db0ce_row9_col0\" class=\"data row9 col0\" >0.6211</td>\n","      <td id=\"T_db0ce_row9_col1\" class=\"data row9 col1\" >0.0000</td>\n","      <td id=\"T_db0ce_row9_col2\" class=\"data row9 col2\" >0.6211</td>\n","      <td id=\"T_db0ce_row9_col3\" class=\"data row9 col3\" >0.3857</td>\n","      <td id=\"T_db0ce_row9_col4\" class=\"data row9 col4\" >0.4759</td>\n","      <td id=\"T_db0ce_row9_col5\" class=\"data row9 col5\" >0.0000</td>\n","      <td id=\"T_db0ce_row9_col6\" class=\"data row9 col6\" >0.0000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_db0ce_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n","      <td id=\"T_db0ce_row10_col0\" class=\"data row10 col0\" >0.6209</td>\n","      <td id=\"T_db0ce_row10_col1\" class=\"data row10 col1\" >0.1000</td>\n","      <td id=\"T_db0ce_row10_col2\" class=\"data row10 col2\" >0.6209</td>\n","      <td id=\"T_db0ce_row10_col3\" class=\"data row10 col3\" >0.3855</td>\n","      <td id=\"T_db0ce_row10_col4\" class=\"data row10 col4\" >0.4757</td>\n","      <td id=\"T_db0ce_row10_col5\" class=\"data row10 col5\" >0.0000</td>\n","      <td id=\"T_db0ce_row10_col6\" class=\"data row10 col6\" >0.0000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_db0ce_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n","      <td id=\"T_db0ce_row11_col0\" class=\"data row11 col0\" >0.0016</td>\n","      <td id=\"T_db0ce_row11_col1\" class=\"data row11 col1\" >0.2000</td>\n","      <td id=\"T_db0ce_row11_col2\" class=\"data row11 col2\" >0.0016</td>\n","      <td id=\"T_db0ce_row11_col3\" class=\"data row11 col3\" >0.0020</td>\n","      <td id=\"T_db0ce_row11_col4\" class=\"data row11 col4\" >0.0020</td>\n","      <td id=\"T_db0ce_row11_col5\" class=\"data row11 col5\" >0.0000</td>\n","      <td id=\"T_db0ce_row11_col6\" class=\"data row11 col6\" >0.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fitting 10 folds for each of 4 candidates, totalling 40 fits\n","Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"]},{"output_type":"display_data","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7f738c125a20>"],"text/html":["<style type=\"text/css\">\n","</style>\n","<table id=\"T_faa4e\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_faa4e_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n","      <th id=\"T_faa4e_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n","      <th id=\"T_faa4e_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n","      <th id=\"T_faa4e_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n","      <th id=\"T_faa4e_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n","      <th id=\"T_faa4e_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n","      <th id=\"T_faa4e_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n","      <th id=\"T_faa4e_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_faa4e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_faa4e_row0_col0\" class=\"data row0 col0\" >Dummy Classifier</td>\n","      <td id=\"T_faa4e_row0_col1\" class=\"data row0 col1\" >0.6209</td>\n","      <td id=\"T_faa4e_row0_col2\" class=\"data row0 col2\" >0</td>\n","      <td id=\"T_faa4e_row0_col3\" class=\"data row0 col3\" >0.6209</td>\n","      <td id=\"T_faa4e_row0_col4\" class=\"data row0 col4\" >0.3855</td>\n","      <td id=\"T_faa4e_row0_col5\" class=\"data row0 col5\" >0.4757</td>\n","      <td id=\"T_faa4e_row0_col6\" class=\"data row0 col6\" >0.0000</td>\n","      <td id=\"T_faa4e_row0_col7\" class=\"data row0 col7\" >0.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["     rating_class prediction_label\n","9808         Good             Good\n","1499         Good             Good\n","4581         Good             Good\n","2293      Average             Good\n","3356         Good             Good\n","...           ...              ...\n","6611      Average             Good\n","335          Good             Good\n","5721      Average             Good\n","3412         Good             Good\n","559          Good             Good\n","\n","[1915 rows x 2 columns]\n"]},{"output_type":"display_data","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7f738c206050>"],"text/html":["<style type=\"text/css\">\n","</style>\n","<table id=\"T_3b51c\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_3b51c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n","      <th id=\"T_3b51c_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n","      <th id=\"T_3b51c_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n","      <th id=\"T_3b51c_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n","      <th id=\"T_3b51c_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n","      <th id=\"T_3b51c_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n","      <th id=\"T_3b51c_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n","      <th id=\"T_3b51c_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_3b51c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_3b51c_row0_col0\" class=\"data row0 col0\" >Dummy Classifier</td>\n","      <td id=\"T_3b51c_row0_col1\" class=\"data row0 col1\" >0.6209</td>\n","      <td id=\"T_3b51c_row0_col2\" class=\"data row0 col2\" >0</td>\n","      <td id=\"T_3b51c_row0_col3\" class=\"data row0 col3\" >0.6209</td>\n","      <td id=\"T_3b51c_row0_col4\" class=\"data row0 col4\" >0.3855</td>\n","      <td id=\"T_3b51c_row0_col5\" class=\"data row0 col5\" >0.4757</td>\n","      <td id=\"T_3b51c_row0_col6\" class=\"data row0 col6\" >0.0000</td>\n","      <td id=\"T_3b51c_row0_col7\" class=\"data row0 col7\" >0.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["     rating_class prediction_label\n","0       Excellent             Good\n","1       Excellent             Good\n","2       Excellent             Good\n","3         Average             Good\n","4       Excellent             Good\n","...           ...              ...\n","9952         Good             Good\n","9953    Excellent             Good\n","9954    Excellent             Good\n","9955    Excellent             Good\n","9956      Average             Good\n","\n","[6381 rows x 2 columns]\n","Transformation Pipeline and Model Successfully Saved\n"]}]},{"cell_type":"code","source":["# Perform approach 2 classification on the netflix dataset\n","from pycaret.classification import *\n","\n","# Select target and features\n","target_variable = 'rating_class_10'\n","five_cat_data = rating_df.copy()\n","\n","exp = ClassificationExperiment()\n","\n","# Step 2: Set up the classification environment\n","clf_setup = exp.setup(\n","    data=five_cat_data,\n","    target=target_variable,  # Target column\n","    session_id=42,  # For reproducibility\n","    ignore_features=['title', 'rating_class', 'rating'],  # Exclude irrelevant columns\n","    numeric_features=[\n","        'votes',\n","        *[f'nmf_feature_{i}' for i in range(1, 11)],  # Numeric NMF features\n","        *[f'nmf_desc_feature_{i}' for i in range(1, 11)]  # NMF description features\n","    ],\n","    categorical_features=['certificate', 'genre', 'stars', 'combined_text'],  # Treat these as categorical\n","    date_features=['year'],  # Treat 'year' as a date feature\n","    use_gpu=True,  # Use GPU for acceleration if available\n","    verbose=False,  # Suppress detailed output during setup\n","    experiment_name='rating_classification_10'  # Name the experiment for tracking\n",")\n","\n","# Step 3: Compare models to find the best one\n","class_10_best_model = clf_setup.compare_models(exclude=\"rf\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["df0cf71b9ee846cb870e29ec3d9e9d16","8ff2263bfd2c488b942552b204a18141","ebc2cb87b2124741b50952f019efeaa2","b89ec192106b432e88dbfd9c833920d0","eba7e7130ffe4c68bfcce140a8950a9b","ef65c5c4fbe34ace8c2811d1e6761b53","8c3acaadb3a54d2f8e466defff6479b8","904aa4cb48cc4d728c7a8dbb87b2788e","e58b3401ce9642c082ea9eaa53b14585","a7e9a40229d04cedb368b47c0a0064a1","6cf6754e80684ef894aaf7a01bb014bd"]},"id":"-4hmUnUvb3_C","executionInfo":{"status":"ok","timestamp":1732547951221,"user_tz":-480,"elapsed":1010203,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"outputId":"ae943f98-404b-49e5-cd2d-f283f92fa3e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n","[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n","[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n","[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 0\n","[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n","[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n","[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n","[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"]},{"output_type":"stream","name":"stderr","text":["[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n","[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n","Please recompile with CMake option -DUSE_CUDA=1\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7f7385e41240>"],"text/html":["<style type=\"text/css\">\n","#T_ce4ea th {\n","  text-align: left;\n","}\n","#T_ce4ea_row0_col0, #T_ce4ea_row0_col2, #T_ce4ea_row0_col5, #T_ce4ea_row0_col6, #T_ce4ea_row1_col0, #T_ce4ea_row1_col1, #T_ce4ea_row1_col3, #T_ce4ea_row1_col4, #T_ce4ea_row1_col5, #T_ce4ea_row1_col6, #T_ce4ea_row1_col7, #T_ce4ea_row2_col0, #T_ce4ea_row2_col1, #T_ce4ea_row2_col2, #T_ce4ea_row2_col3, #T_ce4ea_row2_col4, #T_ce4ea_row2_col5, #T_ce4ea_row2_col6, #T_ce4ea_row2_col7, #T_ce4ea_row3_col0, #T_ce4ea_row3_col1, #T_ce4ea_row3_col2, #T_ce4ea_row3_col3, #T_ce4ea_row3_col4, #T_ce4ea_row3_col5, #T_ce4ea_row3_col6, #T_ce4ea_row3_col7, #T_ce4ea_row4_col0, #T_ce4ea_row4_col1, #T_ce4ea_row4_col2, #T_ce4ea_row4_col3, #T_ce4ea_row4_col4, #T_ce4ea_row4_col5, #T_ce4ea_row4_col6, #T_ce4ea_row4_col7, #T_ce4ea_row5_col0, #T_ce4ea_row5_col1, #T_ce4ea_row5_col2, #T_ce4ea_row5_col3, #T_ce4ea_row5_col4, #T_ce4ea_row5_col5, #T_ce4ea_row5_col6, #T_ce4ea_row5_col7, #T_ce4ea_row6_col0, #T_ce4ea_row6_col1, #T_ce4ea_row6_col2, #T_ce4ea_row6_col3, #T_ce4ea_row6_col4, #T_ce4ea_row6_col5, #T_ce4ea_row6_col6, #T_ce4ea_row6_col7, #T_ce4ea_row7_col0, #T_ce4ea_row7_col1, #T_ce4ea_row7_col2, #T_ce4ea_row7_col3, #T_ce4ea_row7_col4, #T_ce4ea_row7_col7, #T_ce4ea_row8_col0, #T_ce4ea_row8_col1, #T_ce4ea_row8_col2, #T_ce4ea_row8_col3, #T_ce4ea_row8_col4, #T_ce4ea_row8_col5, #T_ce4ea_row8_col6, #T_ce4ea_row8_col7, #T_ce4ea_row9_col0, #T_ce4ea_row9_col1, #T_ce4ea_row9_col2, #T_ce4ea_row9_col3, #T_ce4ea_row9_col4, #T_ce4ea_row9_col5, #T_ce4ea_row9_col6, #T_ce4ea_row9_col7, #T_ce4ea_row10_col0, #T_ce4ea_row10_col1, #T_ce4ea_row10_col2, #T_ce4ea_row10_col3, #T_ce4ea_row10_col4, #T_ce4ea_row10_col5, #T_ce4ea_row10_col6, #T_ce4ea_row10_col7, #T_ce4ea_row11_col0, #T_ce4ea_row11_col1, #T_ce4ea_row11_col2, #T_ce4ea_row11_col3, #T_ce4ea_row11_col4, #T_ce4ea_row11_col5, #T_ce4ea_row11_col6, #T_ce4ea_row11_col7, #T_ce4ea_row12_col0, #T_ce4ea_row12_col1, #T_ce4ea_row12_col2, #T_ce4ea_row12_col3, #T_ce4ea_row12_col4, #T_ce4ea_row12_col5, #T_ce4ea_row12_col6, #T_ce4ea_row12_col7, #T_ce4ea_row13_col0, #T_ce4ea_row13_col1, #T_ce4ea_row13_col2, #T_ce4ea_row13_col3, #T_ce4ea_row13_col4, #T_ce4ea_row13_col5, #T_ce4ea_row13_col6, #T_ce4ea_row13_col7, #T_ce4ea_row14_col0, #T_ce4ea_row14_col1, #T_ce4ea_row14_col2, #T_ce4ea_row14_col3, #T_ce4ea_row14_col4, #T_ce4ea_row14_col5, #T_ce4ea_row14_col6, #T_ce4ea_row14_col7 {\n","  text-align: left;\n","}\n","#T_ce4ea_row0_col1, #T_ce4ea_row0_col3, #T_ce4ea_row0_col4, #T_ce4ea_row0_col7, #T_ce4ea_row1_col2, #T_ce4ea_row7_col5, #T_ce4ea_row7_col6 {\n","  text-align: left;\n","  background-color: yellow;\n","}\n","#T_ce4ea_row0_col8, #T_ce4ea_row1_col8, #T_ce4ea_row2_col8, #T_ce4ea_row3_col8, #T_ce4ea_row4_col8, #T_ce4ea_row5_col8, #T_ce4ea_row6_col8, #T_ce4ea_row7_col8, #T_ce4ea_row8_col8, #T_ce4ea_row9_col8, #T_ce4ea_row10_col8, #T_ce4ea_row11_col8, #T_ce4ea_row13_col8, #T_ce4ea_row14_col8 {\n","  text-align: left;\n","  background-color: lightgrey;\n","}\n","#T_ce4ea_row12_col8 {\n","  text-align: left;\n","  background-color: yellow;\n","  background-color: lightgrey;\n","}\n","</style>\n","<table id=\"T_ce4ea\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_ce4ea_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n","      <th id=\"T_ce4ea_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n","      <th id=\"T_ce4ea_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n","      <th id=\"T_ce4ea_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n","      <th id=\"T_ce4ea_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n","      <th id=\"T_ce4ea_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n","      <th id=\"T_ce4ea_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n","      <th id=\"T_ce4ea_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n","      <th id=\"T_ce4ea_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_ce4ea_level0_row0\" class=\"row_heading level0 row0\" >catboost</th>\n","      <td id=\"T_ce4ea_row0_col0\" class=\"data row0 col0\" >CatBoost Classifier</td>\n","      <td id=\"T_ce4ea_row0_col1\" class=\"data row0 col1\" >0.3594</td>\n","      <td id=\"T_ce4ea_row0_col2\" class=\"data row0 col2\" >0.5739</td>\n","      <td id=\"T_ce4ea_row0_col3\" class=\"data row0 col3\" >0.3594</td>\n","      <td id=\"T_ce4ea_row0_col4\" class=\"data row0 col4\" >0.5058</td>\n","      <td id=\"T_ce4ea_row0_col5\" class=\"data row0 col5\" >0.2595</td>\n","      <td id=\"T_ce4ea_row0_col6\" class=\"data row0 col6\" >0.0919</td>\n","      <td id=\"T_ce4ea_row0_col7\" class=\"data row0 col7\" >0.1667</td>\n","      <td id=\"T_ce4ea_row0_col8\" class=\"data row0 col8\" >18.5440</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ce4ea_level0_row1\" class=\"row_heading level0 row1\" >et</th>\n","      <td id=\"T_ce4ea_row1_col0\" class=\"data row1 col0\" >Extra Trees Classifier</td>\n","      <td id=\"T_ce4ea_row1_col1\" class=\"data row1 col1\" >0.3565</td>\n","      <td id=\"T_ce4ea_row1_col2\" class=\"data row1 col2\" >0.6051</td>\n","      <td id=\"T_ce4ea_row1_col3\" class=\"data row1 col3\" >0.3565</td>\n","      <td id=\"T_ce4ea_row1_col4\" class=\"data row1 col4\" >0.4822</td>\n","      <td id=\"T_ce4ea_row1_col5\" class=\"data row1 col5\" >0.2521</td>\n","      <td id=\"T_ce4ea_row1_col6\" class=\"data row1 col6\" >0.0858</td>\n","      <td id=\"T_ce4ea_row1_col7\" class=\"data row1 col7\" >0.1622</td>\n","      <td id=\"T_ce4ea_row1_col8\" class=\"data row1 col8\" >0.6760</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ce4ea_level0_row2\" class=\"row_heading level0 row2\" >gbc</th>\n","      <td id=\"T_ce4ea_row2_col0\" class=\"data row2 col0\" >Gradient Boosting Classifier</td>\n","      <td id=\"T_ce4ea_row2_col1\" class=\"data row2 col1\" >0.3536</td>\n","      <td id=\"T_ce4ea_row2_col2\" class=\"data row2 col2\" >0.0000</td>\n","      <td id=\"T_ce4ea_row2_col3\" class=\"data row2 col3\" >0.3536</td>\n","      <td id=\"T_ce4ea_row2_col4\" class=\"data row2 col4\" >0.4505</td>\n","      <td id=\"T_ce4ea_row2_col5\" class=\"data row2 col5\" >0.2615</td>\n","      <td id=\"T_ce4ea_row2_col6\" class=\"data row2 col6\" >0.0886</td>\n","      <td id=\"T_ce4ea_row2_col7\" class=\"data row2 col7\" >0.1495</td>\n","      <td id=\"T_ce4ea_row2_col8\" class=\"data row2 col8\" >26.1310</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ce4ea_level0_row3\" class=\"row_heading level0 row3\" >xgboost</th>\n","      <td id=\"T_ce4ea_row3_col0\" class=\"data row3 col0\" >Extreme Gradient Boosting</td>\n","      <td id=\"T_ce4ea_row3_col1\" class=\"data row3 col1\" >0.3504</td>\n","      <td id=\"T_ce4ea_row3_col2\" class=\"data row3 col2\" >0.5346</td>\n","      <td id=\"T_ce4ea_row3_col3\" class=\"data row3 col3\" >0.3504</td>\n","      <td id=\"T_ce4ea_row3_col4\" class=\"data row3 col4\" >0.4714</td>\n","      <td id=\"T_ce4ea_row3_col5\" class=\"data row3 col5\" >0.2815</td>\n","      <td id=\"T_ce4ea_row3_col6\" class=\"data row3 col6\" >0.0953</td>\n","      <td id=\"T_ce4ea_row3_col7\" class=\"data row3 col7\" >0.1380</td>\n","      <td id=\"T_ce4ea_row3_col8\" class=\"data row3 col8\" >3.8840</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ce4ea_level0_row4\" class=\"row_heading level0 row4\" >lda</th>\n","      <td id=\"T_ce4ea_row4_col0\" class=\"data row4 col0\" >Linear Discriminant Analysis</td>\n","      <td id=\"T_ce4ea_row4_col1\" class=\"data row4 col1\" >0.3502</td>\n","      <td id=\"T_ce4ea_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n","      <td id=\"T_ce4ea_row4_col3\" class=\"data row4 col3\" >0.3502</td>\n","      <td id=\"T_ce4ea_row4_col4\" class=\"data row4 col4\" >0.4613</td>\n","      <td id=\"T_ce4ea_row4_col5\" class=\"data row4 col5\" >0.2428</td>\n","      <td id=\"T_ce4ea_row4_col6\" class=\"data row4 col6\" >0.0789</td>\n","      <td id=\"T_ce4ea_row4_col7\" class=\"data row4 col7\" >0.1493</td>\n","      <td id=\"T_ce4ea_row4_col8\" class=\"data row4 col8\" >0.3200</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ce4ea_level0_row5\" class=\"row_heading level0 row5\" >ada</th>\n","      <td id=\"T_ce4ea_row5_col0\" class=\"data row5 col0\" >Ada Boost Classifier</td>\n","      <td id=\"T_ce4ea_row5_col1\" class=\"data row5 col1\" >0.3497</td>\n","      <td id=\"T_ce4ea_row5_col2\" class=\"data row5 col2\" >0.0000</td>\n","      <td id=\"T_ce4ea_row5_col3\" class=\"data row5 col3\" >0.3497</td>\n","      <td id=\"T_ce4ea_row5_col4\" class=\"data row5 col4\" >0.2893</td>\n","      <td id=\"T_ce4ea_row5_col5\" class=\"data row5 col5\" >0.2330</td>\n","      <td id=\"T_ce4ea_row5_col6\" class=\"data row5 col6\" >0.0699</td>\n","      <td id=\"T_ce4ea_row5_col7\" class=\"data row5 col7\" >0.1408</td>\n","      <td id=\"T_ce4ea_row5_col8\" class=\"data row5 col8\" >0.9580</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ce4ea_level0_row6\" class=\"row_heading level0 row6\" >lightgbm</th>\n","      <td id=\"T_ce4ea_row6_col0\" class=\"data row6 col0\" >Light Gradient Boosting Machine</td>\n","      <td id=\"T_ce4ea_row6_col1\" class=\"data row6 col1\" >0.3471</td>\n","      <td id=\"T_ce4ea_row6_col2\" class=\"data row6 col2\" >0.5203</td>\n","      <td id=\"T_ce4ea_row6_col3\" class=\"data row6 col3\" >0.3471</td>\n","      <td id=\"T_ce4ea_row6_col4\" class=\"data row6 col4\" >0.4344</td>\n","      <td id=\"T_ce4ea_row6_col5\" class=\"data row6 col5\" >0.2688</td>\n","      <td id=\"T_ce4ea_row6_col6\" class=\"data row6 col6\" >0.0882</td>\n","      <td id=\"T_ce4ea_row6_col7\" class=\"data row6 col7\" >0.1348</td>\n","      <td id=\"T_ce4ea_row6_col8\" class=\"data row6 col8\" >4.3680</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ce4ea_level0_row7\" class=\"row_heading level0 row7\" >knn</th>\n","      <td id=\"T_ce4ea_row7_col0\" class=\"data row7 col0\" >K Neighbors Classifier</td>\n","      <td id=\"T_ce4ea_row7_col1\" class=\"data row7 col1\" >0.3318</td>\n","      <td id=\"T_ce4ea_row7_col2\" class=\"data row7 col2\" >0.5450</td>\n","      <td id=\"T_ce4ea_row7_col3\" class=\"data row7 col3\" >0.3318</td>\n","      <td id=\"T_ce4ea_row7_col4\" class=\"data row7 col4\" >0.3278</td>\n","      <td id=\"T_ce4ea_row7_col5\" class=\"data row7 col5\" >0.3258</td>\n","      <td id=\"T_ce4ea_row7_col6\" class=\"data row7 col6\" >0.1105</td>\n","      <td id=\"T_ce4ea_row7_col7\" class=\"data row7 col7\" >0.1111</td>\n","      <td id=\"T_ce4ea_row7_col8\" class=\"data row7 col8\" >0.2230</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ce4ea_level0_row8\" class=\"row_heading level0 row8\" >lr</th>\n","      <td id=\"T_ce4ea_row8_col0\" class=\"data row8 col0\" >Logistic Regression</td>\n","      <td id=\"T_ce4ea_row8_col1\" class=\"data row8 col1\" >0.3229</td>\n","      <td id=\"T_ce4ea_row8_col2\" class=\"data row8 col2\" >0.0000</td>\n","      <td id=\"T_ce4ea_row8_col3\" class=\"data row8 col3\" >0.3229</td>\n","      <td id=\"T_ce4ea_row8_col4\" class=\"data row8 col4\" >0.2454</td>\n","      <td id=\"T_ce4ea_row8_col5\" class=\"data row8 col5\" >0.2162</td>\n","      <td id=\"T_ce4ea_row8_col6\" class=\"data row8 col6\" >0.0331</td>\n","      <td id=\"T_ce4ea_row8_col7\" class=\"data row8 col7\" >0.0550</td>\n","      <td id=\"T_ce4ea_row8_col8\" class=\"data row8 col8\" >4.1730</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ce4ea_level0_row9\" class=\"row_heading level0 row9\" >dt</th>\n","      <td id=\"T_ce4ea_row9_col0\" class=\"data row9 col0\" >Decision Tree Classifier</td>\n","      <td id=\"T_ce4ea_row9_col1\" class=\"data row9 col1\" >0.3229</td>\n","      <td id=\"T_ce4ea_row9_col2\" class=\"data row9 col2\" >0.4820</td>\n","      <td id=\"T_ce4ea_row9_col3\" class=\"data row9 col3\" >0.3229</td>\n","      <td id=\"T_ce4ea_row9_col4\" class=\"data row9 col4\" >0.3598</td>\n","      <td id=\"T_ce4ea_row9_col5\" class=\"data row9 col5\" >0.2765</td>\n","      <td id=\"T_ce4ea_row9_col6\" class=\"data row9 col6\" >0.0760</td>\n","      <td id=\"T_ce4ea_row9_col7\" class=\"data row9 col7\" >0.0957</td>\n","      <td id=\"T_ce4ea_row9_col8\" class=\"data row9 col8\" >0.2480</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ce4ea_level0_row10\" class=\"row_heading level0 row10\" >dummy</th>\n","      <td id=\"T_ce4ea_row10_col0\" class=\"data row10 col0\" >Dummy Classifier</td>\n","      <td id=\"T_ce4ea_row10_col1\" class=\"data row10 col1\" >0.3032</td>\n","      <td id=\"T_ce4ea_row10_col2\" class=\"data row10 col2\" >0.4500</td>\n","      <td id=\"T_ce4ea_row10_col3\" class=\"data row10 col3\" >0.3032</td>\n","      <td id=\"T_ce4ea_row10_col4\" class=\"data row10 col4\" >0.0919</td>\n","      <td id=\"T_ce4ea_row10_col5\" class=\"data row10 col5\" >0.1411</td>\n","      <td id=\"T_ce4ea_row10_col6\" class=\"data row10 col6\" >0.0000</td>\n","      <td id=\"T_ce4ea_row10_col7\" class=\"data row10 col7\" >0.0000</td>\n","      <td id=\"T_ce4ea_row10_col8\" class=\"data row10 col8\" >0.1930</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ce4ea_level0_row11\" class=\"row_heading level0 row11\" >ridge</th>\n","      <td id=\"T_ce4ea_row11_col0\" class=\"data row11 col0\" >Ridge Classifier</td>\n","      <td id=\"T_ce4ea_row11_col1\" class=\"data row11 col1\" >0.2743</td>\n","      <td id=\"T_ce4ea_row11_col2\" class=\"data row11 col2\" >0.0000</td>\n","      <td id=\"T_ce4ea_row11_col3\" class=\"data row11 col3\" >0.2743</td>\n","      <td id=\"T_ce4ea_row11_col4\" class=\"data row11 col4\" >0.3638</td>\n","      <td id=\"T_ce4ea_row11_col5\" class=\"data row11 col5\" >0.1699</td>\n","      <td id=\"T_ce4ea_row11_col6\" class=\"data row11 col6\" >0.0488</td>\n","      <td id=\"T_ce4ea_row11_col7\" class=\"data row11 col7\" >0.0987</td>\n","      <td id=\"T_ce4ea_row11_col8\" class=\"data row11 col8\" >0.2320</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ce4ea_level0_row12\" class=\"row_heading level0 row12\" >nb</th>\n","      <td id=\"T_ce4ea_row12_col0\" class=\"data row12 col0\" >Naive Bayes</td>\n","      <td id=\"T_ce4ea_row12_col1\" class=\"data row12 col1\" >0.2215</td>\n","      <td id=\"T_ce4ea_row12_col2\" class=\"data row12 col2\" >0.5308</td>\n","      <td id=\"T_ce4ea_row12_col3\" class=\"data row12 col3\" >0.2215</td>\n","      <td id=\"T_ce4ea_row12_col4\" class=\"data row12 col4\" >0.2690</td>\n","      <td id=\"T_ce4ea_row12_col5\" class=\"data row12 col5\" >0.1966</td>\n","      <td id=\"T_ce4ea_row12_col6\" class=\"data row12 col6\" >0.0406</td>\n","      <td id=\"T_ce4ea_row12_col7\" class=\"data row12 col7\" >0.0466</td>\n","      <td id=\"T_ce4ea_row12_col8\" class=\"data row12 col8\" >0.1890</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ce4ea_level0_row13\" class=\"row_heading level0 row13\" >qda</th>\n","      <td id=\"T_ce4ea_row13_col0\" class=\"data row13 col0\" >Quadratic Discriminant Analysis</td>\n","      <td id=\"T_ce4ea_row13_col1\" class=\"data row13 col1\" >0.1381</td>\n","      <td id=\"T_ce4ea_row13_col2\" class=\"data row13 col2\" >0.0000</td>\n","      <td id=\"T_ce4ea_row13_col3\" class=\"data row13 col3\" >0.1381</td>\n","      <td id=\"T_ce4ea_row13_col4\" class=\"data row13 col4\" >0.3208</td>\n","      <td id=\"T_ce4ea_row13_col5\" class=\"data row13 col5\" >0.1112</td>\n","      <td id=\"T_ce4ea_row13_col6\" class=\"data row13 col6\" >0.0120</td>\n","      <td id=\"T_ce4ea_row13_col7\" class=\"data row13 col7\" >0.0180</td>\n","      <td id=\"T_ce4ea_row13_col8\" class=\"data row13 col8\" >0.3600</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ce4ea_level0_row14\" class=\"row_heading level0 row14\" >svm</th>\n","      <td id=\"T_ce4ea_row14_col0\" class=\"data row14 col0\" >SVM - Linear Kernel</td>\n","      <td id=\"T_ce4ea_row14_col1\" class=\"data row14 col1\" >0.0040</td>\n","      <td id=\"T_ce4ea_row14_col2\" class=\"data row14 col2\" >0.0000</td>\n","      <td id=\"T_ce4ea_row14_col3\" class=\"data row14 col3\" >0.0040</td>\n","      <td id=\"T_ce4ea_row14_col4\" class=\"data row14 col4\" >0.0001</td>\n","      <td id=\"T_ce4ea_row14_col5\" class=\"data row14 col5\" >0.0001</td>\n","      <td id=\"T_ce4ea_row14_col6\" class=\"data row14 col6\" >-0.0004</td>\n","      <td id=\"T_ce4ea_row14_col7\" class=\"data row14 col7\" >-0.0007</td>\n","      <td id=\"T_ce4ea_row14_col8\" class=\"data row14 col8\" >37.7840</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[I] [23:03:05.562640] Unused keyword parameter: n_jobs during cuML estimator initialization\n"]}]},{"cell_type":"code","source":["# # Tune model\n","class_10_tuned_model = clf_setup.tune_model(class_10_best_model)\n","\n","# Validate the tuned model on test data\n","validation_results = clf_setup.predict_model(class_10_tuned_model)\n","print(validation_results[['rating_class_10', 'prediction_label']])\n","\n","# # Finalize the model\n","class_10_final_model = clf_setup.finalize_model(class_10_tuned_model)\n","\n","# # Make predictions on the test set\n","predictions = clf_setup.predict_model(class_10_final_model, five_cat_data)\n","print(predictions[['rating_class_10', 'prediction_label']])\n","\n","rating_class_10_classifier = clf_setup.save_model(final_model, 'rating_class_10_classifier')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":966,"referenced_widgets":["fe83245aa4ec4e3f968a29bd5244161a","ae288b9bfa39472c820fe3b55fcfae8e","c9bd52062d2041818acb5bbc5bbb7d7e","4fd80b07c1d04aaea344ca953c88c5ce","80e730cbbe98438aa612904691a3a516","9069e36adab84ab68b7e167df3648f49","257356496399429f85103dd798aeb897","3ab2ad514355420ea311d4c29f443938","29900edfd6ef40508c5e171953e29e4c","6ef91e438e2648da9c1a71c073f3bbf8","ed02dbc2f2634c3e92edd6ca0230fd13"]},"id":"Nki5qPDjb7zy","executionInfo":{"status":"ok","timestamp":1732548554206,"user_tz":-480,"elapsed":578450,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"outputId":"1d7fdb88-aaeb-4116-b681-7cce64047baa"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7f72f01e4eb0>"],"text/html":["<style type=\"text/css\">\n","#T_cb637_row10_col0, #T_cb637_row10_col1, #T_cb637_row10_col2, #T_cb637_row10_col3, #T_cb637_row10_col4, #T_cb637_row10_col5, #T_cb637_row10_col6 {\n","  background: yellow;\n","}\n","</style>\n","<table id=\"T_cb637\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_cb637_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n","      <th id=\"T_cb637_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n","      <th id=\"T_cb637_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n","      <th id=\"T_cb637_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n","      <th id=\"T_cb637_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n","      <th id=\"T_cb637_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n","      <th id=\"T_cb637_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n","    </tr>\n","    <tr>\n","      <th class=\"index_name level0\" >Fold</th>\n","      <th class=\"blank col0\" >&nbsp;</th>\n","      <th class=\"blank col1\" >&nbsp;</th>\n","      <th class=\"blank col2\" >&nbsp;</th>\n","      <th class=\"blank col3\" >&nbsp;</th>\n","      <th class=\"blank col4\" >&nbsp;</th>\n","      <th class=\"blank col5\" >&nbsp;</th>\n","      <th class=\"blank col6\" >&nbsp;</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_cb637_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_cb637_row0_col0\" class=\"data row0 col0\" >0.3579</td>\n","      <td id=\"T_cb637_row0_col1\" class=\"data row0 col1\" >0.6074</td>\n","      <td id=\"T_cb637_row0_col2\" class=\"data row0 col2\" >0.3579</td>\n","      <td id=\"T_cb637_row0_col3\" class=\"data row0 col3\" >0.5493</td>\n","      <td id=\"T_cb637_row0_col4\" class=\"data row0 col4\" >0.2490</td>\n","      <td id=\"T_cb637_row0_col5\" class=\"data row0 col5\" >0.0876</td>\n","      <td id=\"T_cb637_row0_col6\" class=\"data row0 col6\" >0.1749</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_cb637_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n","      <td id=\"T_cb637_row1_col0\" class=\"data row1 col0\" >0.3826</td>\n","      <td id=\"T_cb637_row1_col1\" class=\"data row1 col1\" >0.6340</td>\n","      <td id=\"T_cb637_row1_col2\" class=\"data row1 col2\" >0.3826</td>\n","      <td id=\"T_cb637_row1_col3\" class=\"data row1 col3\" >0.6814</td>\n","      <td id=\"T_cb637_row1_col4\" class=\"data row1 col4\" >0.2877</td>\n","      <td id=\"T_cb637_row1_col5\" class=\"data row1 col5\" >0.1211</td>\n","      <td id=\"T_cb637_row1_col6\" class=\"data row1 col6\" >0.2205</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_cb637_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n","      <td id=\"T_cb637_row2_col0\" class=\"data row2 col0\" >0.3624</td>\n","      <td id=\"T_cb637_row2_col1\" class=\"data row2 col1\" >0.6064</td>\n","      <td id=\"T_cb637_row2_col2\" class=\"data row2 col2\" >0.3624</td>\n","      <td id=\"T_cb637_row2_col3\" class=\"data row2 col3\" >0.5266</td>\n","      <td id=\"T_cb637_row2_col4\" class=\"data row2 col4\" >0.2565</td>\n","      <td id=\"T_cb637_row2_col5\" class=\"data row2 col5\" >0.0949</td>\n","      <td id=\"T_cb637_row2_col6\" class=\"data row2 col6\" >0.1832</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_cb637_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n","      <td id=\"T_cb637_row3_col0\" class=\"data row3 col0\" >0.3669</td>\n","      <td id=\"T_cb637_row3_col1\" class=\"data row3 col1\" >0.6100</td>\n","      <td id=\"T_cb637_row3_col2\" class=\"data row3 col2\" >0.3669</td>\n","      <td id=\"T_cb637_row3_col3\" class=\"data row3 col3\" >0.5937</td>\n","      <td id=\"T_cb637_row3_col4\" class=\"data row3 col4\" >0.2668</td>\n","      <td id=\"T_cb637_row3_col5\" class=\"data row3 col5\" >0.0995</td>\n","      <td id=\"T_cb637_row3_col6\" class=\"data row3 col6\" >0.1840</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_cb637_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n","      <td id=\"T_cb637_row4_col0\" class=\"data row4 col0\" >0.3490</td>\n","      <td id=\"T_cb637_row4_col1\" class=\"data row4 col1\" >0.6166</td>\n","      <td id=\"T_cb637_row4_col2\" class=\"data row4 col2\" >0.3490</td>\n","      <td id=\"T_cb637_row4_col3\" class=\"data row4 col3\" >0.3486</td>\n","      <td id=\"T_cb637_row4_col4\" class=\"data row4 col4\" >0.2426</td>\n","      <td id=\"T_cb637_row4_col5\" class=\"data row4 col5\" >0.0758</td>\n","      <td id=\"T_cb637_row4_col6\" class=\"data row4 col6\" >0.1366</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_cb637_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n","      <td id=\"T_cb637_row5_col0\" class=\"data row5 col0\" >0.3468</td>\n","      <td id=\"T_cb637_row5_col1\" class=\"data row5 col1\" >0.6426</td>\n","      <td id=\"T_cb637_row5_col2\" class=\"data row5 col2\" >0.3468</td>\n","      <td id=\"T_cb637_row5_col3\" class=\"data row5 col3\" >0.4897</td>\n","      <td id=\"T_cb637_row5_col4\" class=\"data row5 col4\" >0.2396</td>\n","      <td id=\"T_cb637_row5_col5\" class=\"data row5 col5\" >0.0737</td>\n","      <td id=\"T_cb637_row5_col6\" class=\"data row5 col6\" >0.1408</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_cb637_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n","      <td id=\"T_cb637_row6_col0\" class=\"data row6 col0\" >0.3632</td>\n","      <td id=\"T_cb637_row6_col1\" class=\"data row6 col1\" >0.0000</td>\n","      <td id=\"T_cb637_row6_col2\" class=\"data row6 col2\" >0.3632</td>\n","      <td id=\"T_cb637_row6_col3\" class=\"data row6 col3\" >0.6747</td>\n","      <td id=\"T_cb637_row6_col4\" class=\"data row6 col4\" >0.2647</td>\n","      <td id=\"T_cb637_row6_col5\" class=\"data row6 col5\" >0.0955</td>\n","      <td id=\"T_cb637_row6_col6\" class=\"data row6 col6\" >0.1827</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_cb637_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n","      <td id=\"T_cb637_row7_col0\" class=\"data row7 col0\" >0.3363</td>\n","      <td id=\"T_cb637_row7_col1\" class=\"data row7 col1\" >0.6029</td>\n","      <td id=\"T_cb637_row7_col2\" class=\"data row7 col2\" >0.3363</td>\n","      <td id=\"T_cb637_row7_col3\" class=\"data row7 col3\" >0.6038</td>\n","      <td id=\"T_cb637_row7_col4\" class=\"data row7 col4\" >0.2166</td>\n","      <td id=\"T_cb637_row7_col5\" class=\"data row7 col5\" >0.0563</td>\n","      <td id=\"T_cb637_row7_col6\" class=\"data row7 col6\" >0.1310</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_cb637_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n","      <td id=\"T_cb637_row8_col0\" class=\"data row8 col0\" >0.3565</td>\n","      <td id=\"T_cb637_row8_col1\" class=\"data row8 col1\" >0.6412</td>\n","      <td id=\"T_cb637_row8_col2\" class=\"data row8 col2\" >0.3565</td>\n","      <td id=\"T_cb637_row8_col3\" class=\"data row8 col3\" >0.4264</td>\n","      <td id=\"T_cb637_row8_col4\" class=\"data row8 col4\" >0.2496</td>\n","      <td id=\"T_cb637_row8_col5\" class=\"data row8 col5\" >0.0910</td>\n","      <td id=\"T_cb637_row8_col6\" class=\"data row8 col6\" >0.1671</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_cb637_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n","      <td id=\"T_cb637_row9_col0\" class=\"data row9 col0\" >0.3386</td>\n","      <td id=\"T_cb637_row9_col1\" class=\"data row9 col1\" >0.6446</td>\n","      <td id=\"T_cb637_row9_col2\" class=\"data row9 col2\" >0.3386</td>\n","      <td id=\"T_cb637_row9_col3\" class=\"data row9 col3\" >0.4030</td>\n","      <td id=\"T_cb637_row9_col4\" class=\"data row9 col4\" >0.2498</td>\n","      <td id=\"T_cb637_row9_col5\" class=\"data row9 col5\" >0.0639</td>\n","      <td id=\"T_cb637_row9_col6\" class=\"data row9 col6\" >0.1032</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_cb637_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n","      <td id=\"T_cb637_row10_col0\" class=\"data row10 col0\" >0.3560</td>\n","      <td id=\"T_cb637_row10_col1\" class=\"data row10 col1\" >0.5606</td>\n","      <td id=\"T_cb637_row10_col2\" class=\"data row10 col2\" >0.3560</td>\n","      <td id=\"T_cb637_row10_col3\" class=\"data row10 col3\" >0.5297</td>\n","      <td id=\"T_cb637_row10_col4\" class=\"data row10 col4\" >0.2523</td>\n","      <td id=\"T_cb637_row10_col5\" class=\"data row10 col5\" >0.0859</td>\n","      <td id=\"T_cb637_row10_col6\" class=\"data row10 col6\" >0.1624</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_cb637_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n","      <td id=\"T_cb637_row11_col0\" class=\"data row11 col0\" >0.0132</td>\n","      <td id=\"T_cb637_row11_col1\" class=\"data row11 col1\" >0.1875</td>\n","      <td id=\"T_cb637_row11_col2\" class=\"data row11 col2\" >0.0132</td>\n","      <td id=\"T_cb637_row11_col3\" class=\"data row11 col3\" >0.1073</td>\n","      <td id=\"T_cb637_row11_col4\" class=\"data row11 col4\" >0.0179</td>\n","      <td id=\"T_cb637_row11_col5\" class=\"data row11 col5\" >0.0180</td>\n","      <td id=\"T_cb637_row11_col6\" class=\"data row11 col6\" >0.0324</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fitting 10 folds for each of 10 candidates, totalling 100 fits\n","Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"]},{"output_type":"display_data","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7f72f10cfa60>"],"text/html":["<style type=\"text/css\">\n","</style>\n","<table id=\"T_1a244\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_1a244_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n","      <th id=\"T_1a244_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n","      <th id=\"T_1a244_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n","      <th id=\"T_1a244_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n","      <th id=\"T_1a244_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n","      <th id=\"T_1a244_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n","      <th id=\"T_1a244_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n","      <th id=\"T_1a244_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_1a244_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_1a244_row0_col0\" class=\"data row0 col0\" >CatBoost Classifier</td>\n","      <td id=\"T_1a244_row0_col1\" class=\"data row0 col1\" >0.3661</td>\n","      <td id=\"T_1a244_row0_col2\" class=\"data row0 col2\" >0.6489</td>\n","      <td id=\"T_1a244_row0_col3\" class=\"data row0 col3\" >0.3661</td>\n","      <td id=\"T_1a244_row0_col4\" class=\"data row0 col4\" >0.5355</td>\n","      <td id=\"T_1a244_row0_col5\" class=\"data row0 col5\" >0.2651</td>\n","      <td id=\"T_1a244_row0_col6\" class=\"data row0 col6\" >0.1004</td>\n","      <td id=\"T_1a244_row0_col7\" class=\"data row0 col7\" >0.1864</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["      rating_class_10  prediction_label\n","2032                7                 7\n","4977                8                 7\n","4019                7                 7\n","2961                6                 7\n","9862                8                 8\n","...               ...               ...\n","1906                7                 7\n","8711                7                 7\n","202                 7                 7\n","9303                8                 8\n","9470                7                 7\n","\n","[1915 rows x 2 columns]\n"]},{"output_type":"display_data","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7f73a3653280>"],"text/html":["<style type=\"text/css\">\n","</style>\n","<table id=\"T_de0f5\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_de0f5_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n","      <th id=\"T_de0f5_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n","      <th id=\"T_de0f5_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n","      <th id=\"T_de0f5_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n","      <th id=\"T_de0f5_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n","      <th id=\"T_de0f5_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n","      <th id=\"T_de0f5_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n","      <th id=\"T_de0f5_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_de0f5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_de0f5_row0_col0\" class=\"data row0 col0\" >CatBoost Classifier</td>\n","      <td id=\"T_de0f5_row0_col1\" class=\"data row0 col1\" >0.9992</td>\n","      <td id=\"T_de0f5_row0_col2\" class=\"data row0 col2\" >1.0000</td>\n","      <td id=\"T_de0f5_row0_col3\" class=\"data row0 col3\" >0.9992</td>\n","      <td id=\"T_de0f5_row0_col4\" class=\"data row0 col4\" >0.9992</td>\n","      <td id=\"T_de0f5_row0_col5\" class=\"data row0 col5\" >0.9992</td>\n","      <td id=\"T_de0f5_row0_col6\" class=\"data row0 col6\" >0.9990</td>\n","      <td id=\"T_de0f5_row0_col7\" class=\"data row0 col7\" >0.9990</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["      rating_class_10  prediction_label\n","0                   8                 8\n","1                   9                 9\n","2                   9                 9\n","3                   6                 6\n","4                   9                 9\n","...               ...               ...\n","9952                6                 6\n","9953                8                 8\n","9954                9                 9\n","9955                8                 8\n","9956                6                 6\n","\n","[6381 rows x 2 columns]\n","Transformation Pipeline and Model Successfully Saved\n"]}]},{"cell_type":"markdown","source":["# Netflix Recommender System"],"metadata":{"id":"nPl0-UxAkhNx"}},{"cell_type":"code","execution_count":26,"metadata":{"id":"GfHzMtoU79ky","executionInfo":{"status":"ok","timestamp":1732626262259,"user_tz":-480,"elapsed":9,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}}},"outputs":[],"source":["# Create a recommender system\n","# Should we create another NMF on the processed netflix dataset?\n","# Think about the implications of doing so\n","# If not, how would we incorporate non-NMF features into the recommender system?"]},{"cell_type":"code","source":["# Preprocessing - Data Cleaning\n","# End goal to recommend similar shows, regardless of ratings and vote\n","import pandas as pd\n","import math\n","\n","netflix = pd.read_csv('netflix_recommender/netflix_movies.csv')\n","\n","duration_without_mins = netflix[netflix.duration.notna()]['duration'].copy().str.replace(' min', '').astype(int)\n","duration_mean = str(math.ceil(duration_without_mins.mean()))  + ' min'\n","netflix.duration.fillna(duration_mean, inplace=True)\n","\n","# # netflix = netflix.dropna()\n","\n","# remove non digits from year but keep - hypen character eg.(2018-2022)\n","netflix['year'] = netflix['year'].str.replace(r'[^0-9-]', '', regex=True)\n","\n","# take first digits of year as int\n","netflix['year'] = netflix['year'].str[:4]\n","netflix['year'] = pd.to_numeric(netflix['year'], errors='coerce').fillna(9999).astype(int)\n","\n","# convert duration column to remove the text ' min'\n","netflix['duration'] = netflix['duration'].str.replace(' min', '', regex=False).astype(int)\n","\n","# convert votes to int before calculating the median.\n","# Remove commas and convert to numeric\n","netflix['votes'] = netflix['votes'].str.replace(',', '', regex=False).astype(float)\n","\n","# fill na in the votes column with median\n","netflix['votes'] = netflix['votes'].fillna(netflix['votes'].median())\n","\n","# Now 'votes' contains numeric values without commas. Convert to int if necessary.\n","netflix['votes'] = netflix['votes'].astype(int)\n","\n","# convert rating to float\n","netflix['rating'] = netflix['rating'].astype(float)\n","\n","# fill empty rows in the rating column with median\n","netflix['rating'] = netflix['rating'].fillna(netflix['rating'].median())\n","\n","# Clean the 'stars' column\n","netflix['stars'] = netflix['stars'].str.replace(r\"\\|\\s*\", \",\", regex=True)\n","netflix['stars'] = netflix['stars'].str.replace(\"','\", \"\", regex=False).str.replace(\"', '\", \", \", regex=False).str.strip()\n","netflix['stars'] = netflix['stars'].str.replace(r\",\\s*,\", \",\", regex=True)  # Remove ', ,'\n","netflix['stars'] = netflix['stars'].str.replace(r\"\\[\\s*'\\s*|\\s*'\\s*\\]\", \"\", regex=True)  # Remove surrounding brackets and quotes\n","netflix['stars'] = netflix['stars'].str.replace(r\"', '    Stars:\", \"\", regex=True)  # Normalize 'Stars:' formatting\n","netflix['stars'] = netflix['stars'].str.replace(r\", '    Stars:\", \"\", regex=True)  # Normalize 'Stars:' formatting\n","netflix['stars'] = netflix['stars'].str.replace(r\" \\\", '\", \"\", regex=True)\n","netflix['stars'] = netflix['stars'].str.replace(r\" '    Star:',\", \"\", regex=True)\n","netflix['stars'] = netflix['stars'].str.replace(r\"', '    Star:\", \"\", regex=True)\n","netflix['stars'] = netflix['stars'].str.replace(r\"[\\[\\]]\", \"\", regex=True)  # Remove square brackets\n","netflix['stars'] = netflix['stars'].str.replace('\"', \"\", regex=False)  # Remove double quotes\n","netflix['stars'] = netflix['stars'].str.strip()  # Remove leading/trailing spaces\n","\n","\n","# save to csv\n","netflix.to_csv('netflix_recommender/netflix_movies_processed.csv', index=False)\n","\n","print(netflix.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82jmuJSJOJYa","executionInfo":{"status":"ok","timestamp":1732626262737,"user_tz":-480,"elapsed":476,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"outputId":"ed6f3949-728c-49fa-8476-1635a4e2d599"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["                    title  year certificate  duration  \\\n","0               Cobra Kai  2018       TV-14        30   \n","1               The Crown  2016       TV-MA        58   \n","2        Better Call Saul  2015       TV-MA        46   \n","3           Devil in Ohio  2022       TV-MA       356   \n","4  Cyberpunk: Edgerunners  2022       TV-MA        24   \n","\n","                          genre  rating  \\\n","0         Action, Comedy, Drama     8.5   \n","1     Biography, Drama, History     8.7   \n","2                  Crime, Drama     8.9   \n","3        Drama, Horror, Mystery     5.9   \n","4  Animation, Action, Adventure     8.6   \n","\n","                                         description  \\\n","0  Decades after their 1984 All Valley Karate Tou...   \n","1  Follows the political rivalries and romance of...   \n","2  The trials and tribulations of criminal lawyer...   \n","3  When a psychiatrist shelters a mysterious cult...   \n","4  A Street Kid trying to survive in a technology...   \n","\n","                                               stars   votes  \n","0  Ralph Macchio, William Zabka, Courtney Henggel...  177031  \n","1  Claire Foy, Olivia Colman, Imelda Staunton, Ma...  199885  \n","2  Bob Odenkirk, Rhea Seehorn, Jonathan Banks, Pa...  501384  \n","3  Emily Deschanel, Sam Jaeger, Gerardo Celasco, ...    9773  \n","4   Zach Aguilar, Kenichiro Ohashi, Emi Lo, Aoi Yki   15413  \n"]}]},{"cell_type":"code","execution_count":28,"metadata":{"id":"o83D5_O479ky","executionInfo":{"status":"ok","timestamp":1732626262739,"user_tz":-480,"elapsed":1,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}}},"outputs":[],"source":["# Using your choice, prepare the NMF features for recommender system\n","\n","# Perform the step necessary for applying cosine similarity\n","\n","# Apply the normalizer to the selected_nmf"]},{"cell_type":"code","source":["# Convert encode genre to true false as column header\n","\n","exploded_df = netflix.assign(genre_type=netflix['genre'].str.split(', ')).explode('genre_type')\n","\n","# Think of a way to indicate 1 for every genre that each title belongs to\n","genre_one_hot_df = pd.get_dummies(exploded_df['genre_type'])\n","genre_indicators_df = pd.concat([exploded_df[['title']], genre_one_hot_df], axis=1)\n","\n","# map for title and its hash\n","mapping = pd.DataFrame({\n","    'title': netflix['title'],\n","    'hash': [hash(title) for title in netflix['title']]\n","})\n","\n","# to use as index instead of title\n","genre_indicators_df['title'] = genre_indicators_df['title'].apply(hash)\n","# # Combine rows by title, taking the maximum value for each column\n","combined_df = genre_indicators_df.groupby('title', sort=False).max().astype(int)\n","\n","# # Reset index (optional, to make Title a regular column again)\n","combined_df.reset_index(inplace=True)\n","\n","hash_to_title = dict(zip(mapping['hash'], mapping['title']))\n","combined_df['title'] = combined_df['title'].map(hash_to_title)\n","\n","# combine this with the netflix df\n","netflix_recommender = netflix.merge(combined_df, on='title', how='left')\n","\n","# drop the column genre\n","netflix_recommender.drop(columns=['genre'], inplace=True)\n","\n","# convert column header to lowercase and replace spaces with hypen -\n","netflix_recommender.columns = netflix_recommender.columns.str.lower().str.replace(' ', '-')\n","\n","# save to csv\n","# netflix_recommender.to_csv('netflix_recommender/netflix_recommender.csv', index=False)"],"metadata":{"id":"XfGMB7RGeDJx","executionInfo":{"status":"ok","timestamp":1732626262836,"user_tz":-480,"elapsed":95,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","execution_count":30,"metadata":{"id":"MGfE0PvW79ky","executionInfo":{"status":"ok","timestamp":1732626262851,"user_tz":-480,"elapsed":4,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2067dacd-76eb-44c7-b75e-57c7fe8064c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["                    title  year certificate  duration  rating  \\\n","0               Cobra Kai  2018       TV-14        30     8.5   \n","1               The Crown  2016       TV-MA        58     8.7   \n","2        Better Call Saul  2015       TV-MA        46     8.9   \n","3           Devil in Ohio  2022       TV-MA       356     5.9   \n","4  Cyberpunk: Edgerunners  2022       TV-MA        24     8.6   \n","\n","                                         description  \\\n","0  Decades after their 1984 All Valley Karate Tou...   \n","1  Follows the political rivalries and romance of...   \n","2  The trials and tribulations of criminal lawyer...   \n","3  When a psychiatrist shelters a mysterious cult...   \n","4  A Street Kid trying to survive in a technology...   \n","\n","                                               stars   votes  action  \\\n","0  Ralph Macchio, William Zabka, Courtney Henggel...  177031       1   \n","1  Claire Foy, Olivia Colman, Imelda Staunton, Ma...  199885       0   \n","2  Bob Odenkirk, Rhea Seehorn, Jonathan Banks, Pa...  501384       0   \n","3  Emily Deschanel, Sam Jaeger, Gerardo Celasco, ...    9773       0   \n","4   Zach Aguilar, Kenichiro Ohashi, Emi Lo, Aoi Yki   15413       1   \n","\n","   adventure  ...  news  reality-tv  romance  sci-fi  short  sport  talk-show  \\\n","0          0  ...     0           0        0       0      0      0          0   \n","1          0  ...     0           0        0       0      0      0          0   \n","2          0  ...     0           0        0       0      0      0          0   \n","3          0  ...     0           0        0       0      0      0          0   \n","4          1  ...     0           0        0       0      0      0          0   \n","\n","   thriller  war  western  \n","0         0    0        0  \n","1         0    0        0  \n","2         0    0        0  \n","3         0    0        0  \n","4         0    0        0  \n","\n","[5 rows x 35 columns]\n"]}],"source":["# Check how the nmf_recommender looks like in a dataframe\n","print(netflix_recommender.head())"]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.cluster import KMeans\n","\n","# Clasify into similar clusters\n","\n","# Step 1: Preprocess Descriptions (Text Data)\n","netflix_recommender['description_clean'] = netflix_recommender['description'].str.lower().fillna('')\n","\n","# Step 2: Extract Features\n","# 2a. TF-IDF for Descriptions\n","tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n","tfidf_matrix = tfidf_vectorizer.fit_transform(netflix_recommender['description_clean'])\n","\n","# 2b. Genre-Based Feature Vector\n","genre_columns = [\n","    'action', 'adventure', 'animation', 'biography', 'comedy', 'crime',\n","    'documentary', 'drama', 'family', 'fantasy', 'history', 'horror',\n","    'music', 'mystery', 'news', 'reality-tv', 'romance', 'sci-fi', 'short',\n","    'sport', 'talk-show', 'thriller', 'war', 'western'\n","]\n","genre_matrix = netflix_recommender[genre_columns].values\n","\n","# Step 3: Combine Features\n","# Normalize genre matrix to the same scale as TF-IDF\n","scaler = StandardScaler()\n","normalized_genre_matrix = scaler.fit_transform(genre_matrix)\n","\n","\n","# Combine TF-IDF and normalized genre features\n","combined_matrix = np.hstack((tfidf_matrix.toarray(), normalized_genre_matrix))\n","\n","# Step 4: Perform Similarity Grouping\n","# Compute cosine similarity on the combined feature matrix\n","similarity_matrix = cosine_similarity(combined_matrix)\n","\n","# Step 5: Clustering (Optional)\n","num_clusters = 5\n","kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n","netflix_recommender['combined_cluster'] = kmeans.fit_predict(combined_matrix)\n","\n","# save netflix_recommender to csv\n","# netflix_recommender.to_csv('netflix_recommender/netflix_recommender_clustered.csv', index=False)\n","\n","data = netflix_recommender.copy()\n"],"metadata":{"id":"MRIOiZA7qy0h","executionInfo":{"status":"ok","timestamp":1732626265277,"user_tz":-480,"elapsed":2425,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","execution_count":32,"metadata":{"id":"iu2wZ2Lm79ky","executionInfo":{"status":"ok","timestamp":1732626265367,"user_tz":-480,"elapsed":56,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"75b46850-c4e4-4913-bf67-74094718d110"},"outputs":[{"output_type":"stream","name":"stdout","text":["Randomly Selected Title: Grand Army\n","title                                                       Grand Army\n","year                                                              2020\n","certificate                                                      TV-MA\n","duration                                                            49\n","rating                                                             7.2\n","description          Joey copes with a difficult setback in her cas...\n","stars                Silas Howard, Odessa Azion, Odley Jean, Amir ...\n","votes                                                              130\n","action                                                               0\n","adventure                                                            0\n","animation                                                            0\n","biography                                                            0\n","comedy                                                               0\n","crime                                                                0\n","documentary                                                          0\n","drama                                                                1\n","family                                                               0\n","fantasy                                                              0\n","film-noir                                                            0\n","game-show                                                            0\n","history                                                              0\n","horror                                                               0\n","music                                                                0\n","musical                                                              0\n","mystery                                                              0\n","news                                                                 0\n","reality-tv                                                           0\n","romance                                                              0\n","sci-fi                                                               0\n","short                                                                0\n","sport                                                                0\n","talk-show                                                            0\n","thriller                                                             0\n","war                                                                  0\n","western                                                              0\n","description_clean    joey copes with a difficult setback in her cas...\n","combined_cluster                                                     3\n","Name: 9244, dtype: object\n","\n","Top 20 Most Similar Titles:\n","                                           title  \\\n","5106  Quiet Victory: The Charlie Wedemeyer Story   \n","5656                               Freshman Year   \n","6016                       The Queen's Classroom   \n","9642                              Inventing Anna   \n","9012                                  Grand Army   \n","8888                                  Grand Army   \n","4323                               The Principal   \n","7472                                 The Postman   \n","4321                          The Gospel of John   \n","6419                                       Piola   \n","9023                                  Grand Army   \n","6329                                   Rich Kids   \n","2597                             Won't Back Down   \n","8869                                      Yankee   \n","2206                                  Marfa Girl   \n","2108                               A Man in Full   \n","7280                               The Chameleon   \n","138                               Inventing Anna   \n","2868                           The Day Will Come   \n","5951                                       Argon   \n","\n","                                            description  combined_cluster  \n","5106  A real-life story about a high school teacher ...                 3  \n","5656  The journey of two young people going off to c...                 3  \n","6016  Maya Akutsu, a new teacher who strives for per...                 3  \n","9642  Under pressure to finish the Anna article and ...                 3  \n","9012  Traumatised m, Joey spirals. Sid opens up in h...                 3  \n","8888  A bombing blocks away sends Grand Army High Sc...                 3  \n","4323  The Principal is set in a notoriously violent ...                 3  \n","7472  The story of Mario Jimnez, a fictional postma...                 3  \n","4321  The life and toils of Jesus Christ, depicted a...                 3  \n","6419  Two friends spend their time making rap music....                 3  \n","9023  Sid struggles with his secret. Nudged by her g...                 3  \n","6329  A group of troubled teens from a low-income co...                 3  \n","2597  Two determined mothers, one a teacher, look t...                 3  \n","8869  Real estate agent and drug smuggler Malcolm ge...                 3  \n","2206  A story centered on a directionless 16-year-ol...                 3  \n","2108  Follows an Atlanta real estate mogul as he fac...                 3  \n","7280  A young man pretends to be a long-lost son to ...                 3  \n","138   A journalist with a lot to prove investigates ...                 3  \n","2868  At the Orphanage Godhavn violence and humiliat...                 3  \n","5951  ARGON shows the struggles behind the scenes in...                 3  \n","Top 20 Most Similar Titles:\n","Title: Quiet Victory: The Charlie Wedemeyer Story | Similarity: 0.8511\n","Title: Freshman Year | Similarity: 0.8387\n","Title: The Queen's Classroom | Similarity: 0.8369\n","Title: Inventing Anna | Similarity: 0.8279\n","Title: Grand Army | Similarity: 0.8208\n","Title: Grand Army | Similarity: 0.8195\n","Title: The Principal | Similarity: 0.8195\n","Title: The Postman | Similarity: 0.8187\n","Title: The Gospel of John | Similarity: 0.8160\n","Title: Piola | Similarity: 0.8120\n","Title: Grand Army | Similarity: 0.8091\n","Title: Rich Kids | Similarity: 0.8086\n","Title: Won't Back Down | Similarity: 0.8050\n","Title: Yankee | Similarity: 0.8032\n","Title: Marfa Girl | Similarity: 0.8026\n","Title: A Man in Full | Similarity: 0.8008\n","Title: The Chameleon | Similarity: 0.8003\n","Title: Inventing Anna | Similarity: 0.7992\n","Title: The Day Will Come | Similarity: 0.7974\n","Title: Argon | Similarity: 0.7784\n"]}],"source":["# Randomly select a title from the netflix dataset\n","import random\n","\n","random_index = random.randint(0, len(data) - 1)\n","random_title = data.iloc[random_index]['title']\n","print(f\"Randomly Selected Title: {random_title}\")\n","\n","# Get the title's profile / embedding\n","print(data.iloc[random_index])\n","\n","# and find the top 20 most similar title\n","\n","similarity_scores = cosine_similarity([combined_matrix[random_index]], combined_matrix).flatten()\n","top_20_indices = similarity_scores.argsort()[::-1][1:21]  # Exclude the random title itself\n","similar_titles = data.iloc[top_20_indices][['title', 'description','combined_cluster']]\n","\n","# Display Results\n","print(\"\\nTop 20 Most Similar Titles:\")\n","print(similar_titles)\n","\n","# Calculate the cosine similarity between the random title and all other titles\n","top_20_similarities = [(data.iloc[i]['title'], similarity_scores[i]) for i in top_20_indices]\n","# Step 7: Print Top 20 Most Similar Titles with Cosine Similarity\n","print(\"Top 20 Most Similar Titles:\")\n","for title, score in top_20_similarities:\n","    print(f\"Title: {title} | Similarity: {score:.4f}\")"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"nr2mb2CI79ky","executionInfo":{"status":"ok","timestamp":1732626265370,"user_tz":-480,"elapsed":2,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}}},"outputs":[],"source":["# Can you improve the recommendation through the use of other features?\n","\n","# use genre and description as features\n","\n","# For each title, get the rating and the votes and present the top 5\n","# highest rated titles\n"]},{"cell_type":"code","source":["# Step 5: Recommend Movies\n","def recommend_movies(input_titles, top_n=10):\n","    # Find indices of input movies\n","    input_indices = data[data['title'].isin(input_titles)].index.tolist()\n","    if not input_indices or len(input_indices) < len(input_titles):\n","        missing_titles = set(input_titles) - set(data.iloc[input_indices]['title'])\n","        return f\"Could not find the following titles in the dataset: {', '.join(missing_titles)}\"\n","\n","    # Compute similarity scores for all movies relative to the input movies\n","    aggregated_scores = np.zeros(similarity_matrix.shape[0])\n","    for idx in input_indices:\n","        aggregated_scores += similarity_matrix[idx]\n","\n","    # Rank movies by similarity score, excluding the input movies\n","    aggregated_scores[input_indices] = -1  # Exclude input movies from recommendations\n","\n","    # Create a DataFrame with scores, ratings, and votes\n","    recommendation_data = data.copy()\n","    recommendation_data['similarity_score'] = aggregated_scores\n","\n","    # For each title, get the rating and the votes and present the top 5\n","    # highest rated titles\n","    # Sort by similarity score, then by rating, and then by votes\n","    recommendation_data = recommendation_data.sort_values(\n","        by=['similarity_score', 'rating', 'votes'], ascending=[False, False, False]\n","    )\n","\n","    # Select the top N recommended movies\n","    recommended_movies = recommendation_data.head(top_n)[['title', 'description', 'combined_cluster', 'rating', 'votes']]\n","\n","    return recommended_movies\n","\n","# Select 3 random rows from the title column\n","random_movies = netflix_recommender.sample(n=3)\n","print(random_movies[['title', 'description', 'combined_cluster']])\n","\n","# get the rows from the netflix_recommender\n","input_movies = random_movies['title'].tolist()\n","\n","# loop through the list of input_movies\n","for index, i in random_movies.iterrows():\n","    print(\"\\n === Input Movie === \")\n","    print(i[['title', 'description', 'combined_cluster']]) # Accessing series data by label\n","    print(\"\\n=== Recommended movies === \")\n","    print(recommend_movies([i['title']], top_n=5))\n","\n","# recommended_movies = recommend_movies(input_movies, top_n=10)\n","# print(\"\\nRecommended Movies:\")\n","# print(recommended_movies)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BLar599Bv_Wu","executionInfo":{"status":"ok","timestamp":1732626265467,"user_tz":-480,"elapsed":96,"user":{"displayName":"Dannel Azqore","userId":"01360291487342414671"}},"outputId":"7053930a-1f75-40da-b3ee-f0543a4c6d2c"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["                          title  \\\n","3232  Last Chance U: Basketball   \n","930                  White Girl   \n","2962                   Aelliseu   \n","\n","                                            description  combined_cluster  \n","3232  Explore an honest and gritty look inside the w...                 3  \n","930   Summer, New York City. A college girl falls ha...                 3  \n","2962  The story of detective Park Jin Gyeom who come...                 3  \n","\n"," === Input Movie === \n","title                                       Last Chance U: Basketball\n","description         Explore an honest and gritty look inside the w...\n","combined_cluster                                                    3\n","Name: 3232, dtype: object\n","\n","=== Recommended movies === \n","                            title  \\\n","2028                Last Chance U   \n","1947                        Cheer   \n","5153               The Short Game   \n","7133    Boca Juniors Confidential   \n","830   Formula 1: Drive to Survive   \n","\n","                                            description  combined_cluster  \\\n","2028  Intense look inside the world of junior colleg...                 3   \n","1947  In the small town of Corsicana, Texas, hard-dr...                 3   \n","5153  The best 7 year old golfers from around the wo...                 3   \n","7133  A closer look of Boca Juniors's players, fans ...                 3   \n","830   Docuseries following the FIA Formula One World...                 3   \n","\n","      rating  votes  \n","2028     8.4   6962  \n","1947     8.1   6381  \n","5153     7.3   1587  \n","7133     6.4    358  \n","830      8.6  39632  \n","\n"," === Input Movie === \n","title                                                      White Girl\n","description         Summer, New York City. A college girl falls ha...\n","combined_cluster                                                    3\n","Name: 930, dtype: object\n","\n","=== Recommended movies === \n","                  title                                        description  \\\n","3040      The Big Combo  A police lieutenant is ordered to stop investi...   \n","5784            Dayveon  In the wake of his older brother's death, 13-y...   \n","5971      Green is Gold  After a teenage boy's father goes to prison, h...   \n","4573            ltr  A journalist goes undercover as a prostitute t...   \n","4820  The Sleeping City  In New York, the murder of a Bellvue Hospital ...   \n","\n","      combined_cluster  rating  votes  \n","3040                 3     7.3   7696  \n","5784                 3     6.3    533  \n","5971                 3     5.9    989  \n","4573                 3     5.5    810  \n","4820                 3     6.7    638  \n","\n"," === Input Movie === \n","title                                                        Aelliseu\n","description         The story of detective Park Jin Gyeom who come...\n","combined_cluster                                                    3\n","Name: 2962, dtype: object\n","\n","=== Recommended movies === \n","          title                                        description  \\\n","8375   The Gift  A picture of Shahmaran confirms Erhan's suspic...   \n","8370   The Gift  Abstract painter Atiye crosses paths with Erha...   \n","2258  Frequency  A police detective in 2016 discovers that she ...   \n","8374   The Gift  Inside the cave, Atiye comes to terms with her...   \n","8372   The Gift  As Zhre's identity comes to light, Atiye susp...   \n","\n","      combined_cluster  rating  votes  \n","8375                 3     7.7    609  \n","8370                 3     7.6    851  \n","2258                 3     7.4  13862  \n","8374                 3     7.4    636  \n","8372                 3     7.8    687  \n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1Q4QXaRlxhGUSvhrQ23Hgo5QBiJymjDY-","timestamp":1732339304842},{"file_id":"1JQAVVrg6i6fE3ntj8D93bfKDO97HTg_F","timestamp":1720234011291}],"collapsed_sections":["6QqkLQZWXk7x","2PFlLypb4L4r","GIrEqfHM2kzn"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7e7e0e0152ed48789138b43c6a3d8c68":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1df4c613d4c84fac96d4a2d5cf21168f","IPY_MODEL_66acfff9ab4c488a941b5ba981d97f5d","IPY_MODEL_8fae36c19d654874828aab4ce9c9ed26"],"layout":"IPY_MODEL_a39cea6d5207416c9a3f1b629cbde24a","tabbable":null,"tooltip":null}},"1df4c613d4c84fac96d4a2d5cf21168f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_60dae55270e64185a77526c1d0e22825","placeholder":"","style":"IPY_MODEL_2cc5277716b7462597a8ea1768d449eb","tabbable":null,"tooltip":null,"value":"Processing:100%"}},"66acfff9ab4c488a941b5ba981d97f5d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"","description":"","description_allow_html":false,"layout":"IPY_MODEL_5b00a55336f34e378c26a01f04181fed","max":77,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ccd64b825b994e70ac08471b8cc65240","tabbable":null,"tooltip":null,"value":77}},"8fae36c19d654874828aab4ce9c9ed26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_0cb45b6a38504708b15f21ff9d37131c","placeholder":"","style":"IPY_MODEL_51fb89dd58c74beb99ca3d163ba396f7","tabbable":null,"tooltip":null,"value":"77/77[05:43&lt;00:00,18.59s/it]"}},"a39cea6d5207416c9a3f1b629cbde24a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"60dae55270e64185a77526c1d0e22825":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cc5277716b7462597a8ea1768d449eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"5b00a55336f34e378c26a01f04181fed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccd64b825b994e70ac08471b8cc65240":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0cb45b6a38504708b15f21ff9d37131c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51fb89dd58c74beb99ca3d163ba396f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"d9855e178e434bc9b18cebb4b58ee794":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2408cc1378e4363b7da40d22232fc40","IPY_MODEL_415c5b11550e4823ac2e39da558a4452","IPY_MODEL_719f02e8440a4a51820419fb4726e0a2"],"layout":"IPY_MODEL_eee093b3f4d34dfeac243f4451c2f988","tabbable":null,"tooltip":null}},"b2408cc1378e4363b7da40d22232fc40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_742a8f7fcb6045e79e4c7ab324a10b3a","placeholder":"","style":"IPY_MODEL_5d099bbccb3143ab8805f169e7b9f09f","tabbable":null,"tooltip":null,"value":"Processing:100%"}},"415c5b11550e4823ac2e39da558a4452":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"","description":"","description_allow_html":false,"layout":"IPY_MODEL_2d5b688f15434bba805eb17d404b21e2","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82e1e99c48e94e2989c4fd01204fa85c","tabbable":null,"tooltip":null,"value":7}},"719f02e8440a4a51820419fb4726e0a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_b4d220e9d2274dfbb357a05332a49bd5","placeholder":"","style":"IPY_MODEL_1841357aedc442d7ba96a4b429cffdab","tabbable":null,"tooltip":null,"value":"7/7[00:50&lt;00:00,5.73s/it]"}},"eee093b3f4d34dfeac243f4451c2f988":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"742a8f7fcb6045e79e4c7ab324a10b3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d099bbccb3143ab8805f169e7b9f09f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"2d5b688f15434bba805eb17d404b21e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82e1e99c48e94e2989c4fd01204fa85c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4d220e9d2274dfbb357a05332a49bd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1841357aedc442d7ba96a4b429cffdab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"5ed5e06d28694c77a12a0992a27cc11a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_251d58a82c50422e822ebe4ebd548a6d","IPY_MODEL_4c65f9dd28a34a44800f76010ba753db","IPY_MODEL_5a354e1c25214c4589b3b9369d85cb5a"],"layout":"IPY_MODEL_95d22b6c0e6a4c35ab5a0b46aa784791","tabbable":null,"tooltip":null}},"251d58a82c50422e822ebe4ebd548a6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_b724571c41e142b3859c7f7c319d01c9","placeholder":"","style":"IPY_MODEL_3be252c93c53464e84544d7e333ea120","tabbable":null,"tooltip":null,"value":"Processing:100%"}},"4c65f9dd28a34a44800f76010ba753db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"","description":"","description_allow_html":false,"layout":"IPY_MODEL_2a8b3dc309db41c1a1501f739aebf109","max":61,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e05d2ee9e7c04812a59edd29f049d62e","tabbable":null,"tooltip":null,"value":61}},"5a354e1c25214c4589b3b9369d85cb5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_95136f5b5a5f48c28fee742cc6f4915e","placeholder":"","style":"IPY_MODEL_4c6c169dc5a442d2a638e94487c12cd7","tabbable":null,"tooltip":null,"value":"61/61[14:37&lt;00:00,15.13s/it]"}},"95d22b6c0e6a4c35ab5a0b46aa784791":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"b724571c41e142b3859c7f7c319d01c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3be252c93c53464e84544d7e333ea120":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"2a8b3dc309db41c1a1501f739aebf109":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e05d2ee9e7c04812a59edd29f049d62e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"95136f5b5a5f48c28fee742cc6f4915e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c6c169dc5a442d2a638e94487c12cd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"3e28c5b9268d41bc835b580536063a93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c8fad4946274558a888ecba95806393","IPY_MODEL_a8c5682b3599426ca88903995a920e35","IPY_MODEL_17f62aeed7524c328891d918d6e74f67"],"layout":"IPY_MODEL_95b8ccdaab154d8abd8d9ebb0f58b24b","tabbable":null,"tooltip":null}},"4c8fad4946274558a888ecba95806393":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_07ec919d277f42cba2d983d4ad60de27","placeholder":"","style":"IPY_MODEL_852caa28e6524f05bd8b977ed299a80b","tabbable":null,"tooltip":null,"value":"Processing:100%"}},"a8c5682b3599426ca88903995a920e35":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"","description":"","description_allow_html":false,"layout":"IPY_MODEL_40e57fed84684f48a40be5ab09dc169c","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ded86a4fa16b4107bbf4de8861e706a0","tabbable":null,"tooltip":null,"value":7}},"17f62aeed7524c328891d918d6e74f67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_4a3107f4cc3146e483c144534311c85c","placeholder":"","style":"IPY_MODEL_b1020dd2915d46e7ae67261a7730b0b1","tabbable":null,"tooltip":null,"value":"7/7[00:04&lt;00:00,1.82it/s]"}},"95b8ccdaab154d8abd8d9ebb0f58b24b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"07ec919d277f42cba2d983d4ad60de27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"852caa28e6524f05bd8b977ed299a80b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"40e57fed84684f48a40be5ab09dc169c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ded86a4fa16b4107bbf4de8861e706a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a3107f4cc3146e483c144534311c85c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1020dd2915d46e7ae67261a7730b0b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"df0cf71b9ee846cb870e29ec3d9e9d16":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ff2263bfd2c488b942552b204a18141","IPY_MODEL_ebc2cb87b2124741b50952f019efeaa2","IPY_MODEL_b89ec192106b432e88dbfd9c833920d0"],"layout":"IPY_MODEL_eba7e7130ffe4c68bfcce140a8950a9b","tabbable":null,"tooltip":null}},"8ff2263bfd2c488b942552b204a18141":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_ef65c5c4fbe34ace8c2811d1e6761b53","placeholder":"","style":"IPY_MODEL_8c3acaadb3a54d2f8e466defff6479b8","tabbable":null,"tooltip":null,"value":"Processing:100%"}},"ebc2cb87b2124741b50952f019efeaa2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"","description":"","description_allow_html":false,"layout":"IPY_MODEL_904aa4cb48cc4d728c7a8dbb87b2788e","max":61,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e58b3401ce9642c082ea9eaa53b14585","tabbable":null,"tooltip":null,"value":61}},"b89ec192106b432e88dbfd9c833920d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_a7e9a40229d04cedb368b47c0a0064a1","placeholder":"","style":"IPY_MODEL_6cf6754e80684ef894aaf7a01bb014bd","tabbable":null,"tooltip":null,"value":"61/61[16:29&lt;00:00,16.95s/it]"}},"eba7e7130ffe4c68bfcce140a8950a9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"ef65c5c4fbe34ace8c2811d1e6761b53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c3acaadb3a54d2f8e466defff6479b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"904aa4cb48cc4d728c7a8dbb87b2788e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e58b3401ce9642c082ea9eaa53b14585":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7e9a40229d04cedb368b47c0a0064a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cf6754e80684ef894aaf7a01bb014bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"fe83245aa4ec4e3f968a29bd5244161a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ae288b9bfa39472c820fe3b55fcfae8e","IPY_MODEL_c9bd52062d2041818acb5bbc5bbb7d7e","IPY_MODEL_4fd80b07c1d04aaea344ca953c88c5ce"],"layout":"IPY_MODEL_80e730cbbe98438aa612904691a3a516","tabbable":null,"tooltip":null}},"ae288b9bfa39472c820fe3b55fcfae8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_9069e36adab84ab68b7e167df3648f49","placeholder":"","style":"IPY_MODEL_257356496399429f85103dd798aeb897","tabbable":null,"tooltip":null,"value":"Processing:100%"}},"c9bd52062d2041818acb5bbc5bbb7d7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"","description":"","description_allow_html":false,"layout":"IPY_MODEL_3ab2ad514355420ea311d4c29f443938","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29900edfd6ef40508c5e171953e29e4c","tabbable":null,"tooltip":null,"value":7}},"4fd80b07c1d04aaea344ca953c88c5ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_6ef91e438e2648da9c1a71c073f3bbf8","placeholder":"","style":"IPY_MODEL_ed02dbc2f2634c3e92edd6ca0230fd13","tabbable":null,"tooltip":null,"value":"7/7[05:45&lt;00:00,39.30s/it]"}},"80e730cbbe98438aa612904691a3a516":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"9069e36adab84ab68b7e167df3648f49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"257356496399429f85103dd798aeb897":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"3ab2ad514355420ea311d4c29f443938":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29900edfd6ef40508c5e171953e29e4c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ef91e438e2648da9c1a71c073f3bbf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed02dbc2f2634c3e92edd6ca0230fd13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}}}}},"nbformat":4,"nbformat_minor":0}